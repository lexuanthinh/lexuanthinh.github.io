{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to DSSAMA DSSAMA l\u00e0 m\u1ed9t n\u1ec1n t\u1ea3ng h\u1ed7 tr\u1ee3 ph\u00e2n t\u00edch v\u00e0 x\u1eed l\u00fd d\u1eef li\u1ec7u l\u1edbn. Project layout H\u01b0\u1edbng d\u1eabn s\u1eed d\u1ee5ng DSSAMA cho b\u00e0i to\u00e1n x\u1eed l\u00fd b\u1ed9 d\u1eef li\u1ec7u Titanic Dataset.","title":"Welcome to DSSAMA"},{"location":"#welcome-to-dssama","text":"DSSAMA l\u00e0 m\u1ed9t n\u1ec1n t\u1ea3ng h\u1ed7 tr\u1ee3 ph\u00e2n t\u00edch v\u00e0 x\u1eed l\u00fd d\u1eef li\u1ec7u l\u1edbn.","title":"Welcome to DSSAMA"},{"location":"#project-layout","text":"H\u01b0\u1edbng d\u1eabn s\u1eed d\u1ee5ng DSSAMA cho b\u00e0i to\u00e1n x\u1eed l\u00fd b\u1ed9 d\u1eef li\u1ec7u Titanic Dataset.","title":"Project layout"},{"location":"EN/en_deep_learning_evaluation/","text":"1. Image Classification Neural Network Step 1: Select Image Input for Classification under the \u201cinputs\u201d list. Dataset: Here we will use the Cifar10 dataset (Link to dataset: https://www.kaggle.com/c/cifar-10/data). The original dataset contains 60000 images. Here, we will use only 15000 images of 3 classes: bird, cat v\u00e0 dog, each class with 5000 images for training and testing. Click RUN to view input data: Step 2: Select \u201cImage\u201d in the \u201ctfsama\u201d Select Image Classification Neural Network, put it on the stage grid and choose the suitable parameters. Layer: where you configure your neural network. Click on the button . Here, we will use RGB images as input of the network, so in the configuration, the input shape will be 32x32x3 (32 pixels in width and height and 3 color channel): We keep the other parameters the same Step 3: Connect Image Input for Classification into stage Image Classification Neural Network Step 4: Click Run to execute the flow and display result. 2. DenseNet 2.1. Algorithm description See more at: https://arxiv.org/pdf/1608.06993.pdf 2.2. Implementation details Step 1: SelectCh\u1ecdn Image Input for Classification trong Input: Dataset: We will use the same Cifar10 dataset (Link dataset: https://www.kaggle.com/c/cifar-10/data) as above. Click RUN to view input data: Step 2: Select DenseNet In \u201ctfsama\u201d package, select DenseNet stage. Then, select the suitable parameter: Architecture: Select the suitable variation of DenseNet. Input_shape: Click CONFIGURATION to choose the suitable input shape.In this case, the shape is (32x32x3). Top Layers: Click CONFIGURATION to fine-tune the Fully Connected layer of the Network Step 3: Connect Image Input for Classification with stage DenseNet B\u01b0\u1edbc 4: Click \u201cRun\u201d to execute flow 3. MobileNet 3.1. Algorithm description See more at: https://arxiv.org/pdf/1704.04861.pdf 3.2. Implementation details Step 1: Select Image Input for Classification in \u201cinputs\u201d list: Dataset: We use the same Cifar10 dataset (Link to dataset: https://www.kaggle.com/c/cifar-10/data) as above. Step 2: Select MobileNet In \u201ctfsama\u201d package select MobileNet and move it to the stage grid Architecture: Select the suitable architecture variation of Mobile Net Input_shape: Click CONFIGURATION and change input shape to 32x32x3 as above: Top Layers: Click CONFIGURATION to configure the last Fully Connected Layer, since we have 3 classes the number of units in the last layers will be 3. Step 3: Connect Image Input for Classification with MobileNet Step 4: Click Run to execute flow and display result 6. TabularData Classification Neural Network Step 1: Ch\u1ecdn stage input Select Tabular Input in \u201cinputs\u201d list. Dataset: We use the Iris dataset (Link to dataset: https://www.kaggle.com/arshid/iris-flower-dataset). This dataset consists of 6 columns: the first is index, the 2nd, 3rd, and 4th are data features including: Petal Length, Petal Width, Sepal Length, Sepal width. The 6th is data labels consisting of three iris species. Selected column: Petal Length, Petal Width, Sepal Length, Sepal Width Click RUN to view input to view input data. Step 2: Select Tabular Data Classification Neural Network In tfsama package, select TabularData Classification Neural Network and move it to the stage grid. Layer: Click on the CONFIGURATION button to finetune the parameters. Here we have 4 features, so the input shape will be 4. Users can finetune other parameters to suit the problem. Step 3: Connect Tabular Input with TabularData Classification Neural Network stage Step 4: Click Run to display result 7. TimeSeries Forecasting Neural Network Step 1: Select Input stage Select Timeseries Input in \u201cinput\u201d lists. Dataset: We use the Google Stock dataset (Link to dataset: https://www.kaggle.com/medharawat/google-stock-price). This dataset n\u00e0y consists of 6 columns: Date, Open, High, Low, Close, Volume Time steps column: Date Selected column: Open, High, Low, Close, Volume Step 2: Select Vectorize Transform In package \u201cscikitsama\u201d select Vectorize Transform and move it to the stage grid. In Vectorize Trasform, we have parameter\u201d Vectorize Column\u201d to select the columns to be vectorize. Here we choose: Open, High, Low, Close Step 3: Connect Timeseries Input with Vectorize Transform stage. Step 4: Click Run to execute flow and display result Step 5: Select TimeSeries Forecasting Neural Network In package \u201ctfsama\u201d, select TimeSeries Forecasting Neural Network and move it to the stage grid. Afterwards, users need to finetune the parameters suitably: - Features Column: Columns that have been vectorized with Vectorize Transform - Target Column: Select Volumn - Layer: click on the CONFIGURATION button to finetune the network We have 4 features: Open, High, Low, Close and set Window size = 10, so the input_shape is as follows: Window size: set to 10 Step 6: Connect Vectorize Trasform with TimeSeries Forecasting Neural Network stage TimeSeries Forecasting Neural Network will used the vectorized columns to predict Target Column Step 7: Click Run to display results.","title":"Deep Learning Evaluation"},{"location":"EN/en_deep_learning_evaluation/#1-image-classification-neural-network","text":"","title":"1. Image Classification Neural Network"},{"location":"EN/en_deep_learning_evaluation/#step-1-select-image-input-for-classification-under-the-inputs-list","text":"Dataset: Here we will use the Cifar10 dataset (Link to dataset: https://www.kaggle.com/c/cifar-10/data). The original dataset contains 60000 images. Here, we will use only 15000 images of 3 classes: bird, cat v\u00e0 dog, each class with 5000 images for training and testing. Click RUN to view input data:","title":"Step 1: Select Image Input for Classification under the \u201cinputs\u201d list."},{"location":"EN/en_deep_learning_evaluation/#step-2-select-image-in-the-tfsama","text":"Select Image Classification Neural Network, put it on the stage grid and choose the suitable parameters. Layer: where you configure your neural network. Click on the button . Here, we will use RGB images as input of the network, so in the configuration, the input shape will be 32x32x3 (32 pixels in width and height and 3 color channel): We keep the other parameters the same","title":"Step 2: Select \u201cImage\u201d in the \u201ctfsama\u201d"},{"location":"EN/en_deep_learning_evaluation/#step-3-connect-image-input-for-classification-into-stage-image-classification-neural-network","text":"","title":"Step 3: Connect Image Input for Classification into stage Image Classification Neural Network"},{"location":"EN/en_deep_learning_evaluation/#step-4-click-run-to-execute-the-flow-and-display-result","text":"","title":"Step 4: Click Run to execute the flow and display result."},{"location":"EN/en_deep_learning_evaluation/#2-densenet","text":"","title":"2. DenseNet"},{"location":"EN/en_deep_learning_evaluation/#21-algorithm-description","text":"See more at: https://arxiv.org/pdf/1608.06993.pdf","title":"2.1. Algorithm description"},{"location":"EN/en_deep_learning_evaluation/#22-implementation-details","text":"","title":"2.2. Implementation details"},{"location":"EN/en_deep_learning_evaluation/#step-1-selectchon-image-input-for-classification-trong-input","text":"Dataset: We will use the same Cifar10 dataset (Link dataset: https://www.kaggle.com/c/cifar-10/data) as above. Click RUN to view input data:","title":"Step 1: SelectCh\u1ecdn Image Input for Classification trong Input:"},{"location":"EN/en_deep_learning_evaluation/#step-2-select-densenet","text":"In \u201ctfsama\u201d package, select DenseNet stage. Then, select the suitable parameter: Architecture: Select the suitable variation of DenseNet. Input_shape: Click CONFIGURATION to choose the suitable input shape.In this case, the shape is (32x32x3). Top Layers: Click CONFIGURATION to fine-tune the Fully Connected layer of the Network","title":"Step 2: Select DenseNet"},{"location":"EN/en_deep_learning_evaluation/#step-3-connect-image-input-for-classification-with-stage-densenet","text":"","title":"Step 3: Connect Image Input for Classification with stage DenseNet"},{"location":"EN/en_deep_learning_evaluation/#buoc-4-click-run-to-execute-flow","text":"","title":"B\u01b0\u1edbc 4: Click \u201cRun\u201d to execute flow"},{"location":"EN/en_deep_learning_evaluation/#3-mobilenet","text":"","title":"3. MobileNet"},{"location":"EN/en_deep_learning_evaluation/#31-algorithm-description","text":"See more at: https://arxiv.org/pdf/1704.04861.pdf","title":"3.1. Algorithm description"},{"location":"EN/en_deep_learning_evaluation/#32-implementation-details","text":"","title":"3.2. Implementation details"},{"location":"EN/en_deep_learning_evaluation/#step-1-select-image-input-for-classification-in-inputs-list","text":"Dataset: We use the same Cifar10 dataset (Link to dataset: https://www.kaggle.com/c/cifar-10/data) as above.","title":"Step 1: Select Image Input for Classification in \u201cinputs\u201d list:"},{"location":"EN/en_deep_learning_evaluation/#step-2-select-mobilenet","text":"In \u201ctfsama\u201d package select MobileNet and move it to the stage grid Architecture: Select the suitable architecture variation of Mobile Net Input_shape: Click CONFIGURATION and change input shape to 32x32x3 as above: Top Layers: Click CONFIGURATION to configure the last Fully Connected Layer, since we have 3 classes the number of units in the last layers will be 3.","title":"Step 2: Select MobileNet"},{"location":"EN/en_deep_learning_evaluation/#step-3-connect-image-input-for-classification-with-mobilenet","text":"","title":"Step 3: Connect Image Input for Classification with MobileNet"},{"location":"EN/en_deep_learning_evaluation/#step-4-click-run-to-execute-flow-and-display-result","text":"","title":"Step 4: Click Run to execute flow and display result"},{"location":"EN/en_deep_learning_evaluation/#6-tabulardata-classification-neural-network","text":"","title":"6. TabularData Classification Neural Network"},{"location":"EN/en_deep_learning_evaluation/#step-1-chon-stage-input","text":"Select Tabular Input in \u201cinputs\u201d list. Dataset: We use the Iris dataset (Link to dataset: https://www.kaggle.com/arshid/iris-flower-dataset). This dataset consists of 6 columns: the first is index, the 2nd, 3rd, and 4th are data features including: Petal Length, Petal Width, Sepal Length, Sepal width. The 6th is data labels consisting of three iris species. Selected column: Petal Length, Petal Width, Sepal Length, Sepal Width Click RUN to view input to view input data.","title":"Step 1: Ch\u1ecdn stage input"},{"location":"EN/en_deep_learning_evaluation/#step-2-select-tabular-data-classification-neural-network","text":"In tfsama package, select TabularData Classification Neural Network and move it to the stage grid. Layer: Click on the CONFIGURATION button to finetune the parameters. Here we have 4 features, so the input shape will be 4. Users can finetune other parameters to suit the problem.","title":"Step 2: Select Tabular Data Classification Neural Network"},{"location":"EN/en_deep_learning_evaluation/#step-3-connect-tabular-input-with-tabulardata-classification-neural-network-stage","text":"","title":"Step 3: Connect Tabular Input with TabularData Classification Neural Network stage"},{"location":"EN/en_deep_learning_evaluation/#step-4-click-run-to-display-result","text":"","title":"Step 4: Click Run to display result"},{"location":"EN/en_deep_learning_evaluation/#7-timeseries-forecasting-neural-network","text":"","title":"7. TimeSeries Forecasting Neural Network"},{"location":"EN/en_deep_learning_evaluation/#step-1-select-input-stage","text":"Select Timeseries Input in \u201cinput\u201d lists. Dataset: We use the Google Stock dataset (Link to dataset: https://www.kaggle.com/medharawat/google-stock-price). This dataset n\u00e0y consists of 6 columns: Date, Open, High, Low, Close, Volume Time steps column: Date Selected column: Open, High, Low, Close, Volume","title":"Step 1: Select Input stage"},{"location":"EN/en_deep_learning_evaluation/#step-2-select-vectorize-transform","text":"In package \u201cscikitsama\u201d select Vectorize Transform and move it to the stage grid. In Vectorize Trasform, we have parameter\u201d Vectorize Column\u201d to select the columns to be vectorize. Here we choose: Open, High, Low, Close","title":"Step 2: Select Vectorize Transform"},{"location":"EN/en_deep_learning_evaluation/#step-3-connect-timeseries-input-with-vectorize-transform-stage","text":"","title":"Step 3: Connect Timeseries Input with Vectorize Transform stage."},{"location":"EN/en_deep_learning_evaluation/#step-4-click-run-to-execute-flow-and-display-result_1","text":"","title":"Step 4: Click Run to execute flow and display result"},{"location":"EN/en_deep_learning_evaluation/#step-5-select-timeseries-forecasting-neural-network","text":"In package \u201ctfsama\u201d, select TimeSeries Forecasting Neural Network and move it to the stage grid. Afterwards, users need to finetune the parameters suitably: - Features Column: Columns that have been vectorized with Vectorize Transform - Target Column: Select Volumn - Layer: click on the CONFIGURATION button to finetune the network We have 4 features: Open, High, Low, Close and set Window size = 10, so the input_shape is as follows: Window size: set to 10","title":"Step 5: Select TimeSeries Forecasting Neural Network"},{"location":"EN/en_deep_learning_evaluation/#step-6-connect-vectorize-trasform-with-timeseries-forecasting-neural-network-stage","text":"TimeSeries Forecasting Neural Network will used the vectorized columns to predict Target Column","title":"Step 6: Connect Vectorize Trasform with TimeSeries Forecasting Neural Network stage"},{"location":"EN/en_deep_learning_evaluation/#step-7-click-run-to-display-results","text":"","title":"Step 7: Click Run to display results."},{"location":"EN/en_deploy/","text":"Deploy Machine Learning model Step 1: Run v\u00e0 deploy Flow on DSSAMA platform 1. Import data: Choose Input Stage into Dataflow Editor. Create Flows for your problems. 2. Click Run. Once a flow is successfully executed, all the boxes will have green ticks 3. Click Deploy on the toolbar. Step 2: Use Postman deploy Flow Installing Postman After deploying the model successfulling, follow these steps: 1. Call request URL : API /releasedFlows to get the list of deployed flow. 2. Call API /release/ping/<flow_id> to get information of the deployed flow according to <flow_id> . <flow_id> can be retrieved on the address bar of DSSAMA platform 3. Call API /released/runflow/<flow_id> to run deployed flow. Pass in the Request body: { \"datasets\": [ { \"inputStageId\": <from results of section 2>, \"idCol\": <id column>, \"labelCol\": <label column>, \"dataType\": <data type>, \"data\": <data> } ] } After sending request, the result will be returned as JSON file as follow:","title":"Deploy"},{"location":"EN/en_deploy/#deploy-machine-learning-model","text":"Step 1: Run v\u00e0 deploy Flow on DSSAMA platform 1. Import data: Choose Input Stage into Dataflow Editor. Create Flows for your problems. 2. Click Run. Once a flow is successfully executed, all the boxes will have green ticks 3. Click Deploy on the toolbar. Step 2: Use Postman deploy Flow Installing Postman After deploying the model successfulling, follow these steps: 1. Call request URL : API /releasedFlows to get the list of deployed flow. 2. Call API /release/ping/<flow_id> to get information of the deployed flow according to <flow_id> . <flow_id> can be retrieved on the address bar of DSSAMA platform 3. Call API /released/runflow/<flow_id> to run deployed flow. Pass in the Request body: { \"datasets\": [ { \"inputStageId\": <from results of section 2>, \"idCol\": <id column>, \"labelCol\": <label column>, \"dataType\": <data type>, \"data\": <data> } ] } After sending request, the result will be returned as JSON file as follow:","title":"Deploy Machine Learning model"},{"location":"EN/en_flow/","text":"","title":"Flow"},{"location":"EN/en_getting_started/","text":"DSSAMA Quick Tour In this section, we will guide you through the interface of DSSAMA, a platform for Big Data project management and implementation, using Titanic Dataset as an example. Welcome to DSSAMA 1. GETTING STARTED NEW USER \u2013 CREATE ACCOUNT \u2022 For first-time visitors, you can create your new accounts here at DSSAMA \u2022 When the interface below appears, click Sign Up \u2022 Then, fill in the required fields of information and click Sign up. An account verification token will be sent to your email. \u2022 Open the mail, copy and paste the token inside to the Token code line and click Confirm. Your account will have been successfully created and ready to be use. Please note that you have 99 seconds to fill in the token. LOGIN \u2022 Log in to DSSAMA with your registered account. Once you\u2019re logged in, you will see an interface as below. 2. WORKSPACE \u2022 After you log in, you can create your Workspaces to work with your data. Each account will be provided with a free and secure default workspace server. However, for your second workspace onwards, workspace server will have to be paid for. Once you fill in the information and click \"Save\", a new Workpsace, where you can carry out your work, will be created, 3. WORKSPACE SERVER 4. PROJECT \u2022 For each Workspace, you can create one or many Projects in order to manage and store Workflows for each particular project and problem. \u2022 To add new Project, click on the \u201c+\u201d symbol inside your Workspace Task \u2022 Task is where you manage, and allocate tasks in a project. Timeline (History) \u2022 Display your activity logs in a project 5. DATA INTERGRATON AND STORAGE Data source is where you store datasets for your projects. Here, you can add a new dataset based on your needs. Click \u201cAdd a new data source\u201d at the List of data source section, fill in the required fields of information. In this case, we will add the Titanic dataset from Kaggle. Data type : As Choose Tabular for the Titanic dataset Source type : Since the train.csv file we are using has \u201ccsv\u201d extension, we choose Csv file. Choose File : Upload the train.csv from your computer. ID column : Choose the Id column. In this file, the Id column is PassengerId Label column : Choose the label column of the dataset. In this case, that is the Survived column. Figure 3. Add a new data source. 6. USER - ASSIGN USER \u2022 In team projects, List of assigned user will show you the list of members and their allocated tasks in a project. 7. FLOW \u2022 A Flow is where we directly work with datasets. For each problem, you can create its own Flow. Figure 4. Add a new Flow 8. SIMPLE FLOW Figure 5. The main components in a Flow\u2019s interface After we create a Flow to work, click on the new Flow to start working. DSSAMA Flow \u2013 your working interface will have the following components: - Dataflow Editor (the Grids): The Grid area to create and edit flows. - Stage Repository: List of available Stages on DSSAMA, they correspond to a variety of Machine Learning/Data Processing algorithms. - Stage Properties: Adjustable properties of a Stage, one a Stage on the Dataflow Editor, you can click on it to adjust its properties to suit your goal. - Console log: The display windown of a flow\u2019s execution results. Stage and Flow On DSSAMA, each Stage represents a dataprocessing task. You can find the Stage you need in the Stage Repository, move them into the Grids. Save for the Input Stage, each Stage can receive output from a previous stage as input. You can adjust a Stage\u2019s Properties to suit the goal. To execute a flow, click on its final Stage and click Run on its toolbar. When you finish, there will be a console log displaying the output of that Stage. Each successfully run Stage will have a green tick in the bottom-right corner. Figure 6. Stage and Stage Properties in a Flow <!-- ## 9. MACHINE LEARNING PIPELINE Data Import and manipulation Importing data Input Stages allow us to use the datasets in the Workspace\u2019s data source. Each type of data source will have its own Input Stage, with the main Input Stages being: \u2022 Tabular Input: Input Stage for tabular data type. \u2022 Text Input: Input Stage for text data type. \u2022 Timeseries Input: Input Stage for sequential data type. \u2022 Image Input: Input Stage for image data type. Other types of Input Stage include Image Input for Classification, Image Input for Segmentation. Data Preprocessing Supervised Modeling Unsupervised Modeling Evaluation 10. TUTORIAL Predict survival of Titanic passengers Titanic \u2013 the classic case of predictive analysis Problem: On April 15th 1912, the Titanic\u2019s disaster went down as one of the most infamous catastrophes in naval history, the RMS Titanic sank after collided with an iceberg, taking 1502 lives of the 2224 passengers and crewmembers on board. Input: You are provided with training data of 892 passengers, including information on their names, gender, age, ticket number, cabinet, etc. and survival status. Output: You are required to create a model that can predict the survivability on the remaining passengers based on the provided fields of information. Meaning: The resultant predictive model will provide lessons and recommendations for future marine travel, such as safer ship design, customer service for vulnerable groups, or alerting mechanisms, etc. Analysis: It can be seen that this is a Two-Class Classification problem with the two outputs being NOT_SUVIVAL or SUVIVAL. For a classification problem like this, there are many algorithms you can implement such as Naive Bayes, Decision Tree, Decision Forest \u2026 In the dataset, each line represents a passenger with these fields of information as below: Survival: 0 = No; 1 = Yes Pclass: Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd) Name: Passenger\u2019s name Sex: Sex Age: Age in years SibSp: # of siblings / spouses aboard the Titanic Parch: # of parents / children aboard the Titanic Ticket: Ticket number Fare: Passenger fare Cabin: Cabin number Embarked: Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton) Getting started Step 1: Create a Flow for this problem. Figure 5. A Flow with name \u201cClassification for Titanic\u201d Click on the Flow to enter its working interface. Figure 6. Working Interface for Flow \u201cClassification for Titanic\u201d Step 2: Importing data For the Titanic problem, data source type is Tabular, so in order to import it, we use Tabular Input Stage. Click Tabular Input Stage, move it to Dataflow Editor, when the Stage Properties window is displayed, we can choose the dataset and the columns to import. \u2022 Dataset: Choose \u201cTitanic\u201d \u2022 Selected colunns: Choose the columns you\u2019ll use. In this example, the selected columns only include PClass, Sex, Age, SibSp, Parch, Fare, Embarked. You can choose all the column if you like. \u2022 Click again on the Stage and click Run to test if the data has been successfully imported. \u2022 After that, a dashboard will be displayed as follow: Step 3: Handling missing data In the Titanic dataset, the Age v\u00e0 Embarked columns have missing values which need to be rectified. To solve missing data in Age column, choose Simple Imputer Transformer Stage in the Transformer package of Scikitsama.ml. Create a link from the Tabular Input Stage to the newly created imputer Stage. Adjust the properties as follow: \u2022 Selected column: Choose the column with missing data. \u2022 Missing Values: Choose either np.nan ho\u1eb7c None, based on how the dataset encodes missing data. In this case, the encoding is NaN. \u2022 *Strategy: Choose the missing-data-handling method from the below: \uf0a7 mean: Fill missing data with the column\u2019s average value. \uf0a7 median: Fill missing data with the column\u2019s median value. \uf0a7 most_frequent: Fill missing data with the column\u2019s most frequently occuring value. \uf0a7 constant: Fill missing data with a constant value, as defined in Fill Value text box. \u2022 Fill Value: only activated with constant option in Strategy Once setup is finished, click Run. Step 4: Encode d\u1eef li\u1ec7u d\u1ea1ng string: Sex Column contains two values: Male v\u00e0 Female, which can\u2019t be used to put in a ML model, so it needs encoding. Select One Hot Encoder Transformer Stage in Transformer subpackage of Scikitsama.ml. Link them with the previous Stages, select Sex Column and set the properties. After that, click on that Stage and click Run. Besides One Hot Encoder Transformer we could also use other encoding methods in the same sub-package such as Ordinal Encoder Transformer. Step 5: Data Normalization: In our current problem, features are in different value ranges, which will make it difficult for the machine learning model to learn. To prevent that, we need to normalize data. In this case, we will normalize Age column. Select Normalize Transformer in Transformer sub-package of Scikitsama.ml, link it to the previous Stage (One Hot Encoder Transformer). Select colum Age, set the property click again on the Stage and click Run. Step 6: Choosing Classification algorithms: DSSAMA Platform provides Classification Stages as shown below, you can choose one of them to complete the ML pipeline with the preprocessing steps taken before. Each Stage\u2019s properties is set up with default parameters for typical problems, you can change them according to your specific problems. You can build the Flow as shown in the figure 11 below: Execution results with Random Forest Classifier algorithm. Some other machine learning implementations in DSSAMA Figure 16. Examples of Machine Learning algorithm Building Flow for clustering problems. -->","title":"Home"},{"location":"EN/en_getting_started/#dssama-quick-tour","text":"In this section, we will guide you through the interface of DSSAMA, a platform for Big Data project management and implementation, using Titanic Dataset as an example. Welcome to DSSAMA","title":"DSSAMA Quick Tour"},{"location":"EN/en_getting_started/#1-getting-started","text":"","title":"1. GETTING STARTED"},{"location":"EN/en_getting_started/#new-user-create-account","text":"\u2022 For first-time visitors, you can create your new accounts here at DSSAMA \u2022 When the interface below appears, click Sign Up \u2022 Then, fill in the required fields of information and click Sign up. An account verification token will be sent to your email. \u2022 Open the mail, copy and paste the token inside to the Token code line and click Confirm. Your account will have been successfully created and ready to be use. Please note that you have 99 seconds to fill in the token.","title":"NEW USER \u2013 CREATE ACCOUNT"},{"location":"EN/en_getting_started/#login","text":"\u2022 Log in to DSSAMA with your registered account. Once you\u2019re logged in, you will see an interface as below.","title":"LOGIN"},{"location":"EN/en_getting_started/#2-workspace","text":"\u2022 After you log in, you can create your Workspaces to work with your data. Each account will be provided with a free and secure default workspace server. However, for your second workspace onwards, workspace server will have to be paid for. Once you fill in the information and click \"Save\", a new Workpsace, where you can carry out your work, will be created,","title":"2. WORKSPACE"},{"location":"EN/en_getting_started/#3-workspace-server","text":"","title":"3. WORKSPACE SERVER"},{"location":"EN/en_getting_started/#4-project","text":"\u2022 For each Workspace, you can create one or many Projects in order to manage and store Workflows for each particular project and problem. \u2022 To add new Project, click on the \u201c+\u201d symbol inside your Workspace","title":"4. PROJECT"},{"location":"EN/en_getting_started/#task","text":"\u2022 Task is where you manage, and allocate tasks in a project.","title":"Task"},{"location":"EN/en_getting_started/#timeline-history","text":"\u2022 Display your activity logs in a project","title":"Timeline (History)"},{"location":"EN/en_getting_started/#5-data-intergraton-and-storage","text":"Data source is where you store datasets for your projects. Here, you can add a new dataset based on your needs. Click \u201cAdd a new data source\u201d at the List of data source section, fill in the required fields of information. In this case, we will add the Titanic dataset from Kaggle. Data type : As Choose Tabular for the Titanic dataset Source type : Since the train.csv file we are using has \u201ccsv\u201d extension, we choose Csv file. Choose File : Upload the train.csv from your computer. ID column : Choose the Id column. In this file, the Id column is PassengerId Label column : Choose the label column of the dataset. In this case, that is the Survived column. Figure 3. Add a new data source.","title":"5. DATA INTERGRATON AND STORAGE"},{"location":"EN/en_getting_started/#6-user-assign-user","text":"\u2022 In team projects, List of assigned user will show you the list of members and their allocated tasks in a project.","title":"6. USER - ASSIGN USER"},{"location":"EN/en_getting_started/#7-flow","text":"\u2022 A Flow is where we directly work with datasets. For each problem, you can create its own Flow. Figure 4. Add a new Flow","title":"7. FLOW"},{"location":"EN/en_getting_started/#8-simple-flow","text":"Figure 5. The main components in a Flow\u2019s interface After we create a Flow to work, click on the new Flow to start working. DSSAMA Flow \u2013 your working interface will have the following components: - Dataflow Editor (the Grids): The Grid area to create and edit flows. - Stage Repository: List of available Stages on DSSAMA, they correspond to a variety of Machine Learning/Data Processing algorithms. - Stage Properties: Adjustable properties of a Stage, one a Stage on the Dataflow Editor, you can click on it to adjust its properties to suit your goal. - Console log: The display windown of a flow\u2019s execution results.","title":"8. SIMPLE FLOW"},{"location":"EN/en_getting_started/#stage-and-flow","text":"On DSSAMA, each Stage represents a dataprocessing task. You can find the Stage you need in the Stage Repository, move them into the Grids. Save for the Input Stage, each Stage can receive output from a previous stage as input. You can adjust a Stage\u2019s Properties to suit the goal. To execute a flow, click on its final Stage and click Run on its toolbar. When you finish, there will be a console log displaying the output of that Stage. Each successfully run Stage will have a green tick in the bottom-right corner. Figure 6. Stage and Stage Properties in a Flow <!-- ## 9. MACHINE LEARNING PIPELINE Data Import and manipulation Importing data Input Stages allow us to use the datasets in the Workspace\u2019s data source. Each type of data source will have its own Input Stage, with the main Input Stages being: \u2022 Tabular Input: Input Stage for tabular data type. \u2022 Text Input: Input Stage for text data type. \u2022 Timeseries Input: Input Stage for sequential data type. \u2022 Image Input: Input Stage for image data type. Other types of Input Stage include Image Input for Classification, Image Input for Segmentation. Data Preprocessing Supervised Modeling Unsupervised Modeling Evaluation","title":"Stage and Flow"},{"location":"EN/en_getting_started/#10-tutorial","text":"Predict survival of Titanic passengers Titanic \u2013 the classic case of predictive analysis Problem: On April 15th 1912, the Titanic\u2019s disaster went down as one of the most infamous catastrophes in naval history, the RMS Titanic sank after collided with an iceberg, taking 1502 lives of the 2224 passengers and crewmembers on board. Input: You are provided with training data of 892 passengers, including information on their names, gender, age, ticket number, cabinet, etc. and survival status. Output: You are required to create a model that can predict the survivability on the remaining passengers based on the provided fields of information. Meaning: The resultant predictive model will provide lessons and recommendations for future marine travel, such as safer ship design, customer service for vulnerable groups, or alerting mechanisms, etc. Analysis: It can be seen that this is a Two-Class Classification problem with the two outputs being NOT_SUVIVAL or SUVIVAL. For a classification problem like this, there are many algorithms you can implement such as Naive Bayes, Decision Tree, Decision Forest \u2026 In the dataset, each line represents a passenger with these fields of information as below: Survival: 0 = No; 1 = Yes Pclass: Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd) Name: Passenger\u2019s name Sex: Sex Age: Age in years SibSp: # of siblings / spouses aboard the Titanic Parch: # of parents / children aboard the Titanic Ticket: Ticket number Fare: Passenger fare Cabin: Cabin number Embarked: Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton) Getting started Step 1: Create a Flow for this problem. Figure 5. A Flow with name \u201cClassification for Titanic\u201d Click on the Flow to enter its working interface. Figure 6. Working Interface for Flow \u201cClassification for Titanic\u201d Step 2: Importing data For the Titanic problem, data source type is Tabular, so in order to import it, we use Tabular Input Stage. Click Tabular Input Stage, move it to Dataflow Editor, when the Stage Properties window is displayed, we can choose the dataset and the columns to import. \u2022 Dataset: Choose \u201cTitanic\u201d \u2022 Selected colunns: Choose the columns you\u2019ll use. In this example, the selected columns only include PClass, Sex, Age, SibSp, Parch, Fare, Embarked. You can choose all the column if you like. \u2022 Click again on the Stage and click Run to test if the data has been successfully imported. \u2022 After that, a dashboard will be displayed as follow: Step 3: Handling missing data In the Titanic dataset, the Age v\u00e0 Embarked columns have missing values which need to be rectified. To solve missing data in Age column, choose Simple Imputer Transformer Stage in the Transformer package of Scikitsama.ml. Create a link from the Tabular Input Stage to the newly created imputer Stage. Adjust the properties as follow: \u2022 Selected column: Choose the column with missing data. \u2022 Missing Values: Choose either np.nan ho\u1eb7c None, based on how the dataset encodes missing data. In this case, the encoding is NaN. \u2022 *Strategy: Choose the missing-data-handling method from the below: \uf0a7 mean: Fill missing data with the column\u2019s average value. \uf0a7 median: Fill missing data with the column\u2019s median value. \uf0a7 most_frequent: Fill missing data with the column\u2019s most frequently occuring value. \uf0a7 constant: Fill missing data with a constant value, as defined in Fill Value text box. \u2022 Fill Value: only activated with constant option in Strategy Once setup is finished, click Run. Step 4: Encode d\u1eef li\u1ec7u d\u1ea1ng string: Sex Column contains two values: Male v\u00e0 Female, which can\u2019t be used to put in a ML model, so it needs encoding. Select One Hot Encoder Transformer Stage in Transformer subpackage of Scikitsama.ml. Link them with the previous Stages, select Sex Column and set the properties. After that, click on that Stage and click Run. Besides One Hot Encoder Transformer we could also use other encoding methods in the same sub-package such as Ordinal Encoder Transformer. Step 5: Data Normalization: In our current problem, features are in different value ranges, which will make it difficult for the machine learning model to learn. To prevent that, we need to normalize data. In this case, we will normalize Age column. Select Normalize Transformer in Transformer sub-package of Scikitsama.ml, link it to the previous Stage (One Hot Encoder Transformer). Select colum Age, set the property click again on the Stage and click Run. Step 6: Choosing Classification algorithms: DSSAMA Platform provides Classification Stages as shown below, you can choose one of them to complete the ML pipeline with the preprocessing steps taken before. Each Stage\u2019s properties is set up with default parameters for typical problems, you can change them according to your specific problems. You can build the Flow as shown in the figure 11 below: Execution results with Random Forest Classifier algorithm. Some other machine learning implementations in DSSAMA Figure 16. Examples of Machine Learning algorithm Building Flow for clustering problems. -->","title":"10. TUTORIAL"},{"location":"EN/en_introduction/","text":"Welcome to DSSAMA DSSAMA Main Features \u0110\u1eb7c tr\u01b0ng ch\u00ednh c\u1ee7a DSSAMA Agility - Quickly build, test and deploy AI solutions with agility! Visuality - Drag and Drop with Visual Workflow! Cooperability - Customers, Technicians, AI Experts all cooperate seamlessly on one platform! Security - Data is always secured and located on local hosts! Others: Integrate powerful tools from third party AI vendors Automated data pipeline, Automated Machine Learning Models Web/mobile infrastructure on both DSSAMA Server and Cloud service through Docker Overall Framework Infrastructure Workspace Storing workspace for projects. - Project management - Tasks - Workflow version/Workflow Graph - Model Parameter, Hyper Parameters - Contributing Users - Data Management: - Storage for analysis - Connect to Data Lake, MDM - Resource Management: - Engine, RAM, Storage, GPU .... Machine Learning Flows Workflow of a project is a graph which describes a machine learning pipeline. Workflows by Graph Representation with Nodes Each node does a step in workflows. DSSAMA Features AI For All Support Collaboration State-of-the-art AI research Powerful Supporters:","title":"Welcome to DSSAMA"},{"location":"EN/en_introduction/#welcome-to-dssama","text":"DSSAMA","title":"Welcome to DSSAMA"},{"location":"EN/en_introduction/#main-features","text":"","title":"Main Features"},{"location":"EN/en_introduction/#ac-trung-chinh-cua-dssama","text":"Agility - Quickly build, test and deploy AI solutions with agility! Visuality - Drag and Drop with Visual Workflow! Cooperability - Customers, Technicians, AI Experts all cooperate seamlessly on one platform! Security - Data is always secured and located on local hosts!","title":"\u0110\u1eb7c tr\u01b0ng ch\u00ednh c\u1ee7a DSSAMA"},{"location":"EN/en_introduction/#others","text":"Integrate powerful tools from third party AI vendors Automated data pipeline, Automated Machine Learning Models Web/mobile infrastructure on both DSSAMA Server and Cloud service through Docker","title":"Others:"},{"location":"EN/en_introduction/#overall-framework-infrastructure","text":"","title":"Overall Framework Infrastructure"},{"location":"EN/en_introduction/#workspace","text":"Storing workspace for projects. - Project management - Tasks - Workflow version/Workflow Graph - Model Parameter, Hyper Parameters - Contributing Users - Data Management: - Storage for analysis - Connect to Data Lake, MDM - Resource Management: - Engine, RAM, Storage, GPU ....","title":"Workspace"},{"location":"EN/en_introduction/#machine-learning-flows","text":"Workflow of a project is a graph which describes a machine learning pipeline.","title":"Machine Learning Flows"},{"location":"EN/en_introduction/#workflows-by-graph-representation-with-nodes","text":"Each node does a step in workflows.","title":"Workflows by Graph Representation with Nodes"},{"location":"EN/en_introduction/#dssama-features","text":"AI For All Support Collaboration State-of-the-art AI research Powerful Supporters:","title":"DSSAMA Features"},{"location":"EN/en_machine-learning-pipeline/","text":"MACHINE LEARNING PIPELINE Data Import and manipulation Importing data Input Stages allow us to use the datasets in the Workspace\u2019s data source. Each type of data source will have its own Input Stage, with the main Input Stages being: \u2022 Tabular Input: Input Stage for tabular data type. \u2022 Text Input: Input Stage for text data type. \u2022 Timeseries Input: Input Stage for sequential data type. \u2022 Image Input: Input Stage for image data type. Other types of Input Stage include Image Input for Classification, Image Input for Segmentation. Data Preprocessing Supervised Learning Unsupervised Learning Evaluation","title":"MACHINE LEARNING PIPELINE"},{"location":"EN/en_machine-learning-pipeline/#machine-learning-pipeline","text":"","title":"MACHINE LEARNING PIPELINE"},{"location":"EN/en_machine-learning-pipeline/#data-import-and-manipulation","text":"Importing data Input Stages allow us to use the datasets in the Workspace\u2019s data source. Each type of data source will have its own Input Stage, with the main Input Stages being: \u2022 Tabular Input: Input Stage for tabular data type. \u2022 Text Input: Input Stage for text data type. \u2022 Timeseries Input: Input Stage for sequential data type. \u2022 Image Input: Input Stage for image data type. Other types of Input Stage include Image Input for Classification, Image Input for Segmentation.","title":"Data Import and manipulation"},{"location":"EN/en_machine-learning-pipeline/#data-preprocessing","text":"","title":"Data Preprocessing"},{"location":"EN/en_machine-learning-pipeline/#supervised-learning","text":"","title":"Supervised Learning"},{"location":"EN/en_machine-learning-pipeline/#unsupervised-learning","text":"","title":"Unsupervised Learning"},{"location":"EN/en_machine-learning-pipeline/#evaluation","text":"","title":"Evaluation"},{"location":"EN/en_machine_learning_pipeline_nltk/","text":"MACHINE LEARNING PIPELINE WITH NLTKSAMA 1. Word Stemming Transformer Step 1: Select Text Input trong Input.Ph\u1ea7n parameter: Dataset: here we use BBC_News Selected column: Content Start record: 0 End record: 9 Click RUN to view input data Step 2: In package nltksama.ml/transform select Word Stemming Transformer. Step 3: Connect Text Input with stage Word Stemming Transformer. The parameters are as follows: language (str) \u2013 Select the language of data: 'arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish'. ignore_stopwords (bool) \u2013 If True, ignore stopwords. Default is False. \u0111\u1ecbnh. Step 4: Click Run 2. Mwe Tokenization Transformer Step 1: Select Text Input in the Input list. Dataset: BBC News BBC_News Selected column: Content Start record: 0 End record: 9 Step 2: package nltksama.ml/transform select Mwe Tokenization Transformer . Step 3: N\u1ed1i Text Input (l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp BBC_News) v\u00e0o stage Mwe Tokenization Transformer . The parameters are as follows: mwe (tuple(str) or list(str)) : List of phrases to tokenize separator : phrase connector. Default is \u201c-\u201c. Step 4: Click Run 3. Tweet Tokenization Transformer Step 1: Select Text Input in the Input list. Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp BBC_News BBC_News elected column: Content Start record: 0 End record: 9 Click RUN to view data: \u2022 Step 2: In the package nltksama.ml/transform select Tweet Tokenization Transformer. \u2022 Step 3: Connect Text Input with Tweet Tokenization Transformer stage. For information on the parameters, visit: https://www.nltk.org/api/nltk.tokenize.html?highlight=tweettokenizer#nltk.tokenize.casual.TweetTokenizer \u2022 Step 4: Click Run:","title":"NLTK Machine Learning Pipeline"},{"location":"EN/en_machine_learning_pipeline_nltk/#machine-learning-pipeline-with-nltksama","text":"","title":"MACHINE LEARNING PIPELINE WITH NLTKSAMA"},{"location":"EN/en_machine_learning_pipeline_nltk/#1-word-stemming-transformer","text":"Step 1: Select Text Input trong Input.Ph\u1ea7n parameter: Dataset: here we use BBC_News Selected column: Content Start record: 0 End record: 9 Click RUN to view input data Step 2: In package nltksama.ml/transform select Word Stemming Transformer. Step 3: Connect Text Input with stage Word Stemming Transformer. The parameters are as follows: language (str) \u2013 Select the language of data: 'arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish'. ignore_stopwords (bool) \u2013 If True, ignore stopwords. Default is False. \u0111\u1ecbnh. Step 4: Click Run","title":"1. Word Stemming Transformer"},{"location":"EN/en_machine_learning_pipeline_nltk/#2-mwe-tokenization-transformer","text":"Step 1: Select Text Input in the Input list. Dataset: BBC News BBC_News Selected column: Content Start record: 0 End record: 9 Step 2: package nltksama.ml/transform select Mwe Tokenization Transformer . Step 3: N\u1ed1i Text Input (l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp BBC_News) v\u00e0o stage Mwe Tokenization Transformer . The parameters are as follows: mwe (tuple(str) or list(str)) : List of phrases to tokenize separator : phrase connector. Default is \u201c-\u201c. Step 4: Click Run","title":"2. Mwe Tokenization Transformer"},{"location":"EN/en_machine_learning_pipeline_nltk/#3-tweet-tokenization-transformer","text":"Step 1: Select Text Input in the Input list. Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp BBC_News BBC_News elected column: Content Start record: 0 End record: 9 Click RUN to view data: \u2022 Step 2: In the package nltksama.ml/transform select Tweet Tokenization Transformer. \u2022 Step 3: Connect Text Input with Tweet Tokenization Transformer stage. For information on the parameters, visit: https://www.nltk.org/api/nltk.tokenize.html?highlight=tweettokenizer#nltk.tokenize.casual.TweetTokenizer \u2022 Step 4: Click Run:","title":"3. Tweet Tokenization Transformer"},{"location":"EN/en_machine_learning_pipeline_scikitsama/","text":"MACHINE LEARNING PIPELINE WITH SCILITSAMA Scikitsama In this section, we will demonstrate some of the main features of scikitsama package. 1. Data Import and manipulation From the datasets you imported into Data source, to use them in a Flow, we use Input Stages. The list of input types is as follows: Tabular Input : Stage input for tabular data. Text Input : Stage input for text data. Timeseries Input : Stage input for temporal data. Image Input : Stage input for image data. Image Input for Classification : Image Input for Segmentation : Maps Input : Input for map data. Scikit Input : Input scikit-learn library with some classic dataset. Operations To import data into grid flow editor: 1. Click on the suitable Input stage (for example, for tabular datasource, we need to use Tabular Input) Click again on the grid to move the stage into the editor Select Stage features on the stage properties menu Click Run to visualize data. Data Preprocessing Supervised Modeling 1. Classification Scikit-sama package has a variety of Supervised Learning algorithms for classification . In this section, we will use Iris dataset in Scikit Input Stage as the example. This dataset has been preprocessed and has 4 features: sepal length (cm), sepal width (cm), petal length (cm) v\u00e0 petal width (cm). Target/label of the dataset is the name of the three Iris species. Click on the symbol to split data into and train v\u00e0 test sets. Default is 0.7/70% for training: Click Run to view data 1.1. Decision Tree Classifier 1.1.1. Algorithm Descriptions Decision Tree Classifier 1.1.2. Implementation Details Step 1: In package scikitsama.ml/classification, select Decision Tree Classifier by clicking on it and move the cursor to the data flow editor, click again. Step 2: Connect Scikit Input with Decision Tree Classifier stage. In Decision Tree Classifier, there are parameters to fine-tune. For more information, visit: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html Step 3: Click Run to view the results - The results are displayed in Metrics table and 2 columns target v\u00e0 y_pred. ![](https://i.imgur.com/n0AfmMj.png) ![](https://i.imgur.com/LueOX8C.png) Step 4: Model will be saved automatically after training and marked with a green tick d\u01b0\u1edbi 2. Regression Unsupervised Modeling Evaluation","title":"Scikit-learn Machine Learning Pipeline"},{"location":"EN/en_machine_learning_pipeline_scikitsama/#machine-learning-pipeline-with-scilitsama","text":"","title":"MACHINE LEARNING PIPELINE WITH SCILITSAMA"},{"location":"EN/en_machine_learning_pipeline_scikitsama/#scikitsama","text":"In this section, we will demonstrate some of the main features of scikitsama package.","title":"Scikitsama"},{"location":"EN/en_machine_learning_pipeline_scikitsama/#1-data-import-and-manipulation","text":"From the datasets you imported into Data source, to use them in a Flow, we use Input Stages. The list of input types is as follows: Tabular Input : Stage input for tabular data. Text Input : Stage input for text data. Timeseries Input : Stage input for temporal data. Image Input : Stage input for image data. Image Input for Classification : Image Input for Segmentation : Maps Input : Input for map data. Scikit Input : Input scikit-learn library with some classic dataset.","title":"1. Data Import and manipulation"},{"location":"EN/en_machine_learning_pipeline_scikitsama/#operations","text":"To import data into grid flow editor: 1. Click on the suitable Input stage (for example, for tabular datasource, we need to use Tabular Input) Click again on the grid to move the stage into the editor Select Stage features on the stage properties menu Click Run to visualize data.","title":"Operations"},{"location":"EN/en_machine_learning_pipeline_scikitsama/#data-preprocessing","text":"","title":"Data Preprocessing"},{"location":"EN/en_machine_learning_pipeline_scikitsama/#supervised-modeling","text":"","title":"Supervised Modeling"},{"location":"EN/en_machine_learning_pipeline_scikitsama/#1-classification","text":"Scikit-sama package has a variety of Supervised Learning algorithms for classification . In this section, we will use Iris dataset in Scikit Input Stage as the example. This dataset has been preprocessed and has 4 features: sepal length (cm), sepal width (cm), petal length (cm) v\u00e0 petal width (cm). Target/label of the dataset is the name of the three Iris species. Click on the symbol to split data into and train v\u00e0 test sets. Default is 0.7/70% for training: Click Run to view data","title":"1. Classification"},{"location":"EN/en_machine_learning_pipeline_scikitsama/#11-decision-tree-classifier","text":"","title":"1.1. Decision Tree Classifier"},{"location":"EN/en_machine_learning_pipeline_scikitsama/#111-algorithm-descriptions","text":"Decision Tree Classifier","title":"1.1.1. Algorithm Descriptions"},{"location":"EN/en_machine_learning_pipeline_scikitsama/#112-implementation-details","text":"Step 1: In package scikitsama.ml/classification, select Decision Tree Classifier by clicking on it and move the cursor to the data flow editor, click again. Step 2: Connect Scikit Input with Decision Tree Classifier stage. In Decision Tree Classifier, there are parameters to fine-tune. For more information, visit: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html Step 3: Click Run to view the results - The results are displayed in Metrics table and 2 columns target v\u00e0 y_pred. ![](https://i.imgur.com/n0AfmMj.png) ![](https://i.imgur.com/LueOX8C.png) Step 4: Model will be saved automatically after training and marked with a green tick d\u01b0\u1edbi","title":"1.1.2. Implementation Details"},{"location":"EN/en_machine_learning_pipeline_scikitsama/#2-regression","text":"","title":"2. Regression"},{"location":"EN/en_machine_learning_pipeline_scikitsama/#unsupervised-modeling","text":"","title":"Unsupervised Modeling"},{"location":"EN/en_machine_learning_pipeline_scikitsama/#evaluation","text":"","title":"Evaluation"},{"location":"EN/en_pyvisama/","text":"","title":"Pyvi Tutorial"},{"location":"EN/en_simpleflow/","text":"","title":"Simple Flow"},{"location":"EN/en_tutorial/","text":"DSSAMA Tutorial for Data Projects In this chapter, we will go in depths on how to use DSSAMA for classification machine learning problems, using the Titanic dataset as the example. 1. Predict survival of Titanic passengers Titanic \u2013 the classic case of predictive analysis Problem : On April 15th 1912, the Titanic\u2019s disaster went down as one of the most infamous catastrophes in naval history, the RMS Titanic sank after collided with an iceberg, taking 1502 lives of the 2224 passengers and crewmembers on board. Input : You are provided with training data of 892 passengers, including information on their names, gender, age, ticket number, cabinet, etc. and survival status. Output : You are required to create a model that can predict the survivability on the remaining passengers based on the provided fields of information. Meaning : The resultant predictive model will provide lessons and recommendations for future marine travel, such as safer ship design, customer service for vulnerable groups, or alerting mechanisms, etc. Analysis : It can be seen that this is a Two-Class Classification problem with the two outputs being NOT_SUVIVAL or SUVIVAL. For a classification problem like this, there are many algorithms you can implement such as Naive Bayes, Decision Tree, Decision Forest \u2026 In the dataset, each line represents a passenger with these fields of information as below: Survival: 0 = No; 1 = Yes Pclass : Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd) Name : Passenger\u2019s name Sex : Sex Age : Age in years SibSp : Number of siblings / spouses aboard the Titanic Parch : Number of parents / children aboard the Titanic Ticket : Ticket number Fare : Passenger fare Cabin : Cabin number Embarked : Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton) Getting started Step 1 : Create a Flow for this problem. Figure 5. A Flow with name \u201cClassification for Titanic\u201d Click on the Flow to enter its working interface. Figure 6. Working Interface for Flow \u201cClassification for Titanic\u201d Step 2 : Importing data For the Titanic problem, data source type is Tabular, so in order to import it, we use Tabular Input Stage. Click Tabular Input Stage, move it to Dataflow Editor, when the Stage Properties window is displayed, we can choose the dataset and the columns to import. - Dataset : Choose \u201cTitanic\u201d - Selected colunns : Choose the columns you\u2019ll use. In this example, the selected columns only include PClass , Sex , Age , SibSp , Parch , Fare . You can choose all the column if you like. - Click again on the Stage and click Run to test if the data has been successfully imported. - After that, a dashboard will be displayed as follow: Step 3: Handling missing data In the Titanic dataset, the Age v\u00e0 Embarked columns have missing values which need to be rectified. To solve missing data in Age column, choose Simple Imputer Transformer Stage in the Transformer package of Scikitsama.ml. Create a link from the Tabular Input Stage to the newly created imputer Stage. Adjust the properties as follow: - Selected column : Choose the column with missing data. - Missing Values : Choose either np.nan ho\u1eb7c None, based on how the dataset encodes missing data. In this case, the encoding is NaN. - Strategy : Choose the missing-data-handling method from the below: - mean: Fill missing data with the column\u2019s average value. - median: Fill missing data with the column\u2019s median value. - most_frequent: Fill missing data with the column\u2019s most frequently occuring value. - constant: Fill missing data with a constant value, as defined in Fill Value text box. - Fill Value: only activated with constant option in Strategy Once setup is finished, click Run . Step 4: Encode d\u1eef li\u1ec7u d\u1ea1ng string: Sex Column contains two values: Male v\u00e0 Female, which can\u2019t be used to put in a ML model, so it needs encoding. Select One Hot Encoder Transformer Stage in Transformer subpackage of Scikitsama.ml. Link them with the previous Stages, select Sex Column and set the properties. After that, click on that Stage and click Run . Besides One Hot Encoder Transformer we could also use other encoding methods in the same sub-package such as Ordinal Encoder Transformer. Step 5: Data Normalization: In our current problem, features are in different value ranges, which will make it difficult for the machine learning model to learn. To prevent that, we need to normalize data. In this case, we will normalize Age column. Select Normalize Transformer in Transformer sub-package of Scikitsama.ml, link it to the previous Stage (One Hot Encoder Transformer). Select colum Age, set the property click again on the Stage and click Run . Step 6: Choosing Classification algorithms: DSSAMA Platform provides Classification Stages as shown below, you can choose one of them to complete the ML pipeline with the preprocessing steps taken before. Each Stage\u2019s properties is set up with default parameters for typical problems, you can change them according to your specific problems. You can build the Flow as shown in the figure below: Execution results with Random Forest Classifier algorithm. Some other machine learning implementations in DSSAMA Examples of Machine Learning algorithm Building Flow Regression Problems Building Flow for Clustering problems ALS Recommendation 1. Algorithm description: Alternating least squares (ALS) is built upon the idea of decomposing an R matrix into two matrices U v\u00e0 V so that . The row size of the unknown matrix is in number and provided as parameters for the algorithm, called hidden factors. Since Matrix Factorization can be used in the context, matrices U v\u00e0 V can be called User Matrix and Item Matrix respectively. Column i of User Matrix is denoted as v and column I of Item Matrix denoted as . R Matrix can be called Ratings Matrix . To find user and item matrix, we need to optimize the cost function below: \u03bb is the regularization coefficient, is the number of items rated by user I and is the number of times item j is rated. Regularization is used to prevent overfitting, called weighted-\u03bb-regularization. Simultaneously optimizing U, V is computationally expensive, instead, the method is to alternating between optimization one matrix and freezing the other and vice versa, repeating until convergence. Matrix R is denoted as (i,j,r) in which: i is the number of rows, j is the number of columns, and r is the value of matrix at position (i, j) 2. Problem description: Use a .csv file with user rating for movies in the MovieLens dataset for ALS implementation Output: A predictive model that can predict the level of rating a user may have for some movies as well as potential audience for a movie. Dataset: a table with 10000 records and 3 columns: - Iduser : id of the rater - Idmovie : id of the movie - Rating : the level of rate 3. Implementation steps: Step 1: Add the .csv file to the data source section including 3 columns iduser, idmovie v\u00e0 rating in your Workspace (do not select ID Column and Label Column): Step 2: Create a new Flowt: Step 3: Create a new flow with one Tabular Input Stage and 1 ALS stage: With Tabular Input Stage: Choose the newly-added dataset and choose all the column. With ALS Stage we need to pay attention to the following parameters: Type of Recommendation: Including 2 options: predicting rating levels from users to certain films (RECOMMENDATION_FOR_USERS) and predicting potential watcher for a film (RECOMMENDATION_FOR_ITEMS). Number of Recommendation: Number of recommendations. User Col: Select userId. Item Col: Select movieId. Rating Col: Select rating. Rank: Number of hidden factors in the model (default 10). Max Iter: Number of training iterations (default 10). Reg Param: param regularization in ALS. Cold Start Strategy: select \u2018drop\u2019. Step 4: Run and see the result: \u2022 Output: The top 10 highest-rate films by users.","title":"Tutorial"},{"location":"EN/en_tutorial/#dssama-tutorial-for-data-projects","text":"In this chapter, we will go in depths on how to use DSSAMA for classification machine learning problems, using the Titanic dataset as the example.","title":"DSSAMA Tutorial for Data Projects"},{"location":"EN/en_tutorial/#1-predict-survival-of-titanic-passengers","text":"Titanic \u2013 the classic case of predictive analysis Problem : On April 15th 1912, the Titanic\u2019s disaster went down as one of the most infamous catastrophes in naval history, the RMS Titanic sank after collided with an iceberg, taking 1502 lives of the 2224 passengers and crewmembers on board. Input : You are provided with training data of 892 passengers, including information on their names, gender, age, ticket number, cabinet, etc. and survival status. Output : You are required to create a model that can predict the survivability on the remaining passengers based on the provided fields of information. Meaning : The resultant predictive model will provide lessons and recommendations for future marine travel, such as safer ship design, customer service for vulnerable groups, or alerting mechanisms, etc. Analysis : It can be seen that this is a Two-Class Classification problem with the two outputs being NOT_SUVIVAL or SUVIVAL. For a classification problem like this, there are many algorithms you can implement such as Naive Bayes, Decision Tree, Decision Forest \u2026 In the dataset, each line represents a passenger with these fields of information as below: Survival: 0 = No; 1 = Yes Pclass : Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd) Name : Passenger\u2019s name Sex : Sex Age : Age in years SibSp : Number of siblings / spouses aboard the Titanic Parch : Number of parents / children aboard the Titanic Ticket : Ticket number Fare : Passenger fare Cabin : Cabin number Embarked : Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)","title":"1. Predict survival of Titanic passengers"},{"location":"EN/en_tutorial/#getting-started","text":"","title":"Getting started"},{"location":"EN/en_tutorial/#step-1-create-a-flow-for-this-problem","text":"Figure 5. A Flow with name \u201cClassification for Titanic\u201d Click on the Flow to enter its working interface. Figure 6. Working Interface for Flow \u201cClassification for Titanic\u201d","title":"Step 1: Create a Flow for this problem."},{"location":"EN/en_tutorial/#step-2-importing-data","text":"For the Titanic problem, data source type is Tabular, so in order to import it, we use Tabular Input Stage. Click Tabular Input Stage, move it to Dataflow Editor, when the Stage Properties window is displayed, we can choose the dataset and the columns to import. - Dataset : Choose \u201cTitanic\u201d - Selected colunns : Choose the columns you\u2019ll use. In this example, the selected columns only include PClass , Sex , Age , SibSp , Parch , Fare . You can choose all the column if you like. - Click again on the Stage and click Run to test if the data has been successfully imported. - After that, a dashboard will be displayed as follow:","title":"Step 2: Importing data"},{"location":"EN/en_tutorial/#step-3-handling-missing-data","text":"In the Titanic dataset, the Age v\u00e0 Embarked columns have missing values which need to be rectified. To solve missing data in Age column, choose Simple Imputer Transformer Stage in the Transformer package of Scikitsama.ml. Create a link from the Tabular Input Stage to the newly created imputer Stage. Adjust the properties as follow: - Selected column : Choose the column with missing data. - Missing Values : Choose either np.nan ho\u1eb7c None, based on how the dataset encodes missing data. In this case, the encoding is NaN. - Strategy : Choose the missing-data-handling method from the below: - mean: Fill missing data with the column\u2019s average value. - median: Fill missing data with the column\u2019s median value. - most_frequent: Fill missing data with the column\u2019s most frequently occuring value. - constant: Fill missing data with a constant value, as defined in Fill Value text box. - Fill Value: only activated with constant option in Strategy Once setup is finished, click Run .","title":"Step 3: Handling missing data"},{"location":"EN/en_tutorial/#step-4-encode-du-lieu-dang-string","text":"Sex Column contains two values: Male v\u00e0 Female, which can\u2019t be used to put in a ML model, so it needs encoding. Select One Hot Encoder Transformer Stage in Transformer subpackage of Scikitsama.ml. Link them with the previous Stages, select Sex Column and set the properties. After that, click on that Stage and click Run . Besides One Hot Encoder Transformer we could also use other encoding methods in the same sub-package such as Ordinal Encoder Transformer.","title":"Step 4: Encode d\u1eef li\u1ec7u d\u1ea1ng string:"},{"location":"EN/en_tutorial/#step-5-data-normalization","text":"In our current problem, features are in different value ranges, which will make it difficult for the machine learning model to learn. To prevent that, we need to normalize data. In this case, we will normalize Age column. Select Normalize Transformer in Transformer sub-package of Scikitsama.ml, link it to the previous Stage (One Hot Encoder Transformer). Select colum Age, set the property click again on the Stage and click Run .","title":"Step 5: Data Normalization:"},{"location":"EN/en_tutorial/#step-6-choosing-classification-algorithms","text":"DSSAMA Platform provides Classification Stages as shown below, you can choose one of them to complete the ML pipeline with the preprocessing steps taken before. Each Stage\u2019s properties is set up with default parameters for typical problems, you can change them according to your specific problems. You can build the Flow as shown in the figure below: Execution results with Random Forest Classifier algorithm. Some other machine learning implementations in DSSAMA Examples of Machine Learning algorithm","title":"Step 6: Choosing Classification algorithms:"},{"location":"EN/en_tutorial/#building-flow-regression-problems","text":"","title":"Building Flow Regression Problems"},{"location":"EN/en_tutorial/#building-flow-for-clustering-problems","text":"","title":"Building Flow for Clustering problems"},{"location":"EN/en_tutorial/#als-recommendation","text":"","title":"ALS Recommendation"},{"location":"EN/en_tutorial/#1-algorithm-description","text":"Alternating least squares (ALS) is built upon the idea of decomposing an R matrix into two matrices U v\u00e0 V so that . The row size of the unknown matrix is in number and provided as parameters for the algorithm, called hidden factors. Since Matrix Factorization can be used in the context, matrices U v\u00e0 V can be called User Matrix and Item Matrix respectively. Column i of User Matrix is denoted as v and column I of Item Matrix denoted as . R Matrix can be called Ratings Matrix . To find user and item matrix, we need to optimize the cost function below: \u03bb is the regularization coefficient, is the number of items rated by user I and is the number of times item j is rated. Regularization is used to prevent overfitting, called weighted-\u03bb-regularization. Simultaneously optimizing U, V is computationally expensive, instead, the method is to alternating between optimization one matrix and freezing the other and vice versa, repeating until convergence. Matrix R is denoted as (i,j,r) in which: i is the number of rows, j is the number of columns, and r is the value of matrix at position (i, j)","title":"1. Algorithm description:"},{"location":"EN/en_tutorial/#2-problem-description","text":"Use a .csv file with user rating for movies in the MovieLens dataset for ALS implementation Output: A predictive model that can predict the level of rating a user may have for some movies as well as potential audience for a movie. Dataset: a table with 10000 records and 3 columns: - Iduser : id of the rater - Idmovie : id of the movie - Rating : the level of rate","title":"2. Problem description:"},{"location":"EN/en_tutorial/#3-implementation-steps","text":"","title":"3. Implementation steps:"},{"location":"EN/en_tutorial/#step-1-add-the-csv-file-to-the-data-source-section-including-3-columns-iduser-idmovie-va-rating-in-your-workspace-do-not-select-id-column-and-label-column","text":"","title":"Step 1: Add the .csv file to the data source section including 3 columns iduser, idmovie v\u00e0 rating in your Workspace (do not select ID Column and Label Column):"},{"location":"EN/en_tutorial/#step-2-create-a-new-flowt","text":"","title":"Step 2: Create a new Flowt:"},{"location":"EN/en_tutorial/#step-3-create-a-new-flow-with-one-tabular-input-stage-and-1-als-stage","text":"With Tabular Input Stage: Choose the newly-added dataset and choose all the column. With ALS Stage we need to pay attention to the following parameters: Type of Recommendation: Including 2 options: predicting rating levels from users to certain films (RECOMMENDATION_FOR_USERS) and predicting potential watcher for a film (RECOMMENDATION_FOR_ITEMS). Number of Recommendation: Number of recommendations. User Col: Select userId. Item Col: Select movieId. Rating Col: Select rating. Rank: Number of hidden factors in the model (default 10). Max Iter: Number of training iterations (default 10). Reg Param: param regularization in ALS. Cold Start Strategy: select \u2018drop\u2019.","title":"Step 3: Create a new flow with one Tabular Input Stage and 1 ALS stage:"},{"location":"EN/en_tutorial/#step-4-run-and-see-the-result","text":"\u2022 Output: The top 10 highest-rate films by users.","title":"Step 4: Run and see the result:"},{"location":"EN/en_workspace/","text":"","title":"Workspace"},{"location":"VN/vn_deep_learning_evaluation/","text":"1. Image Classification Neural Network B\u01b0\u1edbc 1: Ch\u1ecdn Image Input for Classification trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Cifar10 dataset (Link dataset: https://www.kaggle.com/c/cifar-10/data). T\u1eadp dataset n\u00e0y sau khi t\u1ea3i v\u1ec1 \u0111\u00e3 \u0111\u01b0\u1ee3c \u0111i\u1ec1u ch\u1ec9nh \u0111\u1ec3 ph\u00f9 h\u1ee3p v\u1edbi vi\u1ec7c ch\u1ea1y th\u1eed g\u1ed3m 3 l\u1edbp: bird, cat v\u00e0 dog. M\u1ed7i l\u1edbp g\u1ed3m 5000 image \u0111\u1ec3 train v\u00e0 test. \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package tfsama ch\u1ecdn Image Classification Neural Network b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Trong Image Classification Neural Network ng\u01b0\u1eddi d\u00f9ng c\u1ea7n tu\u1ef3 ch\u1ec9nh c\u00e1c parameter cho ph\u00f9 h\u1ee3p v\u1edbi b\u00e0i to\u00e1n c\u1ee7a m\u00ecnh: Layer: d\u00f9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh Network b\u1eb1ng file Json b\u1eb1ng c\u00e1ch click chu\u1ed9t v\u00e0o \u1ede d\u00e2y v\u1edbi t\u1eadp dataset c\u00f3 3 l\u1edbp g\u1ed3m 1500 \u1ea3nh m\u00e0u (RGB) ta s\u1ebd c\u1ea5u h\u00ecnh nh\u01b0 sau: C\u00f2n c\u00e1c tham s\u1ed1 kh\u00e1c \u0111\u1ec3 m\u1eb7c \u0111\u1ecbnh B\u01b0\u1edbc 3: N\u1ed1i Image Input for Classification v\u00e0o stage Image Classification Neural Network B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 2. DenseNet 2.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n Chi ti\u1ebft xem t\u1ea1i: https://arxiv.org/pdf/1608.06993.pdf 2.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Ch\u1ecdn Image Input for Classification trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Cifar10 dataset (Link dataset: https://www.kaggle.com/c/cifar-10/data). T\u1eadp dataset n\u00e0y sau khi t\u1ea3i v\u1ec1 \u0111\u00e3 \u0111\u01b0\u1ee3c \u0111i\u1ec1u ch\u1ec9nh \u0111\u1ec3 ph\u00f9 h\u1ee3p v\u1edbi vi\u1ec7c ch\u1ea1y th\u1eed g\u1ed3m 3 l\u1edbp: bird, cat v\u00e0 dog. M\u1ed7i l\u1edbp g\u1ed3m 5000 image \u0111\u1ec3 train v\u00e0 test. \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Ch\u1ecdn DesenNet Trong package tfsama ch\u1ecdn DenseNet b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Trong DenseNet ng\u01b0\u1eddi d\u00f9ng c\u1ea7n tu\u1ef3 ch\u1ec9nh c\u00e1c parameter cho ph\u00f9 h\u1ee3p v\u1edbi b\u00e0i to\u00e1n c\u1ee7a m\u00ecnh: Architecture: Ch\u1ecdn ki\u1ebfn tr\u00fac m\u1ea1ng DenseNet ph\u00f9 h\u1ee3p. Input_shape: Click v\u00e0o CONFIGURATION d\u00f9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh \u0111\u1ea7u v\u00e0o cho ki\u1ebfn tr\u00fac DenseNet \u0111\u00e3 build s\u1eb5n.\u1ede \u0111\u00e2y v\u1edbi t\u1eadp Cifar dataset(32x32x3) ta c\u1ea5u h\u00ecnh nh\u01b0 sau: Top Layers: Click v\u00e0o CONFIGURATION d\u00f9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh cho l\u1edbp Fully Connected c\u1ee7a Network \u1edf \u0111\u00e2y v\u1edbi t\u1eadp Cifar dataset \u0111\u00e3 nh\u01b0 tr\u00ean g\u1ed3m 3 l\u1edbp ta s\u1ebd c\u00f3 m\u1eabu c\u1ea5u h\u00ecnh tham kh\u1ea3o nh\u01b0 sau: v\u1edbi units trong khoanh tr\u00f2n \u0111\u1ecf l\u00e0 s\u1ed1 l\u01b0\u1ee3ng l\u1edbp c\u1ea7n ph\u00e2n l\u1edbp. C\u00e1c tham s\u1ed1 c\u00f2n l\u1ea1i \u0111\u1ec3 m\u1eb7c \u0111\u1ecbnh ho\u1eb7c tu\u1ef3 ng\u01b0\u1eddi d\u00f9ng config B\u01b0\u1edbc 3: N\u1ed1i Image Input for Classification v\u00e0o stage DenseNet B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 3. MobileNet 3.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n Chi ti\u1ebft xe t\u1ea1i: https://arxiv.org/pdf/1704.04861.pdf 3.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Ch\u1ecdn Image Input for Classification trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Cifar10 dataset (Link dataset: https://www.kaggle.com/c/cifar-10/data). T\u1eadp dataset n\u00e0y sau khi t\u1ea3i v\u1ec1 \u0111\u00e3 \u0111\u01b0\u1ee3c \u0111i\u1ec1u ch\u1ec9nh \u0111\u1ec3 ph\u00f9 h\u1ee3p v\u1edbi vi\u1ec7c ch\u1ea1y th\u1eed g\u1ed3m 3 l\u1edbp: bird, cat v\u00e0 dog. M\u1ed7i l\u1edbp g\u1ed3m 5000 image \u0111\u1ec3 train v\u00e0 test. \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Ch\u1ecdn MobileNet Trong package tfsama ch\u1ecdn MobileNet b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Trong MobileNet ng\u01b0\u1eddi d\u00f9ng c\u1ea7n tu\u1ef3 ch\u1ec9nh c\u00e1c parameter cho ph\u00f9 h\u1ee3p v\u1edbi b\u00e0i to\u00e1n c\u1ee7a m\u00ecnh: Architecture: Ch\u1ecdn ki\u1ebfn tr\u00fac m\u1ea1ng MobileNet ph\u00f9 h\u1ee3p. Input_shape: Click v\u00e0o CONFIGURATION d\u00f9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh \u0111\u1ea7u v\u00e0o cho ki\u1ebfn tr\u00fac MobileNet \u0111\u00e3 build s\u1eb5n.\u1ede \u0111\u00e2y v\u1edbi t\u1eadp Cifar dataset(32x32x3) ta c\u1ea5u h\u00ecnh nh\u01b0 sau: Top Layers: Click v\u00e0o CONFIGURATION d\u00f9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh cho l\u1edbp Fully Connected c\u1ee7a Network \u1edf \u0111\u00e2y v\u1edbi t\u1eadp Cifar dataset \u0111\u00e3 nh\u01b0 tr\u00ean g\u1ed3m 3 l\u1edbp ta s\u1ebd c\u00f3 m\u1eabu c\u1ea5u h\u00ecnh tham kh\u1ea3o nh\u01b0 sau: v\u1edbi units trong khoanh tr\u00f2n \u0111\u1ecf l\u00e0 s\u1ed1 l\u01b0\u1ee3ng l\u1edbp c\u1ea7n ph\u00e2n l\u1edbp. \u2022 C\u00e1c tham s\u1ed1 c\u00f2n l\u1ea1i \u0111\u1ec3 m\u1eb7c \u0111\u1ecbnh ho\u1eb7c tu\u1ef3 ng\u01b0\u1eddi d\u00f9ng config B\u01b0\u1edbc 3: N\u1ed1i Image Input for Classification v\u00e0o stage MobileNet B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 6. TabularData Classification Neural Network B\u01b0\u1edbc 1: Ch\u1ecdn stage input Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Iris dataset (Link dataset: https://www.kaggle.com/arshid/iris-flower-dataset). T\u1eadp dataset n\u00e0y \u0111\u01b0\u1ee3c x\u1eed l\u00fd g\u1ed3m 6 c\u1ed9t. C\u1ed9t th\u1ee9 nh\u1ea5t l\u00e0 index, c\u1ed9t th\u1ee9 2,3,4, 5 l\u00e0 c\u00e1c \u0111\u1eb7c tr\u0103ng c\u1ee7a hoa g\u1ed3m: Petal Length, Petal Width, Sepal Length, Sepal width. C\u1ed9t th\u1ee9 6 l\u00e0 label g\u1ed3m 3 l\u1edbp t\u01b0\u01a1ng \u1ee9ng v\u1edbi 3 lo\u1ea1i hoa Iris. Selected column: Petal Length, Petal Width, Sepal Length, Sepal width - \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Ch\u1ecdn TabularData Classification Neural Network Trong package tfsama ch\u1ecdn TabularData Classification Neural Network b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Trong TabularData Classification Neural Network ng\u01b0\u1eddi d\u00f9ng c\u1ea7n tu\u1ef3 ch\u1ec9nh c\u00e1c parameter cho ph\u00f9 h\u1ee3p v\u1edbi b\u00e0i to\u00e1n c\u1ee7a m\u00ecnh: Layer: d\u00f9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh Network b\u1eb1ng file Json b\u1eb1ng c\u00e1ch click chu\u1ed9t v\u00e0o \u1ede \u0111\u00e2y th\u1ea5y t\u1eadp dataset c\u00f3 4 features do \u0111\u00f3 input_shape: 4 c\u00f2n c\u00e1c tham s\u1ed1 c\u00f2n l\u1ea1i \u0111\u1ec3 m\u1eb7c \u0111\u1ecbnh. C\u00e1c tham s\u1ed1 c\u00f2n l\u1ea1i ng\u01b0\u1eddi d\u00f9ng tu\u1ef3 ch\u1ec9nh \u0111\u1ec3 ph\u00f9 h\u1ee3p b\u00e0i to\u00e1n. B\u01b0\u1edbc 3: N\u1ed1i Tabular Input v\u00e0o stage TabularData Classification Neural Network B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 7. TimeSeries Forecasting Neural Network B\u01b0\u1edbc 1: Ch\u1ecdn stage Input Ch\u1ecdn Timeseries Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Google Stock dataset (Link dataset: https://www.kaggle.com/medharawat/google-stock-price). T\u1eadp dataset n\u00e0y g\u1ed3m 6 c\u1ed9t: Date, Open, High, Low, Close, Volume Time steps column: Date Selected column: Open, High, Low, Close, Volume \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Ch\u1ecdn Vectorize Trasform Trong package scikitsama ch\u1ecdn Vectorize Trasform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Trong Vectorize Trasform c\u00f3 parameter Vectorize Column \u0111\u1ec3 ch\u1ecdn c\u00e1c c\u1ed9t c\u1ea7n vector ho\u00e1.\u1ede \u0111\u00e2y ta ch\u1ecdn: Open, High, Low, Close B\u01b0\u1edbc 3: N\u1ed1i Timeseries Input v\u00e0o stage Vectorize Trasform. B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Ch\u1ecdn TimeSeries Forecasting Neural Network Trong package tfsama ch\u1ecdn TimeSeries Forecasting Neural Network b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Trong TimeSeries Forecasting Neural Network ng\u01b0\u1eddi d\u00f9ng c\u1ea7n tu\u1ef3 ch\u1ec9nh c\u00e1c parameter cho ph\u00f9 h\u1ee3p v\u1edbi b\u00e0i to\u00e1n c\u1ee7a m\u00ecnh: Features Column : Ch\u00ednh l\u00e0 c\u00e1c c\u1ed9t v\u1eeba \u0111\u01b0\u1ee3c Vectorize trong stage Vectorize Trasform Target Column : Ch\u00ednh l\u00e0 c\u00e1c c\u1ed9t v\u1eeba \u0111\u01b0\u1ee3c Vectorize trong stage Vectorize Trasform Layer : d\u00f9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh Network b\u1eb1ng file Json b\u1eb1ng c\u00e1ch click chu\u1ed9t v\u00e0o \u1ede \u0111\u00e2y th\u1ea5y trong Vectorize Trasform ta c\u00f3 4 feature: Open, High, Low, Close. \u0110\u1ed3ng th\u1eddi ch\u1ecdn Window size = 10 c\u00f2n c\u00e1c tham s\u1ed1 kh\u00e1c \u0111\u1ec3 m\u1eb7c \u0111\u1ecbnh n\u00ean ta c\u00f3 config nh\u01b0 sau: Window size : tham s\u1ed1 n\u00e0y c\u0169ng ph\u1ea3i \u0111\u1eb7t t\u01b0\u01a1ng \u1ee9ng v\u1edbi Window size trong file config l\u00e0: 10 B\u01b0\u1edbc 6: N\u1ed1i Vectorize Trasform v\u00e0o stage TimeSeries Forecasting Neural Network . TimeSeries Forecasting Neural Network s\u1ebd d\u00f9ng c\u00e1c c\u1ed9t \u0111\u01b0\u1ee3c Vectorize \u0111\u1ec3 d\u1ef1 \u0111o\u00e1n ra c\u00e1c c\u1ed9t Target Column B\u01b0\u1edbc 7: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3","title":"Deep Learning Evaluation"},{"location":"VN/vn_deep_learning_evaluation/#1-image-classification-neural-network","text":"","title":"1.   Image Classification Neural Network"},{"location":"VN/vn_deep_learning_evaluation/#buoc-1-chon-image-input-for-classification-trong-inputphan-parameter","text":"Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Cifar10 dataset (Link dataset: https://www.kaggle.com/c/cifar-10/data). T\u1eadp dataset n\u00e0y sau khi t\u1ea3i v\u1ec1 \u0111\u00e3 \u0111\u01b0\u1ee3c \u0111i\u1ec1u ch\u1ec9nh \u0111\u1ec3 ph\u00f9 h\u1ee3p v\u1edbi vi\u1ec7c ch\u1ea1y th\u1eed g\u1ed3m 3 l\u1edbp: bird, cat v\u00e0 dog. M\u1ed7i l\u1edbp g\u1ed3m 5000 image \u0111\u1ec3 train v\u00e0 test. \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o:","title":"B\u01b0\u1edbc 1: Ch\u1ecdn Image Input for Classification trong Input.Ph\u1ea7n parameter:"},{"location":"VN/vn_deep_learning_evaluation/#buoc-2-trong-package-tfsama-chon-image","text":"Classification Neural Network b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Trong Image Classification Neural Network ng\u01b0\u1eddi d\u00f9ng c\u1ea7n tu\u1ef3 ch\u1ec9nh c\u00e1c parameter cho ph\u00f9 h\u1ee3p v\u1edbi b\u00e0i to\u00e1n c\u1ee7a m\u00ecnh: Layer: d\u00f9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh Network b\u1eb1ng file Json b\u1eb1ng c\u00e1ch click chu\u1ed9t v\u00e0o \u1ede d\u00e2y v\u1edbi t\u1eadp dataset c\u00f3 3 l\u1edbp g\u1ed3m 1500 \u1ea3nh m\u00e0u (RGB) ta s\u1ebd c\u1ea5u h\u00ecnh nh\u01b0 sau: C\u00f2n c\u00e1c tham s\u1ed1 kh\u00e1c \u0111\u1ec3 m\u1eb7c \u0111\u1ecbnh","title":"B\u01b0\u1edbc 2: Trong package tfsama  ch\u1ecdn Image"},{"location":"VN/vn_deep_learning_evaluation/#buoc-3-noi-image-input-for-classification-vao-stage-image-classification-neural-network","text":"","title":"B\u01b0\u1edbc 3: N\u1ed1i Image Input for Classification v\u00e0o stage Image Classification Neural Network"},{"location":"VN/vn_deep_learning_evaluation/#buoc-4-an-run-e-hien-thi-ra-ket-qua","text":"","title":"B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3"},{"location":"VN/vn_deep_learning_evaluation/#2-densenet","text":"","title":"2.   DenseNet"},{"location":"VN/vn_deep_learning_evaluation/#21-mo-ta-thuat-toan","text":"Chi ti\u1ebft xem t\u1ea1i: https://arxiv.org/pdf/1608.06993.pdf","title":"2.1.    M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_deep_learning_evaluation/#22-cac-buoc-thuc-hien","text":"","title":"2.2.    C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_deep_learning_evaluation/#buoc-1-chon-image-input-for-classification-trong-inputphan-parameter_1","text":"Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Cifar10 dataset (Link dataset: https://www.kaggle.com/c/cifar-10/data). T\u1eadp dataset n\u00e0y sau khi t\u1ea3i v\u1ec1 \u0111\u00e3 \u0111\u01b0\u1ee3c \u0111i\u1ec1u ch\u1ec9nh \u0111\u1ec3 ph\u00f9 h\u1ee3p v\u1edbi vi\u1ec7c ch\u1ea1y th\u1eed g\u1ed3m 3 l\u1edbp: bird, cat v\u00e0 dog. M\u1ed7i l\u1edbp g\u1ed3m 5000 image \u0111\u1ec3 train v\u00e0 test. \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o:","title":"B\u01b0\u1edbc 1: Ch\u1ecdn Image Input for Classification trong Input.Ph\u1ea7n parameter:"},{"location":"VN/vn_deep_learning_evaluation/#buoc-2-chon-desennet","text":"Trong package tfsama ch\u1ecdn DenseNet b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Trong DenseNet ng\u01b0\u1eddi d\u00f9ng c\u1ea7n tu\u1ef3 ch\u1ec9nh c\u00e1c parameter cho ph\u00f9 h\u1ee3p v\u1edbi b\u00e0i to\u00e1n c\u1ee7a m\u00ecnh: Architecture: Ch\u1ecdn ki\u1ebfn tr\u00fac m\u1ea1ng DenseNet ph\u00f9 h\u1ee3p. Input_shape: Click v\u00e0o CONFIGURATION d\u00f9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh \u0111\u1ea7u v\u00e0o cho ki\u1ebfn tr\u00fac DenseNet \u0111\u00e3 build s\u1eb5n.\u1ede \u0111\u00e2y v\u1edbi t\u1eadp Cifar dataset(32x32x3) ta c\u1ea5u h\u00ecnh nh\u01b0 sau: Top Layers: Click v\u00e0o CONFIGURATION d\u00f9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh cho l\u1edbp Fully Connected c\u1ee7a Network \u1edf \u0111\u00e2y v\u1edbi t\u1eadp Cifar dataset \u0111\u00e3 nh\u01b0 tr\u00ean g\u1ed3m 3 l\u1edbp ta s\u1ebd c\u00f3 m\u1eabu c\u1ea5u h\u00ecnh tham kh\u1ea3o nh\u01b0 sau: v\u1edbi units trong khoanh tr\u00f2n \u0111\u1ecf l\u00e0 s\u1ed1 l\u01b0\u1ee3ng l\u1edbp c\u1ea7n ph\u00e2n l\u1edbp. C\u00e1c tham s\u1ed1 c\u00f2n l\u1ea1i \u0111\u1ec3 m\u1eb7c \u0111\u1ecbnh ho\u1eb7c tu\u1ef3 ng\u01b0\u1eddi d\u00f9ng config","title":"B\u01b0\u1edbc 2: Ch\u1ecdn DesenNet"},{"location":"VN/vn_deep_learning_evaluation/#buoc-3-noi-image-input-for-classification-vao-stage-densenet","text":"","title":"B\u01b0\u1edbc 3: N\u1ed1i Image Input for Classification v\u00e0o stage DenseNet"},{"location":"VN/vn_deep_learning_evaluation/#buoc-4-an-run-e-hien-thi-ra-ket-qua_1","text":"","title":"B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3"},{"location":"VN/vn_deep_learning_evaluation/#3-mobilenet","text":"","title":"3.   MobileNet"},{"location":"VN/vn_deep_learning_evaluation/#31-mo-ta-thuat-toan","text":"Chi ti\u1ebft xe t\u1ea1i: https://arxiv.org/pdf/1704.04861.pdf","title":"3.1.    M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_deep_learning_evaluation/#32-cac-buoc-thuc-hien","text":"","title":"3.2.    C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_deep_learning_evaluation/#buoc-1-chon-image-input-for-classification-trong-inputphan-parameter_2","text":"Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Cifar10 dataset (Link dataset: https://www.kaggle.com/c/cifar-10/data). T\u1eadp dataset n\u00e0y sau khi t\u1ea3i v\u1ec1 \u0111\u00e3 \u0111\u01b0\u1ee3c \u0111i\u1ec1u ch\u1ec9nh \u0111\u1ec3 ph\u00f9 h\u1ee3p v\u1edbi vi\u1ec7c ch\u1ea1y th\u1eed g\u1ed3m 3 l\u1edbp: bird, cat v\u00e0 dog. M\u1ed7i l\u1edbp g\u1ed3m 5000 image \u0111\u1ec3 train v\u00e0 test. \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o:","title":"B\u01b0\u1edbc 1: Ch\u1ecdn Image Input for Classification trong Input.Ph\u1ea7n parameter:"},{"location":"VN/vn_deep_learning_evaluation/#buoc-2-chon-mobilenet","text":"Trong package tfsama ch\u1ecdn MobileNet b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Trong MobileNet ng\u01b0\u1eddi d\u00f9ng c\u1ea7n tu\u1ef3 ch\u1ec9nh c\u00e1c parameter cho ph\u00f9 h\u1ee3p v\u1edbi b\u00e0i to\u00e1n c\u1ee7a m\u00ecnh: Architecture: Ch\u1ecdn ki\u1ebfn tr\u00fac m\u1ea1ng MobileNet ph\u00f9 h\u1ee3p. Input_shape: Click v\u00e0o CONFIGURATION d\u00f9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh \u0111\u1ea7u v\u00e0o cho ki\u1ebfn tr\u00fac MobileNet \u0111\u00e3 build s\u1eb5n.\u1ede \u0111\u00e2y v\u1edbi t\u1eadp Cifar dataset(32x32x3) ta c\u1ea5u h\u00ecnh nh\u01b0 sau: Top Layers: Click v\u00e0o CONFIGURATION d\u00f9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh cho l\u1edbp Fully Connected c\u1ee7a Network \u1edf \u0111\u00e2y v\u1edbi t\u1eadp Cifar dataset \u0111\u00e3 nh\u01b0 tr\u00ean g\u1ed3m 3 l\u1edbp ta s\u1ebd c\u00f3 m\u1eabu c\u1ea5u h\u00ecnh tham kh\u1ea3o nh\u01b0 sau: v\u1edbi units trong khoanh tr\u00f2n \u0111\u1ecf l\u00e0 s\u1ed1 l\u01b0\u1ee3ng l\u1edbp c\u1ea7n ph\u00e2n l\u1edbp. \u2022 C\u00e1c tham s\u1ed1 c\u00f2n l\u1ea1i \u0111\u1ec3 m\u1eb7c \u0111\u1ecbnh ho\u1eb7c tu\u1ef3 ng\u01b0\u1eddi d\u00f9ng config","title":"B\u01b0\u1edbc 2: Ch\u1ecdn MobileNet"},{"location":"VN/vn_deep_learning_evaluation/#buoc-3-noi-image-input-for-classification-vao-stage-mobilenet","text":"","title":"B\u01b0\u1edbc 3: N\u1ed1i Image Input for Classification v\u00e0o stage MobileNet"},{"location":"VN/vn_deep_learning_evaluation/#buoc-4-an-run-e-hien-thi-ra-ket-qua_2","text":"","title":"B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3"},{"location":"VN/vn_deep_learning_evaluation/#6-tabulardata-classification-neural-network","text":"","title":"6.   TabularData Classification Neural Network"},{"location":"VN/vn_deep_learning_evaluation/#buoc-1-chon-stage-input","text":"Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Iris dataset (Link dataset: https://www.kaggle.com/arshid/iris-flower-dataset). T\u1eadp dataset n\u00e0y \u0111\u01b0\u1ee3c x\u1eed l\u00fd g\u1ed3m 6 c\u1ed9t. C\u1ed9t th\u1ee9 nh\u1ea5t l\u00e0 index, c\u1ed9t th\u1ee9 2,3,4, 5 l\u00e0 c\u00e1c \u0111\u1eb7c tr\u0103ng c\u1ee7a hoa g\u1ed3m: Petal Length, Petal Width, Sepal Length, Sepal width. C\u1ed9t th\u1ee9 6 l\u00e0 label g\u1ed3m 3 l\u1edbp t\u01b0\u01a1ng \u1ee9ng v\u1edbi 3 lo\u1ea1i hoa Iris. Selected column: Petal Length, Petal Width, Sepal Length, Sepal width - \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o:","title":"B\u01b0\u1edbc 1: Ch\u1ecdn stage input"},{"location":"VN/vn_deep_learning_evaluation/#buoc-2-chon-tabulardata-classification-neural-network","text":"Trong package tfsama ch\u1ecdn TabularData Classification Neural Network b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Trong TabularData Classification Neural Network ng\u01b0\u1eddi d\u00f9ng c\u1ea7n tu\u1ef3 ch\u1ec9nh c\u00e1c parameter cho ph\u00f9 h\u1ee3p v\u1edbi b\u00e0i to\u00e1n c\u1ee7a m\u00ecnh: Layer: d\u00f9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh Network b\u1eb1ng file Json b\u1eb1ng c\u00e1ch click chu\u1ed9t v\u00e0o \u1ede \u0111\u00e2y th\u1ea5y t\u1eadp dataset c\u00f3 4 features do \u0111\u00f3 input_shape: 4 c\u00f2n c\u00e1c tham s\u1ed1 c\u00f2n l\u1ea1i \u0111\u1ec3 m\u1eb7c \u0111\u1ecbnh. C\u00e1c tham s\u1ed1 c\u00f2n l\u1ea1i ng\u01b0\u1eddi d\u00f9ng tu\u1ef3 ch\u1ec9nh \u0111\u1ec3 ph\u00f9 h\u1ee3p b\u00e0i to\u00e1n.","title":"B\u01b0\u1edbc 2: Ch\u1ecdn TabularData Classification Neural Network"},{"location":"VN/vn_deep_learning_evaluation/#buoc-3-noi-tabular-input-vao-stage-tabulardata-classification-neural-network","text":"","title":"B\u01b0\u1edbc 3: N\u1ed1i Tabular Input v\u00e0o stage TabularData Classification Neural Network"},{"location":"VN/vn_deep_learning_evaluation/#buoc-4-an-run-e-hien-thi-ra-ket-qua_3","text":"","title":"B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3"},{"location":"VN/vn_deep_learning_evaluation/#7-timeseries-forecasting-neural-network","text":"","title":"7.   TimeSeries Forecasting Neural Network"},{"location":"VN/vn_deep_learning_evaluation/#buoc-1-chon-stage-input_1","text":"Ch\u1ecdn Timeseries Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Google Stock dataset (Link dataset: https://www.kaggle.com/medharawat/google-stock-price). T\u1eadp dataset n\u00e0y g\u1ed3m 6 c\u1ed9t: Date, Open, High, Low, Close, Volume Time steps column: Date Selected column: Open, High, Low, Close, Volume \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o:","title":"B\u01b0\u1edbc 1: Ch\u1ecdn stage Input"},{"location":"VN/vn_deep_learning_evaluation/#buoc-2-chon-vectorize-trasform","text":"Trong package scikitsama ch\u1ecdn Vectorize Trasform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Trong Vectorize Trasform c\u00f3 parameter Vectorize Column \u0111\u1ec3 ch\u1ecdn c\u00e1c c\u1ed9t c\u1ea7n vector ho\u00e1.\u1ede \u0111\u00e2y ta ch\u1ecdn: Open, High, Low, Close","title":"B\u01b0\u1edbc 2: Ch\u1ecdn Vectorize Trasform"},{"location":"VN/vn_deep_learning_evaluation/#buoc-3-noi-timeseries-input-vao-stage-vectorize-trasform","text":"","title":"B\u01b0\u1edbc 3: N\u1ed1i Timeseries Input v\u00e0o stage Vectorize Trasform."},{"location":"VN/vn_deep_learning_evaluation/#buoc-4-an-run-e-hien-thi-ra-ket-qua_4","text":"","title":"B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3"},{"location":"VN/vn_deep_learning_evaluation/#buoc-5-chon-timeseries-forecasting-neural-network","text":"Trong package tfsama ch\u1ecdn TimeSeries Forecasting Neural Network b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Trong TimeSeries Forecasting Neural Network ng\u01b0\u1eddi d\u00f9ng c\u1ea7n tu\u1ef3 ch\u1ec9nh c\u00e1c parameter cho ph\u00f9 h\u1ee3p v\u1edbi b\u00e0i to\u00e1n c\u1ee7a m\u00ecnh: Features Column : Ch\u00ednh l\u00e0 c\u00e1c c\u1ed9t v\u1eeba \u0111\u01b0\u1ee3c Vectorize trong stage Vectorize Trasform Target Column : Ch\u00ednh l\u00e0 c\u00e1c c\u1ed9t v\u1eeba \u0111\u01b0\u1ee3c Vectorize trong stage Vectorize Trasform Layer : d\u00f9ng \u0111\u1ec3 c\u1ea5u h\u00ecnh Network b\u1eb1ng file Json b\u1eb1ng c\u00e1ch click chu\u1ed9t v\u00e0o \u1ede \u0111\u00e2y th\u1ea5y trong Vectorize Trasform ta c\u00f3 4 feature: Open, High, Low, Close. \u0110\u1ed3ng th\u1eddi ch\u1ecdn Window size = 10 c\u00f2n c\u00e1c tham s\u1ed1 kh\u00e1c \u0111\u1ec3 m\u1eb7c \u0111\u1ecbnh n\u00ean ta c\u00f3 config nh\u01b0 sau: Window size : tham s\u1ed1 n\u00e0y c\u0169ng ph\u1ea3i \u0111\u1eb7t t\u01b0\u01a1ng \u1ee9ng v\u1edbi Window size trong file config l\u00e0: 10","title":"B\u01b0\u1edbc 5: Ch\u1ecdn TimeSeries Forecasting Neural Network"},{"location":"VN/vn_deep_learning_evaluation/#buoc-6-noi-vectorize-trasform-vao-stage-timeseries-forecasting-neural-network","text":"TimeSeries Forecasting Neural Network s\u1ebd d\u00f9ng c\u00e1c c\u1ed9t \u0111\u01b0\u1ee3c Vectorize \u0111\u1ec3 d\u1ef1 \u0111o\u00e1n ra c\u00e1c c\u1ed9t Target Column","title":"B\u01b0\u1edbc 6: N\u1ed1i Vectorize Trasform v\u00e0o stage TimeSeries Forecasting Neural Network."},{"location":"VN/vn_deep_learning_evaluation/#buoc-7-an-run-e-hien-thi-ra-ket-qua","text":"","title":"B\u01b0\u1edbc 7: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3"},{"location":"VN/vn_deploy/","text":"Deploy m\u00f4 h\u00ecnh Machine Learning B\u01b0\u1edbc 1 : Run v\u00e0 deploy Flow tr\u00ean DSSAMA Platform Import d\u1eef li\u1ec7u : \u0110\u01b0a Stage Input v\u00e0o Dataflow Editor. T\u1ea1o c\u00e1c FLow cho b\u00e0i to\u00e1n ph\u00e2n t\u00edch. Click Run Stage. Sau khi ch\u1ea1y Flow xong, \u0111\u1ea3m b\u1ea3o t\u1ea5t c\u1ea3 c\u00e1c Stage l\u00e0 estimator Click n\u00fat Deploy tr\u00ean thanh c\u00f4ng c\u1ee5 B\u01b0\u1edbc 2: S\u1eed d\u1ee5ng Postman \u0111\u1ec3 g\u1ecdi \u0111\u1ebfn Flow \u0111\u00e3 deploy C\u00e0i \u0111\u1eb7t Postman Sau khi deployed th\u00e0nh c\u00f4ng, \u0111\u1ec3 s\u1eed d\u1ee5ng flow \u0111\u00e3 deployed th\u1ef1c hi\u1ec7n nh\u01b0 sau: 1. Call request URL : API /releasedFlows \u0111\u1ec3 l\u1ea5y \u0111\u01b0\u1ee3c danh s\u00e1ch c\u00e1c flows \u0111\u00e3 deployed. 1. Call API /release/ping/<flow_id> \u0111\u1ec3 l\u1ea5y th\u00f4ng tin m\u00f4 t\u1ea3 c\u1ee7a flow \u0111\u00e3 deployed theo <flow_id> . <flow_id> c\u1ee5 th\u1ec3 c\u00f3 th\u1ec3 l\u1ea5y tr\u00ean thanh \u0111\u1ecba ch\u1ec9 c\u1ee7a DSSAMA platform sau khi click n\u00fat Deploy Call API /released/runflow/<flow_id> \u0111\u1ec3 run flow \u0111\u00e3 \u0111\u01b0\u1ee3c deployed. Truy\u1ec1n v\u00e0o request Request body: \"datasets\": [ { \"inputStageId\": <l\u1ea5y t\u1eeb k\u1ebft qu\u1ea3 c\u1ee7a m\u1ee5c 2>, \"idCol\": <c\u1ed9t id>, \"labelCol\": <c\u1ed9t nh\u00e3n>, \"dataType\": <ki\u1ec3u d\u1eef li\u1ec7u>, \"data\": <m\u1ea3ng d\u1eef li\u1ec7u> } ] } Sau khi send request, k\u1ebft qu\u1ea3 nh\u1eadn \u0111\u01b0\u1ee3c d\u01b0\u1edbi dang JSON nh\u01b0 sau:","title":"Deploy"},{"location":"VN/vn_deploy/#deploy-mo-hinh-machine-learning","text":"B\u01b0\u1edbc 1 : Run v\u00e0 deploy Flow tr\u00ean DSSAMA Platform Import d\u1eef li\u1ec7u : \u0110\u01b0a Stage Input v\u00e0o Dataflow Editor. T\u1ea1o c\u00e1c FLow cho b\u00e0i to\u00e1n ph\u00e2n t\u00edch. Click Run Stage. Sau khi ch\u1ea1y Flow xong, \u0111\u1ea3m b\u1ea3o t\u1ea5t c\u1ea3 c\u00e1c Stage l\u00e0 estimator Click n\u00fat Deploy tr\u00ean thanh c\u00f4ng c\u1ee5 B\u01b0\u1edbc 2: S\u1eed d\u1ee5ng Postman \u0111\u1ec3 g\u1ecdi \u0111\u1ebfn Flow \u0111\u00e3 deploy C\u00e0i \u0111\u1eb7t Postman Sau khi deployed th\u00e0nh c\u00f4ng, \u0111\u1ec3 s\u1eed d\u1ee5ng flow \u0111\u00e3 deployed th\u1ef1c hi\u1ec7n nh\u01b0 sau: 1. Call request URL : API /releasedFlows \u0111\u1ec3 l\u1ea5y \u0111\u01b0\u1ee3c danh s\u00e1ch c\u00e1c flows \u0111\u00e3 deployed. 1. Call API /release/ping/<flow_id> \u0111\u1ec3 l\u1ea5y th\u00f4ng tin m\u00f4 t\u1ea3 c\u1ee7a flow \u0111\u00e3 deployed theo <flow_id> . <flow_id> c\u1ee5 th\u1ec3 c\u00f3 th\u1ec3 l\u1ea5y tr\u00ean thanh \u0111\u1ecba ch\u1ec9 c\u1ee7a DSSAMA platform sau khi click n\u00fat Deploy Call API /released/runflow/<flow_id> \u0111\u1ec3 run flow \u0111\u00e3 \u0111\u01b0\u1ee3c deployed. Truy\u1ec1n v\u00e0o request Request body: \"datasets\": [ { \"inputStageId\": <l\u1ea5y t\u1eeb k\u1ebft qu\u1ea3 c\u1ee7a m\u1ee5c 2>, \"idCol\": <c\u1ed9t id>, \"labelCol\": <c\u1ed9t nh\u00e3n>, \"dataType\": <ki\u1ec3u d\u1eef li\u1ec7u>, \"data\": <m\u1ea3ng d\u1eef li\u1ec7u> } ] } Sau khi send request, k\u1ebft qu\u1ea3 nh\u1eadn \u0111\u01b0\u1ee3c d\u01b0\u1edbi dang JSON nh\u01b0 sau:","title":"Deploy m\u00f4 h\u00ecnh Machine Learning"},{"location":"VN/vn_flow/","text":"","title":"Flow"},{"location":"VN/vn_getting_started/","text":"GETTING STARTED NG\u01af\u1edcI D\u00d9NG M\u1edaI - T\u1ea0O T\u00c0I KHO\u1ea2N V\u1edbi ng\u01b0\u1eddi d\u00f9ng l\u1ea7n \u0111\u1ea7u s\u1eed d\u1ee5ng, vi\u1ec7c \u0111\u1ea7u ti\u00ean c\u1ea7n l\u00e0m l\u00e0 \u0111\u0103ng k\u00fd t\u00e0i kho\u1ea3n DSSAMA t\u1ea1i DSSAMA N\u1ebfu ch\u01b0a c\u00f3 t\u00e0i kho\u1ea3n DSSAMA, h\u00e3y click v\u00e0o Sign Up \u0110i\u1ec1n \u0111\u1ea7y \u0111\u1ee7 c\u00e1c th\u00f4ng tin v\u00e0 click n\u00fat Sign up. \u0110\u0103ng nh\u1eadp v\u00e0o email \u0111\u0103ng k\u00fd t\u00e0i kho\u1ea3n \u0111\u1ec3 l\u1ea5y m\u00e3 token. Copy m\u00e3 token \u0111\u01b0\u1ee3c g\u1eedi v\u00e0o mail \u0111\u0103ng k\u00fd v\u00e0 paste v\u00e0o Token code v\u00e0 click Confirm . Khi \u0111\u00f3, ng\u01b0\u1eddi d\u00f9ng \u0111\u00e3 ho\u00e0n th\u00e0nh c\u00e1c b\u01b0\u1edbc \u0111\u0103ng k\u00fd t\u00e0i kho\u1ea3n v\u00e0 c\u00f3 th\u1ec3 d\u00f9ng t\u00e0i kho\u1ea3n \u0111\u00f3 \u0111\u0103ng nh\u1eadp. Ng\u01b0\u1eddi d\u00f9ng l\u01b0u \u00fd th\u1eddi gian nh\u1eadp m\u00e3 code. \u0110\u0102NG NH\u1eacP \u0110\u0103ng nh\u1eadp v\u00e0o h\u1ec7 th\u1ed1ng DSSAMA tr\u00ean tr\u00ecnh duy\u1ec7t nh\u1eadp email ng\u01b0\u1eddi d\u00f9ng \u0111\u00e3 \u0111\u0103ng k\u00fd tr\u01b0\u1edbc \u0111\u00f3 v\u00e0 password. Sau khi \u0111\u0103ng nh\u1eadp v\u00e0o h\u1ec7 th\u1ed1ng, giao di\u1ec7n l\u00e0m vi\u1ec7c c\u1ee7a h\u1ec7 th\u1ed1ng DSSAMA nh\u01b0 sau. 2. WORKSPACE Sau khi \u0111\u0103ng nh\u1eadp v\u00e0o h\u1ec7 th\u1ed1ng DSSAMA, ng\u01b0\u1eddi d\u00f9ng c\u1ea7n t\u1ea1o kh\u00f4ng gian l\u00e0m vi\u1ec7c \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi d\u1eef li\u1ec7u tr\u00ean \u0111\u00f3. M\u1ed7i t\u00e0i kho\u1ea3n \u0111\u01b0\u1ee3c cung c\u1ea5p m\u1ed9t default workspace server mi\u1ec5n ph\u00ed v\u00e0 b\u1ea3o m\u1eadt.N\u1ebfu mu\u1ed1n t\u1ea1o h\u01a1n m\u1ed9t Workspace, ng\u01b0\u1eddi d\u00f9ng n\u00ean d\u00f9ng th\u00eam workspace server. M\u1ed7i t\u00e0i kho\u1ea3n \u0111\u01b0\u1ee3c cung c\u1ea5p m\u1ed9t default workspace server mi\u1ec5n ph\u00ed v\u00e0 b\u1ea3o m\u1eadt.N\u1ebfu mu\u1ed1n t\u1ea1o h\u01a1n m\u1ed9t Workspace, ng\u01b0\u1eddi d\u00f9ng n\u00ean d\u00f9ng th\u00eam workspace server. Sau khi click \"Save\" Workpsace \u0111\u01b0\u1ee3c t\u1ea1o, \u0111\u00f3 l\u00e0 kh\u00f4ng gian m\u00e0 ch\u00fang ta s\u1ebd l\u00e0m vi\u1ec7c tr\u00ean \u0111\u00f3. 3. WORKSPACE SERVER 4. PROJECT Project trong DSSAMA l\u00e0 n\u01a1i qu\u1ea3n l\u00fd, l\u01b0u tr\u1eef c\u00e1c Flow (lu\u1ed3ng c\u00f4ng vi\u1ec7c) c\u1ee7a t\u1eebng b\u00e0i to\u00e1n , d\u1ef1 \u00e1n c\u1ee5 th\u1ec3. \u0110\u1ec3 th\u00eam m\u1edbi Project , click v\u00e0o Workspace c\u1ee7a ng\u01b0\u1eddi d\u00f9ng \u0111\u1ec3 v\u00e0o kh\u00f4ng gian l\u00e0m vi\u1ec7c, sau \u0111\u00f3 click n\u00fat th\u00eam m\u1edbi l\u00e0 bi\u1ec3u t\u01b0\u1ee3ng d\u1ea5u \"+\" Sau khi click \"Save\" , data source \u0111\u01b0\u1ee3c l\u01b0u v\u00e0 c\u00f3 th\u1ec3 d\u1eed d\u1ee5ng. Task Task l\u00e0 n\u01a1i ng\u01b0\u1eddi d\u00f9ng qu\u1ea3n l\u00fd, ph\u00e2n chia c\u00e1c c\u00f4ng vi\u1ec7c trong d\u1ef1 \u00e1n. Timeline (History) Hi\u1ec3n th\u1ecb l\u1ecbch s\u1eed ng\u01b0\u1eddi d\u00f9ng thao t\u00e1c trong project 5. DATA INTERGRATON AND STORAGE Data source l\u00e0 ph\u1ea7n ch\u1ee9a dataset s\u1eed d\u1ee5ng cho c\u00e1c Project ng\u01b0\u1eddi d\u00f9ng c\u1ea7n l\u00e0m. T\u1ea1i \u0111\u00e2y , ta t\u1ea1o v\u1edbi datasource t\u01b0\u01a1ng \u1ee9ng v\u1edbi c\u00e1c t\u1eadp dataset c\u1ea7n ph\u00e2n t\u00edch. Click t\u1ea1o m\u1edbi data source t\u1ea1i ph\u1ea7n List of data source, \u0111i\u1ec1n c\u00e1c th\u00f4ng s\u1ed1 c\u1ea7n \u0111i\u1ec3n cho t\u1eadp d\u1eef li\u1ec7u. Titanic t\u1ea3i tr\u00ean Kaggle. Data source : Ch\u1ecdn Tabular cho d\u1eef li\u1ec7u d\u1ea1ng b\u1ea3ng c\u1ee7a Titanic Source type : Ch\u1ecdn Csv file , v\u1edbi file d\u1eef li\u1ec7u \u0111\u01b0a l\u00ean l\u00e0 file train.csv tr\u00ean Kaggle \u0111\u00e3 t\u1ea3i v\u1ec1 v\u00e0 l\u01b0u trong m\u00e1y ng\u01b0\u1eddi d\u00f9ng. Choose File : T\u1ea3i file d\u1eef li\u1ec7u trong m\u00e1y l\u00ean. ID column : L\u1ef1a ch\u1ecdn c\u1ed9t ch\u1ee9a ID . Trong file n\u00e0y , c\u1ed9t ch\u1ee9a ID l\u00e0 *PassengerId Label column : L\u1ef1a ch\u1ecdn c\u1ed9t ng\u01b0\u1eddi d\u00f9ng mu\u1ed1n g\u00e1n nh\u00e3n. Trong b\u00e0i to\u00e1n n\u00e0y , ch\u00fang ta l\u1ef1a ch\u1ecdn c\u1ed9t Survived H\u00ecnh 3. T\u1ea1o m\u1edbi data source. 6. USER - ASSIGN USER Trong c\u00e1c d\u1ef1 \u00e1n l\u00e0m nh\u00f3m, List of assign user l\u00e0 danh s\u00e1ch c\u00e1c th\u00e0nh vi\u00ean m\u00e0 ng\u01b0\u1eddi d\u00f9ng g\u00e1n c\u00f4ng vi\u1ec7c trong d\u1ef1 \u00e1n 7. FLOW Flow l\u00e0 n\u01a1i tr\u1ef1c ti\u1ebfp ng\u01b0\u1eddi d\u00f9ng l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c t\u1eadp d\u1eef li\u1ec7u. Ta t\u1ea1o m\u1edbi Flow cho t\u1eebng b\u00e0i to\u00e1n ph\u00e2n t\u00edch d\u1eef li\u1ec7u c\u1ee5 th\u1ec3. H\u00ecnh 4. T\u1ea1o m\u1edbi Flow 8. SIMPLE FLOW H\u00ecnh 5. c\u00e1c th\u00e0nh ph\u1ea7n ch\u00ednh trong m\u00e0n h\u00ecnh flow Sau khi t\u1ea1o m\u1edbi Flow \u0111\u1ec3 l\u00e0m vi\u1ec7c, click v\u00e0o Flow v\u1eeba t\u1ea1o \u0111\u1ec3 v\u00e0o l\u00e0m vi\u1ec7c v\u1edbi Flow - t\u1ea1o c\u00e1c lu\u1ed3ng x\u1eed l\u00fd d\u1eef li\u1ec7u. DSSAMA Flow - giao di\u1ec7n l\u00e0m vi\u1ec7c tr\u1ef1c ti\u1ebfp \u0111\u01b0\u1ee3c t\u1ea1o th\u00e0nh t\u1eeb c\u00e1c th\u00e0nh ph\u1ea7n sau: - Dataflow Editor: v\u00f9ng Grids \u0111\u1ec3 t\u1ea1o m\u1edbi c\u00e1c lu\u1ed3ng flow v\u00e0 ch\u1ec9nh s\u1eeda c\u00e1c lu\u1ed3ng flow hi\u1ec7n \u0111ang ho\u1ea1t \u0111\u1ed9ng. Stage Repository: Danh m\u1ee5c Stage c\u00f3 s\u1eb5n trong n\u1ec1n t\u1ea3ng DSSAMA \u0111\u01b0\u1ee3c l\u01b0u tr\u1eef t\u1ea1i \u0111\u00e2y, c\u00e1c Stage t\u01b0\u01a1ng \u1ee9ng v\u1edbi c\u00e1c thu\u1eadt to\u00e1n h\u1ecdc m\u00e1y x\u1eed l\u00fd d\u1eef li\u1ec7u, \u0111\u01b0\u1ee3c t\u1ed5 ch\u1ee9c theo c\u00e2y th\u01b0 m\u1ee5c \u0111\u1ec3 d\u1ec5 t\u00ecm ki\u1ebfm. Stage Propeties : C\u00e1c thu\u1ed9c t\u00ednh c\u1ee7a Stage, sau khi \u0111\u01b0a Stage v\u00e0o v\u00f9ng Grids, ng\u01b0\u1eddi d\u00f9ng c\u1ea7n click v\u00e0o Stage \u0111\u1ec3 ch\u1ec9nh s\u1eeda c\u00e1c thu\u1ed9c t\u00ednh \u0111\u1ec3 ph\u00f9 h\u1ee3p v\u1edbi m\u1ee5c \u0111\u00edch x\u1eed l\u00fd d\u1eef li\u1ec7u cho b\u00e0i to\u00e1n. Console logs: Hi\u1ec3n th\u1ecb th\u00f4ng b\u00e1o th\u1ef1c thi cho bi\u1ebft k\u1ebft qu\u1ea3 th\u1ef1c thi c\u00e1c Flow. Stage v\u00e0 Flow Trong n\u1ec1n t\u1ea3ng ph\u00e2n t\u00edch d\u1eef li\u1ec7u DSSAMA , c\u00e1c t\u00e1c v\u1ee5 x\u1eed l\u00fd d\u1eef li\u1ec7u ri\u00eang l\u1ebb \u0111\u01b0\u1ee3c th\u1ec3 hi\u1ec7n b\u1eb1ng c\u00e1c Stage. M\u1ed7i Stage \u0111\u01b0\u1ee3c x\u1ebfp trong ph\u1ea7n Stage Repository, khi \u0111\u01b0a sang v\u00f9ng Grids, m\u1ed7i Stage \u0111\u01b0\u1ee3c hi\u1ec3n d\u01b0\u1edbi d\u1ea1ng h\u1ed9p icon vu\u00f4ng c\u00f3 \u0111\u1ea7u v\u00e0o v\u00e0 \u0111\u1ea7u ra, nh\u01b0ng v\u1edbi Stage Input, v\u00e0 Stage x\u1eed l\u00fd d\u1eef li\u1ec7u cu\u1ed1i l\u00e0 ch\u1ec9 c\u00f3 \u0111\u1ea7u v\u00e0o ho\u1eb7c \u0111\u1ea7u ra. \u0110\u1ea7u v\u00e0o l\u00e0 d\u1eef li\u1ec7u m\u00e0 n\u00fat x\u1eed l\u00fd v\u00e0 \u0111\u00e0u ra l\u00e0 c\u00e1c b\u1ed9 d\u1eef li\u1ec7u k\u1ebft qu\u1ea3. M\u1ed7i Stage c\u00f3 ph\u1ea7n c\u00e0i \u0111\u1eb7t thu\u1ed9c t\u00ednh xu\u1ea5t hi\u1ec7n khi click v\u00e0o Stage, ch\u00fang ta c\u00f3 th\u1ec3 \u0111i\u1ec1u ch\u1ec9nh c\u00e1c thu\u1ed9c t\u00ednh n\u00e0y \u0111\u1ec3 ph\u00f9 h\u1ee3p v\u1edbi d\u1eef li\u1ec7u v\u00e0o , v\u00e0 ra c\u1ee7a Stage v\u00e0 ph\u00f9 h\u1ee3p v\u1edbi Flow x\u1eed l\u00fd b\u00e0i to\u00e1n. Click l\u1ea1i v\u00e0 Stage \u0111\u00e3 c\u00e0i \u0111\u1eb7t , click Run tr\u00ean thanh c\u00f4ng c\u1ee5. Sau khi ch\u1ea1y xong, k\u1ebft qu\u1ea3 ta nh\u1eadn \u0111\u01b0\u1ee3c l\u00e0 m\u1ed9t c\u1eeda s\u1ed5 hi\u1ec3n th\u1ecb d\u1eef li\u1ec7u output c\u1ee7a Stage \u0111\u00f3. M\u1ed7i stage ho\u00e0n th\u00e0nh ch\u1ea1y xong \u0111\u1ec1u c\u00f3 d\u1ea5u t\u00edch xanh \u1edf g\u00f3c ph\u1ea3i b\u00ean d\u01b0\u1edbi c\u00e1c h\u1ed9p icon. H\u00ecnh . Stage v\u00e0 thu\u1ed9c t\u00ednh c\u1ee7a Stage trong Flow","title":"GETTING STARTED"},{"location":"VN/vn_getting_started/#getting-started","text":"","title":"GETTING STARTED"},{"location":"VN/vn_getting_started/#nguoi-dung-moi-tao-tai-khoan","text":"V\u1edbi ng\u01b0\u1eddi d\u00f9ng l\u1ea7n \u0111\u1ea7u s\u1eed d\u1ee5ng, vi\u1ec7c \u0111\u1ea7u ti\u00ean c\u1ea7n l\u00e0m l\u00e0 \u0111\u0103ng k\u00fd t\u00e0i kho\u1ea3n DSSAMA t\u1ea1i DSSAMA N\u1ebfu ch\u01b0a c\u00f3 t\u00e0i kho\u1ea3n DSSAMA, h\u00e3y click v\u00e0o Sign Up \u0110i\u1ec1n \u0111\u1ea7y \u0111\u1ee7 c\u00e1c th\u00f4ng tin v\u00e0 click n\u00fat Sign up. \u0110\u0103ng nh\u1eadp v\u00e0o email \u0111\u0103ng k\u00fd t\u00e0i kho\u1ea3n \u0111\u1ec3 l\u1ea5y m\u00e3 token. Copy m\u00e3 token \u0111\u01b0\u1ee3c g\u1eedi v\u00e0o mail \u0111\u0103ng k\u00fd v\u00e0 paste v\u00e0o Token code v\u00e0 click Confirm . Khi \u0111\u00f3, ng\u01b0\u1eddi d\u00f9ng \u0111\u00e3 ho\u00e0n th\u00e0nh c\u00e1c b\u01b0\u1edbc \u0111\u0103ng k\u00fd t\u00e0i kho\u1ea3n v\u00e0 c\u00f3 th\u1ec3 d\u00f9ng t\u00e0i kho\u1ea3n \u0111\u00f3 \u0111\u0103ng nh\u1eadp. Ng\u01b0\u1eddi d\u00f9ng l\u01b0u \u00fd th\u1eddi gian nh\u1eadp m\u00e3 code.","title":"NG\u01af\u1edcI D\u00d9NG M\u1edaI - T\u1ea0O T\u00c0I KHO\u1ea2N"},{"location":"VN/vn_getting_started/#ang-nhap","text":"\u0110\u0103ng nh\u1eadp v\u00e0o h\u1ec7 th\u1ed1ng DSSAMA tr\u00ean tr\u00ecnh duy\u1ec7t nh\u1eadp email ng\u01b0\u1eddi d\u00f9ng \u0111\u00e3 \u0111\u0103ng k\u00fd tr\u01b0\u1edbc \u0111\u00f3 v\u00e0 password. Sau khi \u0111\u0103ng nh\u1eadp v\u00e0o h\u1ec7 th\u1ed1ng, giao di\u1ec7n l\u00e0m vi\u1ec7c c\u1ee7a h\u1ec7 th\u1ed1ng DSSAMA nh\u01b0 sau.","title":"\u0110\u0102NG NH\u1eacP"},{"location":"VN/vn_getting_started/#2-workspace","text":"Sau khi \u0111\u0103ng nh\u1eadp v\u00e0o h\u1ec7 th\u1ed1ng DSSAMA, ng\u01b0\u1eddi d\u00f9ng c\u1ea7n t\u1ea1o kh\u00f4ng gian l\u00e0m vi\u1ec7c \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi d\u1eef li\u1ec7u tr\u00ean \u0111\u00f3. M\u1ed7i t\u00e0i kho\u1ea3n \u0111\u01b0\u1ee3c cung c\u1ea5p m\u1ed9t default workspace server mi\u1ec5n ph\u00ed v\u00e0 b\u1ea3o m\u1eadt.N\u1ebfu mu\u1ed1n t\u1ea1o h\u01a1n m\u1ed9t Workspace, ng\u01b0\u1eddi d\u00f9ng n\u00ean d\u00f9ng th\u00eam workspace server. M\u1ed7i t\u00e0i kho\u1ea3n \u0111\u01b0\u1ee3c cung c\u1ea5p m\u1ed9t default workspace server mi\u1ec5n ph\u00ed v\u00e0 b\u1ea3o m\u1eadt.N\u1ebfu mu\u1ed1n t\u1ea1o h\u01a1n m\u1ed9t Workspace, ng\u01b0\u1eddi d\u00f9ng n\u00ean d\u00f9ng th\u00eam workspace server. Sau khi click \"Save\" Workpsace \u0111\u01b0\u1ee3c t\u1ea1o, \u0111\u00f3 l\u00e0 kh\u00f4ng gian m\u00e0 ch\u00fang ta s\u1ebd l\u00e0m vi\u1ec7c tr\u00ean \u0111\u00f3.","title":"2. WORKSPACE"},{"location":"VN/vn_getting_started/#3-workspace-server","text":"","title":"3. WORKSPACE SERVER"},{"location":"VN/vn_getting_started/#4-project","text":"Project trong DSSAMA l\u00e0 n\u01a1i qu\u1ea3n l\u00fd, l\u01b0u tr\u1eef c\u00e1c Flow (lu\u1ed3ng c\u00f4ng vi\u1ec7c) c\u1ee7a t\u1eebng b\u00e0i to\u00e1n , d\u1ef1 \u00e1n c\u1ee5 th\u1ec3. \u0110\u1ec3 th\u00eam m\u1edbi Project , click v\u00e0o Workspace c\u1ee7a ng\u01b0\u1eddi d\u00f9ng \u0111\u1ec3 v\u00e0o kh\u00f4ng gian l\u00e0m vi\u1ec7c, sau \u0111\u00f3 click n\u00fat th\u00eam m\u1edbi l\u00e0 bi\u1ec3u t\u01b0\u1ee3ng d\u1ea5u \"+\" Sau khi click \"Save\" , data source \u0111\u01b0\u1ee3c l\u01b0u v\u00e0 c\u00f3 th\u1ec3 d\u1eed d\u1ee5ng.","title":"4. PROJECT"},{"location":"VN/vn_getting_started/#task","text":"Task l\u00e0 n\u01a1i ng\u01b0\u1eddi d\u00f9ng qu\u1ea3n l\u00fd, ph\u00e2n chia c\u00e1c c\u00f4ng vi\u1ec7c trong d\u1ef1 \u00e1n.","title":"Task"},{"location":"VN/vn_getting_started/#timeline-history","text":"Hi\u1ec3n th\u1ecb l\u1ecbch s\u1eed ng\u01b0\u1eddi d\u00f9ng thao t\u00e1c trong project","title":"Timeline (History)"},{"location":"VN/vn_getting_started/#5-data-intergraton-and-storage","text":"Data source l\u00e0 ph\u1ea7n ch\u1ee9a dataset s\u1eed d\u1ee5ng cho c\u00e1c Project ng\u01b0\u1eddi d\u00f9ng c\u1ea7n l\u00e0m. T\u1ea1i \u0111\u00e2y , ta t\u1ea1o v\u1edbi datasource t\u01b0\u01a1ng \u1ee9ng v\u1edbi c\u00e1c t\u1eadp dataset c\u1ea7n ph\u00e2n t\u00edch. Click t\u1ea1o m\u1edbi data source t\u1ea1i ph\u1ea7n List of data source, \u0111i\u1ec1n c\u00e1c th\u00f4ng s\u1ed1 c\u1ea7n \u0111i\u1ec3n cho t\u1eadp d\u1eef li\u1ec7u. Titanic t\u1ea3i tr\u00ean Kaggle. Data source : Ch\u1ecdn Tabular cho d\u1eef li\u1ec7u d\u1ea1ng b\u1ea3ng c\u1ee7a Titanic Source type : Ch\u1ecdn Csv file , v\u1edbi file d\u1eef li\u1ec7u \u0111\u01b0a l\u00ean l\u00e0 file train.csv tr\u00ean Kaggle \u0111\u00e3 t\u1ea3i v\u1ec1 v\u00e0 l\u01b0u trong m\u00e1y ng\u01b0\u1eddi d\u00f9ng. Choose File : T\u1ea3i file d\u1eef li\u1ec7u trong m\u00e1y l\u00ean. ID column : L\u1ef1a ch\u1ecdn c\u1ed9t ch\u1ee9a ID . Trong file n\u00e0y , c\u1ed9t ch\u1ee9a ID l\u00e0 *PassengerId Label column : L\u1ef1a ch\u1ecdn c\u1ed9t ng\u01b0\u1eddi d\u00f9ng mu\u1ed1n g\u00e1n nh\u00e3n. Trong b\u00e0i to\u00e1n n\u00e0y , ch\u00fang ta l\u1ef1a ch\u1ecdn c\u1ed9t Survived H\u00ecnh 3. T\u1ea1o m\u1edbi data source.","title":"5. DATA INTERGRATON AND STORAGE"},{"location":"VN/vn_getting_started/#6-user-assign-user","text":"Trong c\u00e1c d\u1ef1 \u00e1n l\u00e0m nh\u00f3m, List of assign user l\u00e0 danh s\u00e1ch c\u00e1c th\u00e0nh vi\u00ean m\u00e0 ng\u01b0\u1eddi d\u00f9ng g\u00e1n c\u00f4ng vi\u1ec7c trong d\u1ef1 \u00e1n","title":"6. USER - ASSIGN USER"},{"location":"VN/vn_getting_started/#7-flow","text":"Flow l\u00e0 n\u01a1i tr\u1ef1c ti\u1ebfp ng\u01b0\u1eddi d\u00f9ng l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c t\u1eadp d\u1eef li\u1ec7u. Ta t\u1ea1o m\u1edbi Flow cho t\u1eebng b\u00e0i to\u00e1n ph\u00e2n t\u00edch d\u1eef li\u1ec7u c\u1ee5 th\u1ec3. H\u00ecnh 4. T\u1ea1o m\u1edbi Flow","title":"7. FLOW"},{"location":"VN/vn_getting_started/#8-simple-flow","text":"H\u00ecnh 5. c\u00e1c th\u00e0nh ph\u1ea7n ch\u00ednh trong m\u00e0n h\u00ecnh flow Sau khi t\u1ea1o m\u1edbi Flow \u0111\u1ec3 l\u00e0m vi\u1ec7c, click v\u00e0o Flow v\u1eeba t\u1ea1o \u0111\u1ec3 v\u00e0o l\u00e0m vi\u1ec7c v\u1edbi Flow - t\u1ea1o c\u00e1c lu\u1ed3ng x\u1eed l\u00fd d\u1eef li\u1ec7u. DSSAMA Flow - giao di\u1ec7n l\u00e0m vi\u1ec7c tr\u1ef1c ti\u1ebfp \u0111\u01b0\u1ee3c t\u1ea1o th\u00e0nh t\u1eeb c\u00e1c th\u00e0nh ph\u1ea7n sau: - Dataflow Editor: v\u00f9ng Grids \u0111\u1ec3 t\u1ea1o m\u1edbi c\u00e1c lu\u1ed3ng flow v\u00e0 ch\u1ec9nh s\u1eeda c\u00e1c lu\u1ed3ng flow hi\u1ec7n \u0111ang ho\u1ea1t \u0111\u1ed9ng. Stage Repository: Danh m\u1ee5c Stage c\u00f3 s\u1eb5n trong n\u1ec1n t\u1ea3ng DSSAMA \u0111\u01b0\u1ee3c l\u01b0u tr\u1eef t\u1ea1i \u0111\u00e2y, c\u00e1c Stage t\u01b0\u01a1ng \u1ee9ng v\u1edbi c\u00e1c thu\u1eadt to\u00e1n h\u1ecdc m\u00e1y x\u1eed l\u00fd d\u1eef li\u1ec7u, \u0111\u01b0\u1ee3c t\u1ed5 ch\u1ee9c theo c\u00e2y th\u01b0 m\u1ee5c \u0111\u1ec3 d\u1ec5 t\u00ecm ki\u1ebfm. Stage Propeties : C\u00e1c thu\u1ed9c t\u00ednh c\u1ee7a Stage, sau khi \u0111\u01b0a Stage v\u00e0o v\u00f9ng Grids, ng\u01b0\u1eddi d\u00f9ng c\u1ea7n click v\u00e0o Stage \u0111\u1ec3 ch\u1ec9nh s\u1eeda c\u00e1c thu\u1ed9c t\u00ednh \u0111\u1ec3 ph\u00f9 h\u1ee3p v\u1edbi m\u1ee5c \u0111\u00edch x\u1eed l\u00fd d\u1eef li\u1ec7u cho b\u00e0i to\u00e1n. Console logs: Hi\u1ec3n th\u1ecb th\u00f4ng b\u00e1o th\u1ef1c thi cho bi\u1ebft k\u1ebft qu\u1ea3 th\u1ef1c thi c\u00e1c Flow.","title":"8. SIMPLE FLOW"},{"location":"VN/vn_getting_started/#stage-va-flow","text":"Trong n\u1ec1n t\u1ea3ng ph\u00e2n t\u00edch d\u1eef li\u1ec7u DSSAMA , c\u00e1c t\u00e1c v\u1ee5 x\u1eed l\u00fd d\u1eef li\u1ec7u ri\u00eang l\u1ebb \u0111\u01b0\u1ee3c th\u1ec3 hi\u1ec7n b\u1eb1ng c\u00e1c Stage. M\u1ed7i Stage \u0111\u01b0\u1ee3c x\u1ebfp trong ph\u1ea7n Stage Repository, khi \u0111\u01b0a sang v\u00f9ng Grids, m\u1ed7i Stage \u0111\u01b0\u1ee3c hi\u1ec3n d\u01b0\u1edbi d\u1ea1ng h\u1ed9p icon vu\u00f4ng c\u00f3 \u0111\u1ea7u v\u00e0o v\u00e0 \u0111\u1ea7u ra, nh\u01b0ng v\u1edbi Stage Input, v\u00e0 Stage x\u1eed l\u00fd d\u1eef li\u1ec7u cu\u1ed1i l\u00e0 ch\u1ec9 c\u00f3 \u0111\u1ea7u v\u00e0o ho\u1eb7c \u0111\u1ea7u ra. \u0110\u1ea7u v\u00e0o l\u00e0 d\u1eef li\u1ec7u m\u00e0 n\u00fat x\u1eed l\u00fd v\u00e0 \u0111\u00e0u ra l\u00e0 c\u00e1c b\u1ed9 d\u1eef li\u1ec7u k\u1ebft qu\u1ea3. M\u1ed7i Stage c\u00f3 ph\u1ea7n c\u00e0i \u0111\u1eb7t thu\u1ed9c t\u00ednh xu\u1ea5t hi\u1ec7n khi click v\u00e0o Stage, ch\u00fang ta c\u00f3 th\u1ec3 \u0111i\u1ec1u ch\u1ec9nh c\u00e1c thu\u1ed9c t\u00ednh n\u00e0y \u0111\u1ec3 ph\u00f9 h\u1ee3p v\u1edbi d\u1eef li\u1ec7u v\u00e0o , v\u00e0 ra c\u1ee7a Stage v\u00e0 ph\u00f9 h\u1ee3p v\u1edbi Flow x\u1eed l\u00fd b\u00e0i to\u00e1n. Click l\u1ea1i v\u00e0 Stage \u0111\u00e3 c\u00e0i \u0111\u1eb7t , click Run tr\u00ean thanh c\u00f4ng c\u1ee5. Sau khi ch\u1ea1y xong, k\u1ebft qu\u1ea3 ta nh\u1eadn \u0111\u01b0\u1ee3c l\u00e0 m\u1ed9t c\u1eeda s\u1ed5 hi\u1ec3n th\u1ecb d\u1eef li\u1ec7u output c\u1ee7a Stage \u0111\u00f3. M\u1ed7i stage ho\u00e0n th\u00e0nh ch\u1ea1y xong \u0111\u1ec1u c\u00f3 d\u1ea5u t\u00edch xanh \u1edf g\u00f3c ph\u1ea3i b\u00ean d\u01b0\u1edbi c\u00e1c h\u1ed9p icon. H\u00ecnh . Stage v\u00e0 thu\u1ed9c t\u00ednh c\u1ee7a Stage trong Flow","title":"Stage v\u00e0 Flow"},{"location":"VN/vn_introduction/","text":"Welcome to DSSAMA DSSAMA Main Features \u0110\u1eb7c tr\u01b0ng ch\u00ednh c\u1ee7a DSSAMA Nhanh ch\u00f3ng: Cho ph\u00e9p th\u1eed nghi\u1ec7m nhanh c\u00e1c gi\u1ea3i ph\u00e1p v\u1ec1 AI, tr\u1ef1c ti\u1ebfp tr\u00ean d\u1eef li\u1ec7u c\u1ee7a kh\u00e1ch h\u00e0ng. Tr\u1ef1c quan: Ch\u1ec9 v\u1edbi c\u00e1c thao t\u00e1c k\u1ebft n\u1ed1i d\u1eef li\u1ec7u, l\u1ef1a ch\u1ecdn c\u00e1c c\u00f4ng c\u1ee5 AI, kh\u00e1ch h\u00e0ng \u0111\u00e3 c\u00f3 th\u1ec3 \u0111\u01b0a ra m\u1ed9t gi\u1ea3i ph\u00e1p cho b\u00e0i to\u00e1n c\u1ee7a m\u00ecnh. C\u1ed9ng t\u00e1c: N\u1ec1n t\u1ea3ng h\u1ed7 tr\u1ee3 l\u00e0m vi\u1ec7c c\u1ed9ng t\u00e1c tr\u00ean m\u00f4i tr\u01b0\u1eddng \u0111i\u1ec7n to\u00e1n \u0111\u00e1m m\u00e2y, k\u1ebft n\u1ed1i kh\u00e1ch h\u00e0ng t\u1edbi c\u00e1c chuy\u00ean gia v\u1ec1 AI gi\u00fap gi\u1ea3i quy\u1ebft b\u00e0i to\u00e1n c\u1ee7a m\u00ecnh. B\u1ea3o m\u1eadt: Kh\u00e1ch h\u00e0ng kh\u00f4ng c\u1ea7n ph\u1ea3i \u0111em d\u1eef li\u1ec7u ra kh\u1ecfi t\u1ed5 ch\u1ee9c c\u1ee7a m\u00ecnh, h\u1ecd v\u1eabn c\u00f3 th\u1ec3 th\u1ef1c hi\u1ec7n d\u1ef1 \u00e1n t\u1ea1i b\u1ea5t c\u1ee9 \u0111\u00e2u v\u1edbi s\u1ef1 h\u1ed7 tr\u1ee3 c\u1ee7a b\u1ea5t c\u1ee9 ai. C\u00e1c \u0111\u1eb7c tr\u01b0ng kh\u00e1c: T\u00edch h\u1ee3p c\u00e1c c\u00f4ng c\u1ee5 AI m\u1ea1nh m\u1ebd tr\u00ean th\u1ebf gi\u1edbi. T\u1ef1 \u0111\u1ed9ng ho\u00e1 ph\u00e2n t\u00edch, x\u00e2y d\u1ef1ng c\u00e1c m\u00f4 h\u00ecnh h\u1ecdc m\u00e1y Tri\u1ec3n khai nhanh ch\u00f3ng tr\u00ean server d\u00f9ng ri\u00eang ho\u1eb7c cloud. Ki\u1ebfn tr\u00fac c\u1ee7a DSSAMA Workspace \u2013 C\u00e1c kh\u00f4ng gian l\u00e0m vi\u1ec7c Workspace l\u00e0 n\u1edbi l\u01b0u tr\u1eef d\u1eef li\u1ec7u, th\u00f4ng tin v\u00e0 t\u00e0i nguy\u00ean c\u1ee7a c\u00e1c d\u1ef1 \u00e1n. Qu\u1ea3n l\u00fd d\u1ef1 \u00e1n Qu\u1ea3n l\u00fd c\u00e1c t\u00e1c v\u1ee5 Qu\u1ea3n l\u00fd phi\u00ean b\u1ea3n c\u00e1c lu\u1ed3ng d\u1eef li\u1ec7u L\u01b0u tr\u1eef tham s\u1ed1 v\u00e0 si\u00eau tham s\u1ed1 m\u00f4 h\u00ecnh Qu\u1ea3n l\u00fd nh\u00f3m l\u00e0m vi\u1ec7c Qu\u1ea3n tr\u1ecb d\u1eef li\u1ec7u: L\u01b0u tr\u1eef d\u01b0 li\u1ec7u cho c\u00e1c d\u1ef1 \u00e1n K\u1ebft n\u1ed1i t\u1edbi Data Lake, MDM Qu\u1ea3n l\u00fd t\u00e0i nguy\u00ean: C\u00e1c h\u1ec7 th\u1ed1ng t\u00ednh to\u00e1n, RAM, l\u01b0u tr\u1eef, GPU .... Flows \u2013 C\u00e1c lu\u1ed3ng d\u1eef li\u1ec7u, ki\u1ebfn tr\u00fac m\u00f4 h\u00ecnh h\u1ecdc m\u00e1y Workflow \u0111\u01b0\u1ee3c m\u00f4 t\u1ea3 nh\u01b0 c\u00e1c \u0111\u1ed3 th\u1ecb t\u00ednh to\u00e1n trong \u0111\u00f3 c\u00e1c node l\u00e0 c\u00e1c b\u01b0\u1edbc t\u00ednh to\u00e1n d\u1ef1a tr\u00ean h\u1ecdc m\u00e1y v\u00e0 ph\u00e2n t\u00edch d\u1eef li\u1ec7u. Bi\u1ec3u di\u1ec5n c\u00e1c \u0111\u1ed3 th\u1ecb t\u00ednh to\u00e1n M\u1ed7i stage l\u00e0 m\u1ed9t b\u01b0\u1edbc x\u1eed l\u00fd, t\u00e1c v\u1ee5 ri\u00eang bi\u1ec7t. \u0110\u1eb7c tr\u01b0ng c\u1ee7a DSSAMA AI d\u00e0nh cho m\u1ecdi ng\u01b0\u1eddi H\u1ed7 tr\u1ee3 c\u1ed9ng t\u00e1c C\u00e1c k\u1ef9 thu\u1eadt AI c\u1eadp nh\u1eadt nh\u1ea5t. \u0110\u01b0\u1ee3c h\u1ed7 tr\u1ee3 b\u1edfi c\u00e1c c\u00f4ng c\u1ee5 m\u1ea1nh m\u1ebd:","title":"Introduction"},{"location":"VN/vn_introduction/#welcome-to-dssama","text":"DSSAMA","title":"Welcome to DSSAMA"},{"location":"VN/vn_introduction/#main-features","text":"","title":"Main Features"},{"location":"VN/vn_introduction/#ac-trung-chinh-cua-dssama","text":"Nhanh ch\u00f3ng: Cho ph\u00e9p th\u1eed nghi\u1ec7m nhanh c\u00e1c gi\u1ea3i ph\u00e1p v\u1ec1 AI, tr\u1ef1c ti\u1ebfp tr\u00ean d\u1eef li\u1ec7u c\u1ee7a kh\u00e1ch h\u00e0ng. Tr\u1ef1c quan: Ch\u1ec9 v\u1edbi c\u00e1c thao t\u00e1c k\u1ebft n\u1ed1i d\u1eef li\u1ec7u, l\u1ef1a ch\u1ecdn c\u00e1c c\u00f4ng c\u1ee5 AI, kh\u00e1ch h\u00e0ng \u0111\u00e3 c\u00f3 th\u1ec3 \u0111\u01b0a ra m\u1ed9t gi\u1ea3i ph\u00e1p cho b\u00e0i to\u00e1n c\u1ee7a m\u00ecnh. C\u1ed9ng t\u00e1c: N\u1ec1n t\u1ea3ng h\u1ed7 tr\u1ee3 l\u00e0m vi\u1ec7c c\u1ed9ng t\u00e1c tr\u00ean m\u00f4i tr\u01b0\u1eddng \u0111i\u1ec7n to\u00e1n \u0111\u00e1m m\u00e2y, k\u1ebft n\u1ed1i kh\u00e1ch h\u00e0ng t\u1edbi c\u00e1c chuy\u00ean gia v\u1ec1 AI gi\u00fap gi\u1ea3i quy\u1ebft b\u00e0i to\u00e1n c\u1ee7a m\u00ecnh. B\u1ea3o m\u1eadt: Kh\u00e1ch h\u00e0ng kh\u00f4ng c\u1ea7n ph\u1ea3i \u0111em d\u1eef li\u1ec7u ra kh\u1ecfi t\u1ed5 ch\u1ee9c c\u1ee7a m\u00ecnh, h\u1ecd v\u1eabn c\u00f3 th\u1ec3 th\u1ef1c hi\u1ec7n d\u1ef1 \u00e1n t\u1ea1i b\u1ea5t c\u1ee9 \u0111\u00e2u v\u1edbi s\u1ef1 h\u1ed7 tr\u1ee3 c\u1ee7a b\u1ea5t c\u1ee9 ai.","title":"\u0110\u1eb7c tr\u01b0ng ch\u00ednh c\u1ee7a DSSAMA"},{"location":"VN/vn_introduction/#cac-ac-trung-khac","text":"T\u00edch h\u1ee3p c\u00e1c c\u00f4ng c\u1ee5 AI m\u1ea1nh m\u1ebd tr\u00ean th\u1ebf gi\u1edbi. T\u1ef1 \u0111\u1ed9ng ho\u00e1 ph\u00e2n t\u00edch, x\u00e2y d\u1ef1ng c\u00e1c m\u00f4 h\u00ecnh h\u1ecdc m\u00e1y Tri\u1ec3n khai nhanh ch\u00f3ng tr\u00ean server d\u00f9ng ri\u00eang ho\u1eb7c cloud.","title":"C\u00e1c \u0111\u1eb7c tr\u01b0ng kh\u00e1c:"},{"location":"VN/vn_introduction/#kien-truc-cua-dssama","text":"","title":"Ki\u1ebfn tr\u00fac c\u1ee7a DSSAMA"},{"location":"VN/vn_introduction/#workspace-cac-khong-gian-lam-viec","text":"Workspace l\u00e0 n\u1edbi l\u01b0u tr\u1eef d\u1eef li\u1ec7u, th\u00f4ng tin v\u00e0 t\u00e0i nguy\u00ean c\u1ee7a c\u00e1c d\u1ef1 \u00e1n. Qu\u1ea3n l\u00fd d\u1ef1 \u00e1n Qu\u1ea3n l\u00fd c\u00e1c t\u00e1c v\u1ee5 Qu\u1ea3n l\u00fd phi\u00ean b\u1ea3n c\u00e1c lu\u1ed3ng d\u1eef li\u1ec7u L\u01b0u tr\u1eef tham s\u1ed1 v\u00e0 si\u00eau tham s\u1ed1 m\u00f4 h\u00ecnh Qu\u1ea3n l\u00fd nh\u00f3m l\u00e0m vi\u1ec7c Qu\u1ea3n tr\u1ecb d\u1eef li\u1ec7u: L\u01b0u tr\u1eef d\u01b0 li\u1ec7u cho c\u00e1c d\u1ef1 \u00e1n K\u1ebft n\u1ed1i t\u1edbi Data Lake, MDM Qu\u1ea3n l\u00fd t\u00e0i nguy\u00ean: C\u00e1c h\u1ec7 th\u1ed1ng t\u00ednh to\u00e1n, RAM, l\u01b0u tr\u1eef, GPU ....","title":"Workspace \u2013 C\u00e1c kh\u00f4ng gian l\u00e0m vi\u1ec7c"},{"location":"VN/vn_introduction/#flows-cac-luong-du-lieu-kien-truc-mo-hinh-hoc-may","text":"Workflow \u0111\u01b0\u1ee3c m\u00f4 t\u1ea3 nh\u01b0 c\u00e1c \u0111\u1ed3 th\u1ecb t\u00ednh to\u00e1n trong \u0111\u00f3 c\u00e1c node l\u00e0 c\u00e1c b\u01b0\u1edbc t\u00ednh to\u00e1n d\u1ef1a tr\u00ean h\u1ecdc m\u00e1y v\u00e0 ph\u00e2n t\u00edch d\u1eef li\u1ec7u.","title":"Flows \u2013 C\u00e1c lu\u1ed3ng d\u1eef li\u1ec7u, ki\u1ebfn tr\u00fac m\u00f4 h\u00ecnh h\u1ecdc m\u00e1y"},{"location":"VN/vn_introduction/#bieu-dien-cac-o-thi-tinh-toan","text":"M\u1ed7i stage l\u00e0 m\u1ed9t b\u01b0\u1edbc x\u1eed l\u00fd, t\u00e1c v\u1ee5 ri\u00eang bi\u1ec7t.","title":"Bi\u1ec3u di\u1ec5n c\u00e1c \u0111\u1ed3 th\u1ecb t\u00ednh to\u00e1n"},{"location":"VN/vn_introduction/#ac-trung-cua-dssama","text":"AI d\u00e0nh cho m\u1ecdi ng\u01b0\u1eddi H\u1ed7 tr\u1ee3 c\u1ed9ng t\u00e1c C\u00e1c k\u1ef9 thu\u1eadt AI c\u1eadp nh\u1eadt nh\u1ea5t. \u0110\u01b0\u1ee3c h\u1ed7 tr\u1ee3 b\u1edfi c\u00e1c c\u00f4ng c\u1ee5 m\u1ea1nh m\u1ebd:","title":"\u0110\u1eb7c tr\u01b0ng c\u1ee7a DSSAMA"},{"location":"VN/vn_machine_learning_pipeline_nltk/","text":"MACHINE LEARNING PIPELINE WITH NLTKSAMA 1. Word Stemming Transformer B\u01b0\u1edbc 1: Ch\u1ecdn Text Input trong Input.Ph\u1ea7n parameter: Dataset : \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp BBC_News Selected column : Content Start record : 0 End record : 9 \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package nltksama.ml ph\u1ea7n transform ch\u1ecdn Word Stemming Transformer b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 3: N\u1ed1i Text Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp BBC_News) v\u00e0o stage Word Stemming Transformer. Trong Word Stemming Transformer c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n: language (str) \u2013 Ch\u1ecdn ng\u00f4n ng\u1eef c\u1ea7n th\u1ef1c hi\u1ec7n bao g\u1ed3m: 'arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish' . ignore_stopwords (bool) \u2013 N\u1ebfu \u0111\u01b0\u1ee3c \u0111\u1eb7t th\u00e0nh True, stopwords kh\u00f4ng \u0111\u01b0\u1ee3c stemmed and v\u00e0 \u0111\u01b0\u1ee3c tr\u1ea3 l\u1ea1i kh\u00f4ng thay \u0111\u1ed5i. \u0110\u1eb7t False l\u00e0 m\u1eb7c \u0111\u1ecbnh. B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 2. Mwe Tokenization Transformer B\u01b0\u1edbc 1: Ch\u1ecdn Text Input trong Input.Ph\u1ea7n parameter: Dataset : \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp BBC_News Selected column : Content Start record : 0 End record : 9 \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package nltksama.ml ph\u1ea7n transform ch\u1ecdn Mwe Tokenization Transformer b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 3: N\u1ed1i Text Input (l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp BBC_News) v\u00e0o stage Mwe Tokenization Transformer . Trong Mwe Tokenization Transformer c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n: mwe (tuple(str) or list(str)): Danh s\u00e1ch c\u00e1c c\u1ee5m t\u1eeb c\u1ea7n ph\u00e2n t\u00e1ch separator :k\u00fd t\u1ef1 n\u1ed1i c\u00e1c t\u1eeb trong c\u1ee5m t\u1eeb. M\u1eb7c \u0111\u1ecbnh l\u00e0 \u2018-\u2019 B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 3. Tweet Tokenization Transformer B\u01b0\u1edbc 1: Ch\u1ecdn Text Input trong Input.Ph\u1ea7n parameter: Dataset : \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp BBC_News Selected column : Content Start record : 0 End record : 9 \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package nltksama.ml ph\u1ea7n transform ch\u1ecdn stage Tweet Tokenization Transformer \u0111\u01b0a v\u00e0o m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c. B\u01b0\u1edbc 3: N\u1ed1i Text Input (l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp BBC_News) v\u00e0o stage Tweet Tokenization Transformer . Trong Tweet Tokenization Transformer c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://www.nltk.org/api/nltk.tokenize.html?highlight=tweettokenizer#nltk.tokenize.casual.TweetTokenizer B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3:","title":"NLTK Machine Learning Pipeline"},{"location":"VN/vn_machine_learning_pipeline_nltk/#machine-learning-pipeline-with-nltksama","text":"","title":"MACHINE LEARNING PIPELINE WITH NLTKSAMA"},{"location":"VN/vn_machine_learning_pipeline_nltk/#1-word-stemming-transformer","text":"B\u01b0\u1edbc 1: Ch\u1ecdn Text Input trong Input.Ph\u1ea7n parameter: Dataset : \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp BBC_News Selected column : Content Start record : 0 End record : 9 \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package nltksama.ml ph\u1ea7n transform ch\u1ecdn Word Stemming Transformer b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 3: N\u1ed1i Text Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp BBC_News) v\u00e0o stage Word Stemming Transformer. Trong Word Stemming Transformer c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n: language (str) \u2013 Ch\u1ecdn ng\u00f4n ng\u1eef c\u1ea7n th\u1ef1c hi\u1ec7n bao g\u1ed3m: 'arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish' . ignore_stopwords (bool) \u2013 N\u1ebfu \u0111\u01b0\u1ee3c \u0111\u1eb7t th\u00e0nh True, stopwords kh\u00f4ng \u0111\u01b0\u1ee3c stemmed and v\u00e0 \u0111\u01b0\u1ee3c tr\u1ea3 l\u1ea1i kh\u00f4ng thay \u0111\u1ed5i. \u0110\u1eb7t False l\u00e0 m\u1eb7c \u0111\u1ecbnh. B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3","title":"1.   Word Stemming Transformer"},{"location":"VN/vn_machine_learning_pipeline_nltk/#2-mwe-tokenization-transformer","text":"B\u01b0\u1edbc 1: Ch\u1ecdn Text Input trong Input.Ph\u1ea7n parameter: Dataset : \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp BBC_News Selected column : Content Start record : 0 End record : 9 \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package nltksama.ml ph\u1ea7n transform ch\u1ecdn Mwe Tokenization Transformer b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 3: N\u1ed1i Text Input (l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp BBC_News) v\u00e0o stage Mwe Tokenization Transformer . Trong Mwe Tokenization Transformer c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n: mwe (tuple(str) or list(str)): Danh s\u00e1ch c\u00e1c c\u1ee5m t\u1eeb c\u1ea7n ph\u00e2n t\u00e1ch separator :k\u00fd t\u1ef1 n\u1ed1i c\u00e1c t\u1eeb trong c\u1ee5m t\u1eeb. M\u1eb7c \u0111\u1ecbnh l\u00e0 \u2018-\u2019 B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3","title":"2.   Mwe Tokenization Transformer"},{"location":"VN/vn_machine_learning_pipeline_nltk/#3-tweet-tokenization-transformer","text":"B\u01b0\u1edbc 1: Ch\u1ecdn Text Input trong Input.Ph\u1ea7n parameter: Dataset : \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp BBC_News Selected column : Content Start record : 0 End record : 9 \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package nltksama.ml ph\u1ea7n transform ch\u1ecdn stage Tweet Tokenization Transformer \u0111\u01b0a v\u00e0o m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c. B\u01b0\u1edbc 3: N\u1ed1i Text Input (l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp BBC_News) v\u00e0o stage Tweet Tokenization Transformer . Trong Tweet Tokenization Transformer c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://www.nltk.org/api/nltk.tokenize.html?highlight=tweettokenizer#nltk.tokenize.casual.TweetTokenizer B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3:","title":"3.   Tweet Tokenization Transformer"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/","text":"MACHINE LEARNING PIPELINE WITH SCIKITSAMA Scikitsama M\u1ee5c \u0111\u00edch c\u1ee7a h\u01b0\u1edbng d\u1eabn n\u00e0y l\u00e0 \u0111\u1ec3 minh h\u1ecda m\u1ed9t s\u1ed1 t\u00ednh n\u0103ng ch\u00ednh scikit.sama cung c\u1ea5p. Data Import and manipulation T\u1eeb c\u00e1c t\u1eadp dataset \u0111\u00e3 \u0111\u01b0a v\u00e0o Data source, \u0111\u1ec3 s\u1eed d\u1ee5ng dataset \u0111\u00f3 trong Flow, ng\u01b0\u1eddi d\u00f9ng c\u1ea7n import d\u1eef li\u1ec7u. \u0110\u1ec3 import d\u1eef li\u1ec7u, ng\u01b0\u1eddi d\u00f9ng s\u1eed d\u1ee5ng c\u00e1c stage Input l\u1ef1a ch\u1ecdn t\u1eeb nh\u00f3m stage Input. V\u1edbi m\u1ed7i d\u1ea1ng data source s\u1ebd c\u00f3 Stage import d\u1eef li\u1ec7u ri\u00eang , c\u00f3 c\u00e1c stage Input nh\u01b0 sau: Tabular Input : Stage input cho d\u1eef li\u1ec7u ngu\u1ed3n s\u1eed d\u1ee5ng l\u00e0 d\u1ea1ng b\u1ea3ng. Text Input : Stage input t\u01b0\u01a1ng d\u1eef li\u1ec7u ngu\u1ed3n s\u1eed d\u1ee5ng l\u00e0 d\u1ea1ng text. Timeseries Input : Stage input cho d\u1eef li\u1ec7u ngu\u1ed3n s\u1eed d\u1ee5ng l\u00e0 d\u1ea1ng chu\u1ed7i th\u1eddi gian. Image Input : Stage input cho ngu\u1ed3n d\u1eef li\u1ec7u s\u1eed d\u1ee5ng l\u00e0 d\u1ea1ng \u1ea3nh. Image Input for Classification : Image Input for Segmentation : Maps Input : Input d\u1eef li\u1ec7u th\u1ec3 hi\u1ec7n tr\u00ean b\u1ea3n \u0111\u1ed3. Scikit Iput : Input d\u1eef li\u1ec7u d\u00f9ng cho th\u01b0 vi\u1ec7n scikit learn, c\u00f3 s\u1eb5n m\u1ed9t s\u1ed1 dataset kinh \u0111i\u1ec3n. Kh\u00f4ng c\u1ea7n ph\u1ea3i t\u1ea1o data source. ### C\u00e1c thao t\u00e1c \u0110\u1ec3 import data v\u00e0o grid flow editor: 1. Click l\u1ef1a ch\u1ecdn stage Input ph\u00f9 h\u1ee3p v\u1edbi data source \u0111\u00e3 t\u1ea1o v\u00e0 mu\u1ed1n s\u1eed d\u1ee5ng( v\u00ed d\u1ee5 \u0111\u00e3 t\u1ea1o datasource tabular \u0111\u1ec3 s\u1eed d\u1ee5ng ta c\u1ea7n ch\u1ecdn Tabular Input ) 1. Click l\u1ea1i v\u00e0o v\u00f9ng grid \u0111\u1ec3 \u0111\u01b0a stage Input \u0111\u00f3 v\u00e0o 1. T\u00f9y ch\u1ecdn thu\u1ed9c t\u00ednh c\u1ee7a stage \u1edf menu ph\u1ea3i stage properties 1. Click Run \u0111\u1ec3 visualize data \u0111\u01b0a v\u00e0o v\u00e0 quan s\u00e1t d\u1eef li\u1ec7u. Data Preprocessing Transform 1. Normalize Transform 1.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n Preprocessing data: https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-normalization 1.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Titanic Selected column: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: - B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn Normalize Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Parameter: - Selected column: Fare B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Titanic) v\u00e0o stage Normalize Transform. Trong Normalize Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u 2. MinMaxScaler Transform 2.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler 2.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Titanic Selected column: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn MinMaxScaler Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Parameter: Selected column: Fare B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Titanic) v\u00e0o stage MinMaxScaler Transform. Trong MinMaxScaler Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u 3. StandardScaler Transform 3.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler 1.3.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Titanic Selected column: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn StandardScaler Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Parameter: Selected column: Pclass, Fare B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Titanic) v\u00e0o stage StandardScaler Transform. Trong StandardScaler Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u 4. Label Encoder Transform 4.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n https://scikit-learn.org/stable/modules/preprocessing_targets.html#preprocessing-targets 4.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Titanic Selected column: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn Label Encoder Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Parameter: Selected column: Sex B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Titanic) v\u00e0o stage Label Encoder Transform. Trong Label Encoder Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u 5. Ordinal Encoder Transform 5.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features 5.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Titanic Selected column: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn Ordinal Encoder Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Parameter: Selected column: Sex, Embarked B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Titanic) v\u00e0o stage Ordinal Encoder Transform. Trong Ordinal Encoder Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u 6. One Hot Encoder Transform 6.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features 6.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Titanic Selected column: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn One Hot Encoder Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Parameter: Selected column: Sex B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Titanic) v\u00e0o stage One Hot Encoder Transform. Trong One Hot Encoder Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u 7. Simple Imputer Transform 7.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n Thu\u1eadt to\u00e1n \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 x\u1eed l\u00fd handle mising data. https://scikit-learn.org/stable/modules/impute.html#impute 7.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Titanic Selected column: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn Simple Imputer Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Parameter: Selected column: Age B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Titanic) v\u00e0o stage Simple Imputer Transform. Trong Simple Imputer Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u 8. Balances Transform 8.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n https://imbalanced-learn.readthedocs.io/en/stable/api.html 8.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Titanic(Link dataset: https://www.kaggle.com/c/titanic/data) Selected column: Pclass, Fare \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn Balances Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Parameter: Handel method: Random_under_sampling B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Titanic) v\u00e0o stage Balances Transform.Trong Balances Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. (Chi ti\u1ebft t\u1ea1i: https://imbalanced-learn.readthedocs.io/en/stable/api.html) B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 9. Tfidf Transfrom 9.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction 9.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Ch\u1ecdn Text Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp BBC_News Selected column: Content Start record: 0 End record: 9 \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn Tfidf Transfrom b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 3: N\u1ed1i Text Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp BBC_News) v\u00e0o stage Tfidf Transfrom. Trong Tfidf Transfrom c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u 10. CountVectorizer Transform 10.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction 10.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Ch\u1ecdn Text Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp BBC_News Selected column: Content Start record: 0 End record: 9 \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn CountVectorizer Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 3: N\u1ed1i Text Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp BBC_News) v\u00e0o stage CountVectorizer Transform. Trong CountVectorizer Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u 11. Vectorize Transform 11.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n 11.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Titanic Selected column: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn Vectorize Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Parameter: Column Vecterization: Pclass, Fare B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Titanic) v\u00e0o stage Vectorize Transform. Trong Vectorize Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 Supervised Modeling 1. Classification S\u1eed d\u1ee5ng c\u00e1c thu\u1eadt to\u00e1n Supervised Learning \u0111\u1ec3 ph\u00e2n l\u1edbp. Trong ph\u1ea7n n\u00e0y s\u1ebd s\u1eed d\u1ee5ng tr\u1ef1c ti\u1ebfp t\u1eadp d\u1eef li\u1ec7u Iris trong ph\u1ea7n Input c\u1ee7a Scikit.sama \u0111\u1ec3 ph\u00e2n l\u1edbp. \u0110\u00e2y l\u00e0 b\u1ed9 dataset \u0111\u00e3 \u0111\u01b0\u1ee3c ti\u1ec1n x\u1eed l\u00fd g\u1ed3m 4 features: sepal length (cm), sepal width (cm), petal length (cm) v\u00e0 petal width (cm). Target c\u1ee7a b\u1ed9 d\u1eef li\u1ec7u l\u00e0 t\u1eeb 4 features c\u00f3 th\u1ec3 d\u1ef1 \u0111o\u00e1n \u0111\u01b0\u1ee3c n\u00f3 thu\u1ed9c lo\u1ea1i hoa Iris n\u00e0o trong 3 lo\u1ea1i hoa \u0111\u00e3 \u0111\u01b0\u1ee3c encode. Ch\u1ecdn bi\u1ebfu t\u01b0\u1ee3ng \u0111\u1ec3 chia d\u1eef li\u1ec7u th\u00e0nh t\u1eadp train v\u00e0 test. M\u1eb7c \u0111\u1ecbnh l\u00e0 0.7 cho train v\u00e0 0.3 cho test: \u1ea4n Run \u0111\u1ec3 xem d\u1eef li\u1ec7u 1.1. Decision Tree Classifier 1.1.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n Thu\u1eadt to\u00e1n Decision Tree Classifier 1.1.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Trong package scikitsama.ml ph\u1ea7n classification ch\u1ecdn Decision Tree Classifier b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 2: N\u1ed1i Scikit Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Iris) v\u00e0o stage Decision Tree Classifier. Trong Decision Tree Classifier c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html B\u01b0\u1edbc 3: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 B\u01b0\u1edbc 4: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi 2. Regression S\u1eed d\u1ee5ng c\u00e1c thu\u1eadt to\u00e1n Supervised Learning \u0111\u1ec3 d\u1ef1 \u0111o\u00e1n. Trong ph\u1ea7n n\u00e0y s\u1ebd s\u1eed d\u1ee5ng tr\u1ef1c ti\u1ebfp t\u1eadp d\u1eef li\u1ec7u Boston trong ph\u1ea7n Input c\u1ee7a Scikitsama \u0111\u1ec3 th\u1ef1c hi\u1ec7n. B\u1ed9 dataset g\u1ed3m: - id: l\u00e0 c\u1ed9t index c\u1ee7a dataframe - CRIM, ZN, INDUS, CHAS, NOX, RM, AGE, DIS, RAD, TAX, PTRATIO, B, LSTAT l\u00e0 c\u00e1c features(th\u00f4ng tin chi ti\u1ebft: https://scikit-learn.org/stable/datasets/index.html#boston-dataset) - target Gi\u00e1 tr\u1ecb trung v\u1ecb c\u1ee7a c\u00e1c ng\u00f4i nh\u00e0 v\u1edbi \u0111\u01a1n v\u1ecb l\u00e0 ngh\u00ecn \u0111\u00f4 la Ch\u1ecdn bi\u1ebfu t\u01b0\u1ee3ng \u0111\u1ec3 chia d\u1eef li\u1ec7u th\u00e0nh t\u1eadp train v\u00e0 test. M\u1eb7c \u0111\u1ecbnh l\u00e0 0.7 cho train v\u00e0 0.3 cho test: - \u1ea4n Run \u0111\u1ec3 xem d\u1eef li\u1ec7u: 2.1. Decision Tree Regression 2.1.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n https://scikit-learn.org/stable/modules/tree.html#regression 2.1.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Trong package scikitsama.ml ph\u1ea7n regression ch\u1ecdn Decision Tree Regression b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 2: N\u1ed1i Scikit Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Boston) v\u00e0o stage Decision Tree Regression. Trong Decision Tree Regression c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html B\u01b0\u1edbc 3: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 B\u01b0\u1edbc 4: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi 2.2. GBT Regression 2.2.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n https://scikit-learn.org/stable/modules/ensemble.html#regression 2.2.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Trong package scikitsama.ml ph\u1ea7n regression ch\u1ecdn GBT Regression b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 2: N\u1ed1i Scikit Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Boston) v\u00e0o stage GBT Regression. Trong GBT Regression c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html B\u01b0\u1edbc 3: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 - B\u01b0\u1edbc 4: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi 2.3. Isotonic Regression 2.3.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n https://scikit-learn.org/stable/modules/isotonic.html 2.3.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n L\u01b0u \u00fd: Thu\u1eadt to\u00e1n n\u00e0y, datadet ch\u1ec9 g\u1ed3m 1 feature - B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: - Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Boston - Selected column: CRIM (v\u1edbi thu\u1eadt to\u00e1n n\u00e0y ch\u1ec9 ch\u1ecdn 1 feature) \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n regression ch\u1ecdn Isotonic Regression b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Boston) v\u00e0o stage Isotonic Regression. Trong Isotonic Regression c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.isotonic.IsotonicRegression.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi 2.4. Linear Regression 2.4.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n https://scikit-learn.org/stable/modules/linear_model.html 2.4.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Trong package scikitsama.ml ph\u1ea7n regression ch\u1ecdn Linear Regression b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 2: N\u1ed1i Scikit Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Boston) v\u00e0o stage Linear Regression. Trong Linear Regression c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html B\u01b0\u1edbc 3: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 B\u01b0\u1edbc 4: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi 2.5. LinearSVR Regressor 2.5.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html#sklearn.svm.LinearSVR 2.5.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Trong package scikitsama.ml ph\u1ea7n regression ch\u1ecdn LinearSVR Regressor b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 2: N\u1ed1i Scikit Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Boston) v\u00e0o stage LinearSVR Regressor. Trong LinearSVR Regressor c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html#sklearn.svm.LinearSVR B\u01b0\u1edbc 3: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 B\u01b0\u1edbc 4: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi 2.6. Random Forest Regressor 2.6.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n https://scikit-learn.org/stable/modules/ensemble.html#forest 2.6.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Trong package scikitsama.ml ph\u1ea7n regression ch\u1ecdn Random Forest Regressor b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 2: N\u1ed1i Scikit Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Boston) v\u00e0o stage Random Forest Regressor. Trong Random Forest Regressor c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html B\u01b0\u1edbc 3: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 B\u01b0\u1edbc 4: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi 2.7. SVR Regressor 2.7.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n https://scikit-learn.org/stable/modules/svm.html#svm-regression 2.7.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Trong package scikitsama.ml ph\u1ea7n regression ch\u1ecdn SVR Regressor b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 2: N\u1ed1i Scikit Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Boston) v\u00e0o stage SVR Regressor. Trong SVR Regressor c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html B\u01b0\u1edbc 3: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 B\u01b0\u1edbc 4: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi Unsupervised Modeling 1. Clustering S\u1eed d\u1ee5ng c\u00e1c thu\u1eadt to\u00e1n Unsupervised Learning \u0111\u1ec3 ph\u00e2n c\u1ee5m. Trong ph\u1ea7n n\u00e0y s\u1ebd s\u1eed d\u1ee5ng tr\u1ef1c ti\u1ebfp t\u1eadp d\u1eef li\u1ec7u Iris trong ph\u1ea7n Input c\u1ee7a Scikitsama \u0111\u1ec3 ph\u00e2n c\u1ee5m. \u0110\u00e2y l\u00e0 b\u1ed9 dataset \u0111\u00e3 \u0111\u01b0\u1ee3c ti\u1ec1n x\u1eed l\u00fd g\u1ed3m 4 features: sepal length (cm), sepal width (cm), petal length (cm) v\u00e0 petal width (cm). Target c\u1ee7a b\u1ed9 d\u1eef li\u1ec7u l\u00e0 t\u1eeb 4 features c\u00f3 th\u1ec3 d\u1ef1 \u0111o\u00e1n \u0111\u01b0\u1ee3c n\u00f3 thu\u1ed9c lo\u1ea1i hoa Iris n\u00e0o trong 3 lo\u1ea1i hoa \u0111\u00e3 \u0111\u01b0\u1ee3c encode. Ch\u1ecdn bi\u1ebfu t\u01b0\u1ee3ng \u0111\u1ec3 chia d\u1eef li\u1ec7u th\u00e0nh t\u1eadp train v\u00e0 test. M\u1eb7c \u0111\u1ecbnh l\u00e0 0.7 cho train v\u00e0 0.3 cho test: \u1ea4n Run \u0111\u1ec3 xem d\u1eef li\u1ec7u: 1.1. K-Means Clustering 1.1.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n https://scikit-learn.org/stable/modules/clustering.html#k-means 1.1.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Trong package scikitsama.ml ph\u1ea7n clustering ch\u1ecdn K-Means Clustering b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 2: N\u1ed1i Scikit Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Iris) v\u00e0o stage K-Means Clustering. Trong K-Means Clustering c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html B\u01b0\u1edbc 3: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 B\u01b0\u1edbc 4: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi 1.2. GausianMixtrure Clustering 1.2.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n https://scikit-learn.org/stable/modules/mixture.html#gmm 1.2.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Trong package scikitsama.ml ph\u1ea7n clustering ch\u1ecdn GausianMixtrure Clustering b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 2: N\u1ed1i Scikit Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Iris) v\u00e0o stage GausianMixtrure Clustering. Trong GausianMixtrure Clustering c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html B\u01b0\u1edbc 3: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 B\u01b0\u1edbc 4: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi Evaluation","title":"Scikit-learn Machine Learning Pipeline"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#machine-learning-pipeline-with-scikitsama","text":"","title":"MACHINE LEARNING PIPELINE WITH SCIKITSAMA"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#scikitsama","text":"M\u1ee5c \u0111\u00edch c\u1ee7a h\u01b0\u1edbng d\u1eabn n\u00e0y l\u00e0 \u0111\u1ec3 minh h\u1ecda m\u1ed9t s\u1ed1 t\u00ednh n\u0103ng ch\u00ednh scikit.sama cung c\u1ea5p.","title":"Scikitsama"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#data-import-and-manipulation","text":"T\u1eeb c\u00e1c t\u1eadp dataset \u0111\u00e3 \u0111\u01b0a v\u00e0o Data source, \u0111\u1ec3 s\u1eed d\u1ee5ng dataset \u0111\u00f3 trong Flow, ng\u01b0\u1eddi d\u00f9ng c\u1ea7n import d\u1eef li\u1ec7u. \u0110\u1ec3 import d\u1eef li\u1ec7u, ng\u01b0\u1eddi d\u00f9ng s\u1eed d\u1ee5ng c\u00e1c stage Input l\u1ef1a ch\u1ecdn t\u1eeb nh\u00f3m stage Input. V\u1edbi m\u1ed7i d\u1ea1ng data source s\u1ebd c\u00f3 Stage import d\u1eef li\u1ec7u ri\u00eang , c\u00f3 c\u00e1c stage Input nh\u01b0 sau: Tabular Input : Stage input cho d\u1eef li\u1ec7u ngu\u1ed3n s\u1eed d\u1ee5ng l\u00e0 d\u1ea1ng b\u1ea3ng. Text Input : Stage input t\u01b0\u01a1ng d\u1eef li\u1ec7u ngu\u1ed3n s\u1eed d\u1ee5ng l\u00e0 d\u1ea1ng text. Timeseries Input : Stage input cho d\u1eef li\u1ec7u ngu\u1ed3n s\u1eed d\u1ee5ng l\u00e0 d\u1ea1ng chu\u1ed7i th\u1eddi gian. Image Input : Stage input cho ngu\u1ed3n d\u1eef li\u1ec7u s\u1eed d\u1ee5ng l\u00e0 d\u1ea1ng \u1ea3nh. Image Input for Classification : Image Input for Segmentation : Maps Input : Input d\u1eef li\u1ec7u th\u1ec3 hi\u1ec7n tr\u00ean b\u1ea3n \u0111\u1ed3. Scikit Iput : Input d\u1eef li\u1ec7u d\u00f9ng cho th\u01b0 vi\u1ec7n scikit learn, c\u00f3 s\u1eb5n m\u1ed9t s\u1ed1 dataset kinh \u0111i\u1ec3n. Kh\u00f4ng c\u1ea7n ph\u1ea3i t\u1ea1o data source. ### C\u00e1c thao t\u00e1c \u0110\u1ec3 import data v\u00e0o grid flow editor: 1. Click l\u1ef1a ch\u1ecdn stage Input ph\u00f9 h\u1ee3p v\u1edbi data source \u0111\u00e3 t\u1ea1o v\u00e0 mu\u1ed1n s\u1eed d\u1ee5ng( v\u00ed d\u1ee5 \u0111\u00e3 t\u1ea1o datasource tabular \u0111\u1ec3 s\u1eed d\u1ee5ng ta c\u1ea7n ch\u1ecdn Tabular Input ) 1. Click l\u1ea1i v\u00e0o v\u00f9ng grid \u0111\u1ec3 \u0111\u01b0a stage Input \u0111\u00f3 v\u00e0o 1. T\u00f9y ch\u1ecdn thu\u1ed9c t\u00ednh c\u1ee7a stage \u1edf menu ph\u1ea3i stage properties 1. Click Run \u0111\u1ec3 visualize data \u0111\u01b0a v\u00e0o v\u00e0 quan s\u00e1t d\u1eef li\u1ec7u.","title":"Data Import and manipulation"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#data-preprocessing","text":"","title":"Data Preprocessing"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#transform","text":"","title":"Transform"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#1-normalize-transform","text":"","title":"1. Normalize Transform"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#11-mo-ta-thuat-toan","text":"Preprocessing data: https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-normalization","title":"1.1.  M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#12-cac-buoc-thuc-hien","text":"B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Titanic Selected column: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: - B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn Normalize Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Parameter: - Selected column: Fare B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Titanic) v\u00e0o stage Normalize Transform. Trong Normalize Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u","title":"1.2.  C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#2-minmaxscaler-transform","text":"","title":"2. MinMaxScaler Transform"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#21-mo-ta-thuat-toan","text":"https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler","title":"2.1.  M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#22-cac-buoc-thuc-hien","text":"B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Titanic Selected column: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn MinMaxScaler Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Parameter: Selected column: Fare B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Titanic) v\u00e0o stage MinMaxScaler Transform. Trong MinMaxScaler Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u","title":"2.2.  C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#3-standardscaler-transform","text":"","title":"3. StandardScaler Transform"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#31-mo-ta-thuat-toan","text":"https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler 1.3.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Titanic Selected column: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn StandardScaler Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Parameter: Selected column: Pclass, Fare B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Titanic) v\u00e0o stage StandardScaler Transform. Trong StandardScaler Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u","title":"3.1.  M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#4-label-encoder-transform","text":"","title":"4. Label Encoder Transform"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#41-mo-ta-thuat-toan","text":"https://scikit-learn.org/stable/modules/preprocessing_targets.html#preprocessing-targets","title":"4.1.  M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#42-cac-buoc-thuc-hien","text":"B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Titanic Selected column: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn Label Encoder Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Parameter: Selected column: Sex B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Titanic) v\u00e0o stage Label Encoder Transform. Trong Label Encoder Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u","title":"4.2.  C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#5-ordinal-encoder-transform","text":"","title":"5. Ordinal Encoder Transform"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#51-mo-ta-thuat-toan","text":"https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features","title":"5.1.  M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#52-cac-buoc-thuc-hien","text":"B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Titanic Selected column: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn Ordinal Encoder Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Parameter: Selected column: Sex, Embarked B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Titanic) v\u00e0o stage Ordinal Encoder Transform. Trong Ordinal Encoder Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u","title":"5.2.  C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#6-one-hot-encoder-transform","text":"","title":"6. One Hot Encoder Transform"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#61-mo-ta-thuat-toan","text":"https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features","title":"6.1.  M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#62-cac-buoc-thuc-hien","text":"B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Titanic Selected column: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn One Hot Encoder Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Parameter: Selected column: Sex B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Titanic) v\u00e0o stage One Hot Encoder Transform. Trong One Hot Encoder Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u","title":"6.2.  C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#7-simple-imputer-transform","text":"","title":"7. Simple Imputer Transform"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#71-mo-ta-thuat-toan","text":"Thu\u1eadt to\u00e1n \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 x\u1eed l\u00fd handle mising data. https://scikit-learn.org/stable/modules/impute.html#impute","title":"7.1.  M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#72-cac-buoc-thuc-hien","text":"B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Titanic Selected column: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn Simple Imputer Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Parameter: Selected column: Age B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Titanic) v\u00e0o stage Simple Imputer Transform. Trong Simple Imputer Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u","title":"7.2.  C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#8-balances-transform","text":"","title":"8. Balances Transform"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#81-mo-ta-thuat-toan","text":"https://imbalanced-learn.readthedocs.io/en/stable/api.html","title":"8.1.  M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#82-cac-buoc-thuc-hien","text":"B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Titanic(Link dataset: https://www.kaggle.com/c/titanic/data) Selected column: Pclass, Fare \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn Balances Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Parameter: Handel method: Random_under_sampling B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Titanic) v\u00e0o stage Balances Transform.Trong Balances Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. (Chi ti\u1ebft t\u1ea1i: https://imbalanced-learn.readthedocs.io/en/stable/api.html) B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3","title":"8.2.  C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#9-tfidf-transfrom","text":"","title":"9. Tfidf Transfrom"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#91-mo-ta-thuat-toan","text":"https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction","title":"9.1.  M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#92-cac-buoc-thuc-hien","text":"B\u01b0\u1edbc 1: Ch\u1ecdn Text Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp BBC_News Selected column: Content Start record: 0 End record: 9 \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn Tfidf Transfrom b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 3: N\u1ed1i Text Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp BBC_News) v\u00e0o stage Tfidf Transfrom. Trong Tfidf Transfrom c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u","title":"9.2.  C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#10-countvectorizer-transform","text":"","title":"10.    CountVectorizer Transform"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#101-mo-ta-thuat-toan","text":"https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction","title":"10.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#102-cac-buoc-thuc-hien","text":"B\u01b0\u1edbc 1: Ch\u1ecdn Text Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp BBC_News Selected column: Content Start record: 0 End record: 9 \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn CountVectorizer Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 3: N\u1ed1i Text Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp BBC_News) v\u00e0o stage CountVectorizer Transform. Trong CountVectorizer Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u","title":"10.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#11-vectorize-transform","text":"","title":"11.    Vectorize Transform"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#111-mo-ta-thuat-toan","text":"","title":"11.1. M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#112-cac-buoc-thuc-hien","text":"B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Titanic Selected column: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n transform ch\u1ecdn Vectorize Transform b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. Parameter: Column Vecterization: Pclass, Fare B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Titanic) v\u00e0o stage Vectorize Transform. Trong Vectorize Transform c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3","title":"11.2. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#supervised-modeling","text":"","title":"Supervised Modeling"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#1-classification","text":"S\u1eed d\u1ee5ng c\u00e1c thu\u1eadt to\u00e1n Supervised Learning \u0111\u1ec3 ph\u00e2n l\u1edbp. Trong ph\u1ea7n n\u00e0y s\u1ebd s\u1eed d\u1ee5ng tr\u1ef1c ti\u1ebfp t\u1eadp d\u1eef li\u1ec7u Iris trong ph\u1ea7n Input c\u1ee7a Scikit.sama \u0111\u1ec3 ph\u00e2n l\u1edbp. \u0110\u00e2y l\u00e0 b\u1ed9 dataset \u0111\u00e3 \u0111\u01b0\u1ee3c ti\u1ec1n x\u1eed l\u00fd g\u1ed3m 4 features: sepal length (cm), sepal width (cm), petal length (cm) v\u00e0 petal width (cm). Target c\u1ee7a b\u1ed9 d\u1eef li\u1ec7u l\u00e0 t\u1eeb 4 features c\u00f3 th\u1ec3 d\u1ef1 \u0111o\u00e1n \u0111\u01b0\u1ee3c n\u00f3 thu\u1ed9c lo\u1ea1i hoa Iris n\u00e0o trong 3 lo\u1ea1i hoa \u0111\u00e3 \u0111\u01b0\u1ee3c encode. Ch\u1ecdn bi\u1ebfu t\u01b0\u1ee3ng \u0111\u1ec3 chia d\u1eef li\u1ec7u th\u00e0nh t\u1eadp train v\u00e0 test. M\u1eb7c \u0111\u1ecbnh l\u00e0 0.7 cho train v\u00e0 0.3 cho test: \u1ea4n Run \u0111\u1ec3 xem d\u1eef li\u1ec7u","title":"1. Classification"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#11-decision-tree-classifier","text":"","title":"1.1.   Decision Tree Classifier"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#111-mo-ta-thuat-toan_1","text":"Thu\u1eadt to\u00e1n Decision Tree Classifier","title":"1.1.1.    M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#112-cac-buoc-thuc-hien_1","text":"B\u01b0\u1edbc 1: Trong package scikitsama.ml ph\u1ea7n classification ch\u1ecdn Decision Tree Classifier b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 2: N\u1ed1i Scikit Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Iris) v\u00e0o stage Decision Tree Classifier. Trong Decision Tree Classifier c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html B\u01b0\u1edbc 3: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 B\u01b0\u1edbc 4: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi","title":"1.1.2.    C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#2-regression","text":"S\u1eed d\u1ee5ng c\u00e1c thu\u1eadt to\u00e1n Supervised Learning \u0111\u1ec3 d\u1ef1 \u0111o\u00e1n. Trong ph\u1ea7n n\u00e0y s\u1ebd s\u1eed d\u1ee5ng tr\u1ef1c ti\u1ebfp t\u1eadp d\u1eef li\u1ec7u Boston trong ph\u1ea7n Input c\u1ee7a Scikitsama \u0111\u1ec3 th\u1ef1c hi\u1ec7n. B\u1ed9 dataset g\u1ed3m: - id: l\u00e0 c\u1ed9t index c\u1ee7a dataframe - CRIM, ZN, INDUS, CHAS, NOX, RM, AGE, DIS, RAD, TAX, PTRATIO, B, LSTAT l\u00e0 c\u00e1c features(th\u00f4ng tin chi ti\u1ebft: https://scikit-learn.org/stable/datasets/index.html#boston-dataset) - target Gi\u00e1 tr\u1ecb trung v\u1ecb c\u1ee7a c\u00e1c ng\u00f4i nh\u00e0 v\u1edbi \u0111\u01a1n v\u1ecb l\u00e0 ngh\u00ecn \u0111\u00f4 la Ch\u1ecdn bi\u1ebfu t\u01b0\u1ee3ng \u0111\u1ec3 chia d\u1eef li\u1ec7u th\u00e0nh t\u1eadp train v\u00e0 test. M\u1eb7c \u0111\u1ecbnh l\u00e0 0.7 cho train v\u00e0 0.3 cho test: - \u1ea4n Run \u0111\u1ec3 xem d\u1eef li\u1ec7u:","title":"2. Regression"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#21-decision-tree-regression","text":"","title":"2.1.   Decision Tree Regression"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#211-mo-ta-thuat-toan","text":"https://scikit-learn.org/stable/modules/tree.html#regression","title":"2.1.1.    M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#212-cac-buoc-thuc-hien","text":"B\u01b0\u1edbc 1: Trong package scikitsama.ml ph\u1ea7n regression ch\u1ecdn Decision Tree Regression b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 2: N\u1ed1i Scikit Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Boston) v\u00e0o stage Decision Tree Regression. Trong Decision Tree Regression c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html B\u01b0\u1edbc 3: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 B\u01b0\u1edbc 4: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi","title":"2.1.2.    C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#22-gbt-regression","text":"","title":"2.2.   GBT Regression"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#221-mo-ta-thuat-toan","text":"https://scikit-learn.org/stable/modules/ensemble.html#regression","title":"2.2.1.    M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#222-cac-buoc-thuc-hien","text":"B\u01b0\u1edbc 1: Trong package scikitsama.ml ph\u1ea7n regression ch\u1ecdn GBT Regression b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 2: N\u1ed1i Scikit Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Boston) v\u00e0o stage GBT Regression. Trong GBT Regression c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html B\u01b0\u1edbc 3: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 - B\u01b0\u1edbc 4: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi","title":"2.2.2.    C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#23-isotonic-regression","text":"","title":"2.3.   Isotonic Regression"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#231-mo-ta-thuat-toan","text":"https://scikit-learn.org/stable/modules/isotonic.html","title":"2.3.1.    M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#232-cac-buoc-thuc-hien","text":"L\u01b0u \u00fd: Thu\u1eadt to\u00e1n n\u00e0y, datadet ch\u1ec9 g\u1ed3m 1 feature - B\u01b0\u1edbc 1: Ch\u1ecdn Tabular Input trong Input.Ph\u1ea7n parameter: - Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp Boston - Selected column: CRIM (v\u1edbi thu\u1eadt to\u00e1n n\u00e0y ch\u1ec9 ch\u1ecdn 1 feature) \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package scikitsama.ml ph\u1ea7n regression ch\u1ecdn Isotonic Regression b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 3: N\u1ed1i Tabular Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Boston) v\u00e0o stage Isotonic Regression. Trong Isotonic Regression c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.isotonic.IsotonicRegression.html B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi","title":"2.3.2.    C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#24-linear-regression","text":"","title":"2.4.   Linear Regression"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#241-mo-ta-thuat-toan","text":"https://scikit-learn.org/stable/modules/linear_model.html","title":"2.4.1.    M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#242-cac-buoc-thuc-hien","text":"B\u01b0\u1edbc 1: Trong package scikitsama.ml ph\u1ea7n regression ch\u1ecdn Linear Regression b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 2: N\u1ed1i Scikit Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Boston) v\u00e0o stage Linear Regression. Trong Linear Regression c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html B\u01b0\u1edbc 3: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 B\u01b0\u1edbc 4: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi","title":"2.4.2.    C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#25-linearsvr-regressor","text":"","title":"2.5.   LinearSVR Regressor"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#251-mo-ta-thuat-toan","text":"https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html#sklearn.svm.LinearSVR","title":"2.5.1.    M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#252-cac-buoc-thuc-hien","text":"B\u01b0\u1edbc 1: Trong package scikitsama.ml ph\u1ea7n regression ch\u1ecdn LinearSVR Regressor b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 2: N\u1ed1i Scikit Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Boston) v\u00e0o stage LinearSVR Regressor. Trong LinearSVR Regressor c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html#sklearn.svm.LinearSVR B\u01b0\u1edbc 3: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 B\u01b0\u1edbc 4: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi","title":"2.5.2.    C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#26-random-forest-regressor","text":"","title":"2.6.   Random Forest Regressor"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#261-mo-ta-thuat-toan","text":"https://scikit-learn.org/stable/modules/ensemble.html#forest","title":"2.6.1.    M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#262-cac-buoc-thuc-hien","text":"B\u01b0\u1edbc 1: Trong package scikitsama.ml ph\u1ea7n regression ch\u1ecdn Random Forest Regressor b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 2: N\u1ed1i Scikit Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Boston) v\u00e0o stage Random Forest Regressor. Trong Random Forest Regressor c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html B\u01b0\u1edbc 3: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 B\u01b0\u1edbc 4: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi","title":"2.6.2.    C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#27-svr-regressor","text":"","title":"2.7.   SVR Regressor"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#271-mo-ta-thuat-toan","text":"https://scikit-learn.org/stable/modules/svm.html#svm-regression","title":"2.7.1.    M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#272-cac-buoc-thuc-hien","text":"B\u01b0\u1edbc 1: Trong package scikitsama.ml ph\u1ea7n regression ch\u1ecdn SVR Regressor b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 2: N\u1ed1i Scikit Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Boston) v\u00e0o stage SVR Regressor. Trong SVR Regressor c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html B\u01b0\u1edbc 3: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 B\u01b0\u1edbc 4: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi","title":"2.7.2.    C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#unsupervised-modeling","text":"","title":"Unsupervised Modeling"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#1-clustering","text":"S\u1eed d\u1ee5ng c\u00e1c thu\u1eadt to\u00e1n Unsupervised Learning \u0111\u1ec3 ph\u00e2n c\u1ee5m. Trong ph\u1ea7n n\u00e0y s\u1ebd s\u1eed d\u1ee5ng tr\u1ef1c ti\u1ebfp t\u1eadp d\u1eef li\u1ec7u Iris trong ph\u1ea7n Input c\u1ee7a Scikitsama \u0111\u1ec3 ph\u00e2n c\u1ee5m. \u0110\u00e2y l\u00e0 b\u1ed9 dataset \u0111\u00e3 \u0111\u01b0\u1ee3c ti\u1ec1n x\u1eed l\u00fd g\u1ed3m 4 features: sepal length (cm), sepal width (cm), petal length (cm) v\u00e0 petal width (cm). Target c\u1ee7a b\u1ed9 d\u1eef li\u1ec7u l\u00e0 t\u1eeb 4 features c\u00f3 th\u1ec3 d\u1ef1 \u0111o\u00e1n \u0111\u01b0\u1ee3c n\u00f3 thu\u1ed9c lo\u1ea1i hoa Iris n\u00e0o trong 3 lo\u1ea1i hoa \u0111\u00e3 \u0111\u01b0\u1ee3c encode. Ch\u1ecdn bi\u1ebfu t\u01b0\u1ee3ng \u0111\u1ec3 chia d\u1eef li\u1ec7u th\u00e0nh t\u1eadp train v\u00e0 test. M\u1eb7c \u0111\u1ecbnh l\u00e0 0.7 cho train v\u00e0 0.3 cho test: \u1ea4n Run \u0111\u1ec3 xem d\u1eef li\u1ec7u:","title":"1.  Clustering"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#11-k-means-clustering","text":"","title":"1.1.   K-Means Clustering"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#111-mo-ta-thuat-toan_2","text":"https://scikit-learn.org/stable/modules/clustering.html#k-means","title":"1.1.1.    M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#112-cac-buoc-thuc-hien_2","text":"B\u01b0\u1edbc 1: Trong package scikitsama.ml ph\u1ea7n clustering ch\u1ecdn K-Means Clustering b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 2: N\u1ed1i Scikit Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Iris) v\u00e0o stage K-Means Clustering. Trong K-Means Clustering c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html B\u01b0\u1edbc 3: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 B\u01b0\u1edbc 4: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi","title":"1.1.2.    C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#12-gausianmixtrure-clustering","text":"","title":"1.2.   GausianMixtrure Clustering"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#121-mo-ta-thuat-toan","text":"https://scikit-learn.org/stable/modules/mixture.html#gmm","title":"1.2.1.    M\u00f4 t\u1ea3 thu\u1eadt to\u00e1n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#122-cac-buoc-thuc-hien","text":"B\u01b0\u1edbc 1: Trong package scikitsama.ml ph\u1ea7n clustering ch\u1ecdn GausianMixtrure Clustering b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 2: N\u1ed1i Scikit Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp Iris) v\u00e0o stage GausianMixtrure Clustering. Trong GausianMixtrure Clustering c\u00f3 c\u00e1c tham s\u1ed1 \u0111\u1ec3 l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o t\u1eebng b\u00e0i to\u00e1n. \u00dd ngh\u0129a c\u1ee7a t\u1eebng tham s\u1ed1 c\u00f3 th\u1ec3 xem th\u00f4ng tin chi ti\u1ebft t\u1ea1i: https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html B\u01b0\u1edbc 3: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 nh\u00ecn v\u00e0o b\u1ea3ng Metrics table v\u00e0 2 c\u1ed9t target v\u00e0 y_pred \u0111\u1ec3 xem k\u1ebft qu\u1ea3 B\u01b0\u1edbc 4: Model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng l\u01b0u l\u1ea1i sau khi train xong v\u00e0 \u0111\u01b0\u1ee3c \u0111\u00e1nh d\u1ea5u t\u00edch m\u00e0u xanh b\u00ean d\u01b0\u1edbi","title":"1.2.2.    C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n"},{"location":"VN/vn_machine_learning_pipeline_scikitsama/#evaluation","text":"","title":"Evaluation"},{"location":"VN/vn_pyvisama/","text":"MACHINE LEARING - NLP - PYVISAMA 1. Add Accents Transformer B\u01b0\u1edbc 1: Ch\u1ecdn Text Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp VLSP 2016 dataset (Link dataset:). T\u1eadp dataset n\u00e0y g\u1ed3m 3 c\u1ed9t. C\u1ed9t th\u1ee9 nh\u1ea5t l\u00e0 index, c\u1ed9t th\u1ee9 2 l\u00e0 n\u1ed9i dung \u0111\u00e1nh gi\u00e1 v\u1ec1 s\u1ea3n ph\u1ea9m c\u1ee7a kh\u00e1ch h\u00e0ng, c\u1ed9t th\u1ee9 3 l\u00e0 label(\u0111\u00e1nh gi\u00e1 c\u1ee7a kh\u00e1ch h\u00e0ng g\u1ed3m 3 m\u1ee9c: POS, NEG, NEU) Selected column: sentence \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package pyvisama ch\u1ecdn Remove Accents Transformer b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc n\u00e0y d\u00f9ng \u0111\u1ec3 xo\u00e1 d\u1ea5u ti\u1ebfng Vi\u1ec7t. B\u01b0\u1edbc 3: N\u1ed1i Text Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp VLSP 2016 dataset) v\u00e0o stage Remove Accents Transformer. B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Trong package pyvisama ch\u1ecdn Add Accents Transformer b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc n\u00e0y \u0111\u1ec3 th\u00eam l\u1ea1i d\u1ea5u cho ti\u1ebfng Vi\u1ec7t. B\u01b0\u1edbc 6: N\u1ed1i Remove Accents Transformer v\u00e0o stage Add Accents Transformer. B\u01b0\u1edbc 7: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 2. Remove Accents Transformer B\u01b0\u1edbc 1: Ch\u1ecdn Text Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp VLSP 2016 dataset (Link dataset:). T\u1eadp dataset n\u00e0y g\u1ed3m 3 c\u1ed9t. C\u1ed9t th\u1ee9 nh\u1ea5t l\u00e0 index, c\u1ed9t th\u1ee9 2 l\u00e0 n\u1ed9i dung \u0111\u00e1nh gi\u00e1 v\u1ec1 s\u1ea3n ph\u1ea9m c\u1ee7a kh\u00e1ch h\u00e0ng, c\u1ed9t th\u1ee9 3 l\u00e0 label(\u0111\u00e1nh gi\u00e1 c\u1ee7a kh\u00e1ch h\u00e0ng g\u1ed3m 3 m\u1ee9c: POS, NEG, NEU) Selected column: sentence \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package pyvisama ch\u1ecdn Remove Accents Transformer b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 3: N\u1ed1i Text Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp VLSP 2016 dataset) v\u00e0o stage Remove Accents Transformer B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 3. ViPosTagger Transformer B\u01b0\u1edbc 1: Ch\u1ecdn Text Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp VLSP 2016 dataset (Link dataset:). T\u1eadp dataset n\u00e0y g\u1ed3m 3 c\u1ed9t. C\u1ed9t th\u1ee9 nh\u1ea5t l\u00e0 index, c\u1ed9t th\u1ee9 2 l\u00e0 n\u1ed9i dung \u0111\u00e1nh gi\u00e1 v\u1ec1 s\u1ea3n ph\u1ea9m c\u1ee7a kh\u00e1ch h\u00e0ng, c\u1ed9t th\u1ee9 3 l\u00e0 label(\u0111\u00e1nh gi\u00e1 c\u1ee7a kh\u00e1ch h\u00e0ng g\u1ed3m 3 m\u1ee9c: POS, NEG, NEU) Selected column: sentence \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package pyvisama ch\u1ecdn ViTokenizer Transformer b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc n\u00e0y d\u00f9ng \u0111\u1ec3 t\u00e1ch t\u1eeb trong ti\u1ebfng Vi\u1ec7t. B\u01b0\u1edbc 3: N\u1ed1i Text Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp VLSP 2016 dataset) v\u00e0o stage ViTokenizer Transformer. B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Trong package pyvisama ch\u1ecdn ViPosTagger Transformer b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc n\u00e0y x\u00e1c \u0111\u1ecbnh xem t\u1eeb v\u1eeba t\u00e1ch b\u00ean tr\u00ean thu\u1ed9c lo\u1ea1i t\u1eeb n\u00e0o. B\u01b0\u1edbc 6: N\u1ed1i ViTokenizer Transformer v\u00e0o stage ViPosTagger Transformer. B\u01b0\u1edbc 7: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 4. ViTokenizer Transformer B\u01b0\u1edbc 1: Ch\u1ecdn Text Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp VLSP 2016 dataset (Link dataset:). T\u1eadp dataset n\u00e0y g\u1ed3m 3 c\u1ed9t. C\u1ed9t th\u1ee9 nh\u1ea5t l\u00e0 index, c\u1ed9t th\u1ee9 2 l\u00e0 n\u1ed9i dung \u0111\u00e1nh gi\u00e1 v\u1ec1 s\u1ea3n ph\u1ea9m c\u1ee7a kh\u00e1ch h\u00e0ng, c\u1ed9t th\u1ee9 3 l\u00e0 label(\u0111\u00e1nh gi\u00e1 c\u1ee7a kh\u00e1ch h\u00e0ng g\u1ed3m 3 m\u1ee9c: POS, NEG, NEU) Selected column: sentence \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package pyvisama ch\u1ecdn ViTokenizer Transformer b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 3: N\u1ed1i Text Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp VLSP 2016 dataset) v\u00e0o stage ViTokenizer Transformer. B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3","title":"Pyvi Tutorial"},{"location":"VN/vn_pyvisama/#machine-learing-nlp-pyvisama","text":"","title":"MACHINE LEARING  - NLP - PYVISAMA"},{"location":"VN/vn_pyvisama/#1-add-accents-transformer","text":"B\u01b0\u1edbc 1: Ch\u1ecdn Text Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp VLSP 2016 dataset (Link dataset:). T\u1eadp dataset n\u00e0y g\u1ed3m 3 c\u1ed9t. C\u1ed9t th\u1ee9 nh\u1ea5t l\u00e0 index, c\u1ed9t th\u1ee9 2 l\u00e0 n\u1ed9i dung \u0111\u00e1nh gi\u00e1 v\u1ec1 s\u1ea3n ph\u1ea9m c\u1ee7a kh\u00e1ch h\u00e0ng, c\u1ed9t th\u1ee9 3 l\u00e0 label(\u0111\u00e1nh gi\u00e1 c\u1ee7a kh\u00e1ch h\u00e0ng g\u1ed3m 3 m\u1ee9c: POS, NEG, NEU) Selected column: sentence \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package pyvisama ch\u1ecdn Remove Accents Transformer b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc n\u00e0y d\u00f9ng \u0111\u1ec3 xo\u00e1 d\u1ea5u ti\u1ebfng Vi\u1ec7t. B\u01b0\u1edbc 3: N\u1ed1i Text Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp VLSP 2016 dataset) v\u00e0o stage Remove Accents Transformer. B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Trong package pyvisama ch\u1ecdn Add Accents Transformer b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc n\u00e0y \u0111\u1ec3 th\u00eam l\u1ea1i d\u1ea5u cho ti\u1ebfng Vi\u1ec7t. B\u01b0\u1edbc 6: N\u1ed1i Remove Accents Transformer v\u00e0o stage Add Accents Transformer. B\u01b0\u1edbc 7: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3","title":"1.   Add Accents Transformer"},{"location":"VN/vn_pyvisama/#2-remove-accents-transformer","text":"B\u01b0\u1edbc 1: Ch\u1ecdn Text Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp VLSP 2016 dataset (Link dataset:). T\u1eadp dataset n\u00e0y g\u1ed3m 3 c\u1ed9t. C\u1ed9t th\u1ee9 nh\u1ea5t l\u00e0 index, c\u1ed9t th\u1ee9 2 l\u00e0 n\u1ed9i dung \u0111\u00e1nh gi\u00e1 v\u1ec1 s\u1ea3n ph\u1ea9m c\u1ee7a kh\u00e1ch h\u00e0ng, c\u1ed9t th\u1ee9 3 l\u00e0 label(\u0111\u00e1nh gi\u00e1 c\u1ee7a kh\u00e1ch h\u00e0ng g\u1ed3m 3 m\u1ee9c: POS, NEG, NEU) Selected column: sentence \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package pyvisama ch\u1ecdn Remove Accents Transformer b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 3: N\u1ed1i Text Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp VLSP 2016 dataset) v\u00e0o stage Remove Accents Transformer B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3","title":"2.   Remove Accents Transformer"},{"location":"VN/vn_pyvisama/#3-vipostagger-transformer","text":"B\u01b0\u1edbc 1: Ch\u1ecdn Text Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp VLSP 2016 dataset (Link dataset:). T\u1eadp dataset n\u00e0y g\u1ed3m 3 c\u1ed9t. C\u1ed9t th\u1ee9 nh\u1ea5t l\u00e0 index, c\u1ed9t th\u1ee9 2 l\u00e0 n\u1ed9i dung \u0111\u00e1nh gi\u00e1 v\u1ec1 s\u1ea3n ph\u1ea9m c\u1ee7a kh\u00e1ch h\u00e0ng, c\u1ed9t th\u1ee9 3 l\u00e0 label(\u0111\u00e1nh gi\u00e1 c\u1ee7a kh\u00e1ch h\u00e0ng g\u1ed3m 3 m\u1ee9c: POS, NEG, NEU) Selected column: sentence \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package pyvisama ch\u1ecdn ViTokenizer Transformer b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc n\u00e0y d\u00f9ng \u0111\u1ec3 t\u00e1ch t\u1eeb trong ti\u1ebfng Vi\u1ec7t. B\u01b0\u1edbc 3: N\u1ed1i Text Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp VLSP 2016 dataset) v\u00e0o stage ViTokenizer Transformer. B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3 B\u01b0\u1edbc 5: Trong package pyvisama ch\u1ecdn ViPosTagger Transformer b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc n\u00e0y x\u00e1c \u0111\u1ecbnh xem t\u1eeb v\u1eeba t\u00e1ch b\u00ean tr\u00ean thu\u1ed9c lo\u1ea1i t\u1eeb n\u00e0o. B\u01b0\u1edbc 6: N\u1ed1i ViTokenizer Transformer v\u00e0o stage ViPosTagger Transformer. B\u01b0\u1edbc 7: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3","title":"3.   ViPosTagger Transformer"},{"location":"VN/vn_pyvisama/#4-vitokenizer-transformer","text":"B\u01b0\u1edbc 1: Ch\u1ecdn Text Input trong Input.Ph\u1ea7n parameter: Dataset: \u1ede \u0111\u00e2y d\u00f9ng t\u1eadp VLSP 2016 dataset (Link dataset:). T\u1eadp dataset n\u00e0y g\u1ed3m 3 c\u1ed9t. C\u1ed9t th\u1ee9 nh\u1ea5t l\u00e0 index, c\u1ed9t th\u1ee9 2 l\u00e0 n\u1ed9i dung \u0111\u00e1nh gi\u00e1 v\u1ec1 s\u1ea3n ph\u1ea9m c\u1ee7a kh\u00e1ch h\u00e0ng, c\u1ed9t th\u1ee9 3 l\u00e0 label(\u0111\u00e1nh gi\u00e1 c\u1ee7a kh\u00e1ch h\u00e0ng g\u1ed3m 3 m\u1ee9c: POS, NEG, NEU) Selected column: sentence \u1ea4n RUN \u0111\u1ec3 xem d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o: B\u01b0\u1edbc 2: Trong package pyvisama ch\u1ecdn ViTokenizer Transformer b\u1eb1ng c\u00e1ch k\u00edch chu\u1ed9t v\u00e0o n\u00f3 v\u00e0 sau \u0111\u00f3 di chu\u1ed9t ra m\u00e0n h\u00ecnh l\u00e0m vi\u1ec7c, k\u00edch chu\u1ed9t v\u00e0o v\u1ecb tr\u00ed c\u1ea7n \u0111\u1eb7t stage. B\u01b0\u1edbc 3: N\u1ed1i Text Input(l\u00e0 t\u1eadp dataset cho b\u00e0i to\u00e1n nh\u01b0 \u0111\u00e3 n\u00f3i \u1edf b\u00ean tr\u00ean l\u00e0 t\u1eadp VLSP 2016 dataset) v\u00e0o stage ViTokenizer Transformer. B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 hi\u1ec3n th\u1ecb ra k\u1ebft qu\u1ea3","title":"4.   ViTokenizer Transformer"},{"location":"VN/vn_simpleflow/","text":"","title":"Simple Flow"},{"location":"VN/vn_tutorial/","text":"H\u01b0\u1edbng d\u1eabn s\u1eed d\u1ee5ng DSSAMA cho b\u00e0i to\u00e1n ph\u00e2n t\u00edch d\u1eef li\u1ec7u \u1ede ch\u01b0\u01a1ng n\u00e0y , ch\u00fang t\u00f4i s\u1ebd h\u01b0\u1edbng d\u1eabn ng\u01b0\u1eddi d\u00f9ng s\u1eed d\u1ee5ng \u1ee9ng d\u1ee5ng DSSAMA - N\u1ec1n t\u1ea3ng \u0111\u1ec3 qu\u1ea3n l\u00fd v\u00e0 tri\u1ec3n khai c\u00e1c d\u1ef1 \u00e1n Ph\u00e2n t\u00edch d\u1eef li\u1ec7u l\u1edbn \u0111\u1ec3 ph\u00e2n t\u00edch c\u00e1c b\u00e0i to\u00e1n th\u1ef1c t\u1ebf. Welcome to DSSAMA 1. Predict survival Titanic passengers B\u00e0i to\u00e1n Titanic \u0111i\u1ec3n h\u00ecnh trong ph\u00e2n t\u00edch d\u1ef1 \u0111o\u00e1n d\u1eef li\u1ec7u B\u00e0i to\u00e1n : V\u00e0o ng\u00e0y 15 th\u00e1ng 4 n\u0103m 1912, th\u1ea3m h\u1ecda Titanic l\u00e0 m\u1ed9t th\u1ea3m h\u1ecda n\u1ed5i ti\u1ebfng nh\u1ea5t trong l\u1ecbch s\u1eed, T\u00e0u RMS Titanic b\u1ecb ch\u00ecm sau khi va ch\u1ea1m v\u1edbi t\u1ea3ng b\u0103ng \u0111\u00e3 c\u01b0\u1edbp \u0111i 1502 sinh m\u1ea1ng tr\u00ean t\u1ed5ng s\u1ed1 2224 h\u00e0nh kh\u00e1ch v\u00e0 th\u1ee7y th\u1ee7 \u0111o\u00e0n, tr\u00f4i v\u1edbi s\u1ed1 li\u1ec7u thu th\u00e2p \u0111\u01b0\u1ee3c qua th\u1ea3m h\u1ecda bao g\u1ed3m s\u1ed1 l\u01b0\u1ee3ng h\u00e0nh kh\u00e1ch. B\u00e0i to\u00e1n l\u00e0 cho m\u1ed9t l\u01b0\u1ee3ng d\u1eef li\u1ec7u training cho tr\u01b0\u1edbc c\u1ee7a 892 h\u00e0nh kh\u00e1ch bao g\u1ed3m c\u00e1c th\u00f4ng tin nh\u01b0 t\u00ean, gi\u1edbi t\u00ednh, tu\u1ed5i, m\u00e3 s\u1ed1 v\u00e9, cabin, gi\u00e1 v\u00e9, quan h\u1ec7 nh\u00e2n th\u00e2n, s\u1ed1 l\u01b0\u01a1ng tr\u1ebb em, h\u1ecd h\u00e0ng, cha m\u1eb9 \u0111i c\u00f9ng, c\u00f2n s\u1ed1ng hay \u0111\u00e3 t\u1eed n\u1ea1n. Output : D\u1eef li\u1ec7u \u0111\u1ea7u ra l\u00e0 \u0111\u01b0a ra d\u1ef1 \u0111o\u00e1n v\u1ec1 kh\u1ea3 n\u0103ng t\u1eed n\u1ea1n c\u1ee7a c\u00e1c h\u00e0nh kh\u00e1ch c\u00f2n l\u1ea1i d\u1ef1a tr\u00ean nh\u1eefng y\u1ebfu t\u1ed1 bi\u1ebft tr\u01b0\u1edbc nh\u01b0 t\u00ean, tu\u1ed5i, gi\u1edbi t\u00ednh, s\u1ed1 ng\u01b0\u1eddi \u0111i c\u00f9ng, v\u1ecb tr\u00ed ph\u00f2ng v\u2026v. \u00dd ngh\u0129a : B\u00e0i to\u00e1n cho ph\u00e9p ch\u00fang ta c\u00f3 th\u1ec3 d\u1ef1a v\u00e0o \u0111\u00f3 \u0111\u1ec3 d\u1ef1 \u0111o\u00e1n kh\u1ea3 n\u0103ng s\u1ed1ng s\u00f3t c\u1ee7a m\u1ed9t ng\u01b0\u1eddi d\u1ef1a tr\u00ean m\u1ed9t th\u1ea3m h\u1ecda t\u1eeb \u0111\u00f3 c\u00f3 th\u1ec3 r\u00fat ra nh\u1eefng kinh nghi\u1ec7m trong c\u00e1c chuy\u1ebfn h\u00e0nh tr\u00ecnh trong t\u01b0\u01a1ng lai, C\u00f3 th\u1ec3 l\u00e0 thi\u1ebft k\u1ebf l\u1ea1i t\u00e0u m\u1ed9t c\u00e1ch an to\u00e0n h\u01a1n, d\u1ecbch v\u1ee5 ch\u0103m s\u00f3c, c\u1ea3nh b\u00e1o v..v Ph\u00e2n t\u00edch : C\u00f3 th\u1ec3 d\u1ec5 nh\u1eadn th\u1ea5y \u0111\u00e2y l\u00e0 m\u1ed9t b\u00e0i Two-Class Classification v\u1edbi k\u1ebft qu\u1ea3 \u0111\u1ea7u ra l\u00e0 NOT_SUVIVAL ho\u1eb7c SUVIVAL. V\u1edbi m\u1ed9t b\u00e0i to\u00e1n Two-Class Classification nh\u01b0 th\u1ebf n\u00e0y c\u00f3 th\u1ec3 gi\u1ea3i b\u1eb1ng nhi\u1ec1u c\u00e1ch v\u00e0 nhi\u1ec1u thu\u1eadt to\u00e1n kh\u00e1c nhau nh\u01b0 Bayes, Decision Tree, Decision Forest \u2026 T\u1eeb m\u1ed9t m\u1eabu d\u1eef li\u1ec7u RMS Titanic, ch\u00fang ta c\u00f3 th\u1ec3 th\u1ea5y c\u00e1c thu\u1ed9c t\u00ednh th\u1ec3 hi\u1ec3n cho m\u1ed7i h\u00e0nh kh\u00e1ch tr\u00ean t\u00e0u: Survial : K\u1ebft qu\u1ea3 s\u1ed1ng s\u00f3t (0 = Kh\u00f4ng; 1 = C\u00f3) Pclass : L\u1edbp kinh t\u1ebf x\u00e3 h\u1ed9i (1 = T\u1ea7ng l\u1edbp th\u01b0\u1ee3ng l\u01b0u; 2 = T\u1ea7ng l\u1edbp trung l\u01b0u; 3 = C\u00e1c t\u1ea7ng l\u1edbp th\u1ea5p) Name : T\u00ean c\u1ee7a h\u00e0nh kh\u00e1ch Sex : Gi\u1edbi t\u00ednh c\u1ee7a h\u00e0nh kh\u00e1ch Age : Tu\u1ed5i c\u1ee7a h\u00e0nh kh\u00e1ch (30% d\u1eef li\u1ec7u tu\u1ed5i c\u1ee7a h\u00e0nh kh\u00e1ch b\u1ecb khuy\u1ebft) SibSp : S\u1ed1 anh ch\u1ecb em ru\u1ed9t v\u00e0 v\u1ee3 / ch\u1ed3ng c\u1ee7a h\u00e0nh kh\u00e1ch tr\u00ean t\u00e0u Parch : S\u1ed1 ph\u1ee5 huynh v\u00e0 tr\u1ebb em c\u1ee7a h\u00e0nh kh\u00e1ch tr\u00ean t\u00e0u Ticket : S\u1ed1 hi\u1ec7u v\u00e9 c\u1ee7a h\u00e0nh kh\u00e1ch Fare : Gi\u00e1 v\u00e9 h\u00e0nh kh\u00e1ch tr\u1ea3 Cabin : s\u1ed1 cabin c\u1ee7a h\u00e0nh kh\u00e1ch (M\u1ed9t s\u1ed1 m\u1ee5c b\u1ecb khuy\u1ebft d\u1eef li\u1ec7u) Embarked : C\u1ea3ng \u0111\u00f3n kh\u00e1ch c\u1ee7a h\u00e0nh kh\u00e1ch (C = Cherbourg; Q = Queenstown; S = Southampton) Get started B\u01b0\u1edbc 1 : T\u1ea1o m\u1edbi Flow Classification for Titanic \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi b\u00e0i to\u00e1n Titanic s\u1eed d\u1ee5ng c\u00e1c M\u00f4 h\u00ecnh h\u1ecdc m\u00e1y ph\u00e2n l\u1edbp. H\u00ecnh 5. Flow Cassification for Titanic v\u1eeba t\u1ea1o Click v\u00e0o Flow Classification for Titanic , giao di\u1ec7n l\u00e0m vi\u1ec7c tr\u1ef1c ti\u1ebfp - DSSAMA Flow hi\u1ec3n th\u1ecb nh\u01b0 trong h\u00ecnh 5. H\u00ecnh 6. Giao di\u1ec7n l\u00e0m vi\u1ec7c tr\u1ef1c ti\u1ebfp Flow Cassification for Titanic B\u01b0\u1edbc 2: Import d\u1eef li\u1ec7u V\u1edbi b\u00e0i to\u00e1n Titanic, data source ban \u0111\u1ea7u kh\u1edfi t\u1ea1o l\u00e0 d\u1ea1ng Tabular, n\u00ean khi import d\u1eef li\u1ec7u , ta s\u1eed d\u1ee5ng Stage Tabular Input. Click l\u1ef1a ch\u1ecdn Stage Tabular Input \u1edf Stage Repository, \u0111\u01b0a sang Dataflow Editor, khi \u0111\u00f3 hi\u1ec3n th\u1ecb c\u1ed9t Stage Properties b\u00ean ph\u1ea3i m\u00e0n h\u00ecnh, ta t\u00f9y ch\u1ec9nh d\u1eef li\u1ec7u s\u1eed d\u1ee5ng cho ph\u00f9 h\u1ee3p. Quan s\u00e1t h\u00ecnh \u1ea3nh Dataset : l\u1ef1a ch\u1ecdn t\u1eadp d\u1eef li\u1ec7u Titanic Selected Comun : l\u1ef1a l\u1ef1a ch\u1ecdn c\u00e1c c\u1ed9t s\u1ebd s\u1eed d\u1ee5ng trong qu\u00e1 tr\u00ecnh x\u1eed l\u00fd d\u1eef li\u1ec7u. \u1ede v\u00ed d\u1ee5 n\u00e0y, c\u00e1c c\u1ed9t thu\u1ed9c t\u00ednh \u0111\u01b0\u1ee3c l\u1ef1a ch\u1ecdn \u0111\u1ec3 \u0111\u01b0a v\u00e0o ph\u00e2n t\u00edch kh\u00f4ng c\u00f3 thu\u1ed9c t\u00ednh Name , Ticket v\u00e0 Cabin : PClass , Sex , Age , SibSp , Parch , Fare , Embarked . Ng\u01b0\u1eddi d\u00f9ng c\u0169ng c\u00f3 th\u1ec3 l\u1ef1a ch\u1ecdn t\u1ea5t c\u1ea3 c\u00e1c c\u1ed9t d\u1eef li\u1ec7u \u0111\u1ec3 ph\u00e2n t\u00edch. Click l\u1ea1i v\u00e0o Stage v\u00e0 click Run \u0111\u1ec3 ki\u1ec3m tra d\u1eef li\u1ec7u import \u0111\u00e3 ch\u00ednh x\u00e1c ch\u01b0a. Sau khi ch\u1ea1y, ta \u0111\u01b0\u1ee3c b\u1ea3ng d\u1eef li\u1ec7u v\u00e0o \u0111\u01b0\u1ee3c bi\u1ec3u di\u1ec5n d\u01b0\u1edbi d\u1ea1ng \u0111\u1ed3 th\u1ecb v\u00e0 hi\u1ec3n th\u1ecb b\u1ea3ng d\u1eef li\u1ec7u v\u00e0o nh\u01b0 sau: B\u01b0\u1edbc 3: X\u1eed l\u00fd d\u1eef li\u1ec7u khuy\u1ebft Trong b\u00e0i to\u00e1n con t\u00e0u RMS Titanic, c\u1ed9t d\u1eef li\u1ec7u Age v\u00e0 Embarked khuy\u1ebft m\u1ed9t s\u1ed1 \u0111\u01a1n v\u1ecb d\u1eef li\u1ec7u n\u00ean c\u1ea7n x\u1eed l\u00fd c\u00e1c d\u1eef li\u1ec7u khuy\u1ebft \u0111\u00f3. \u0110\u1ec3 x\u1eed l\u00fd c\u1ed9t d\u1eef li\u1ec7u Age v\u00e0 Embarked , ch\u1ecdn Stage Simple Imputer Transformer trong m\u1ee5c Transformer c\u1ee7a Scikitsama.ml \u0111\u01b0a v\u00e0o Dataflow Editor.T\u1ea1o k\u1ebft n\u1ed1i output c\u1ee7a Stage Tabular Input l\u00e0 input c\u1ee7a Stage Simple Imputer Transformer C\u00e0i \u0111\u1eb7t thu\u1ed9c t\u00ednh \u0111\u1ec3 x\u1eed l\u00fd Handle missing data nh\u01b0 h\u00ecnh 8 d\u01b0\u1edbi \u0111\u00e2y: Selected column : L\u1ef1a ch\u1ecdn c\u1ed9t c\u1ea7n x\u1eed l\u00fd Handle missing date. L\u01b0u \u00fd ki\u1ec3u d\u1eef li\u1ec7u c\u1ee7a c\u1ed9t c\u1ea7n x\u1eed l\u00fd Handle missing data. Missing Values : T\u00f9y ch\u1ecdn np.nan ho\u1eb7c None . T\u00f9y v\u00e0o dataset \u0111\u01b0a v\u00e0o c\u00f3 ph\u1ea7n d\u1eef li\u1ec7u b\u1ecb khuy\u1ebft \u0111\u01b0\u1ee3c m\u00e3 d\u01b0\u1edbi d\u1ea1ng n\u00e0o th\u00ec ta ch\u1ecdn d\u1ea1ng \u0111\u00f3. Strategy : l\u1ef1a ch\u1ecdn ph\u01b0\u01a1ng ph\u00e1p Handle missing data trong c\u00e1c ph\u01b0\u01a1ng ph\u00e1p: mean : L\u1ea5p \u0111\u1ea7y d\u1eef li\u1ec7u khuy\u1ebft b\u1eb1ng gi\u00e1 tr\u1ecb trung b\u00ecnh. median : L\u1ea5p \u0111\u1ea7y d\u1eef li\u1ec7u khuy\u1ebft b\u1eb1ng gi\u00e1 tr\u1ecb trung v\u1ecb. most_frequent : L\u1ea5p \u0111\u1ea7y d\u1eef li\u1ec7u khuy\u1ebft b\u1eb1ng d\u1eef li\u1ec7u c\u00f3 t\u1ea7n s\u1ed1 cao nh\u1ea5t. constant : L\u1ea5p \u0111\u1ea7y d\u1eef li\u1ec7u khuy\u1ebft b\u1eb1ng h\u1eb1ng s\u1ed1, h\u1eb1ng s\u1ed1 \u0111i\u1ec1n v\u00e0o \u00f4 textbox Fill Value Fill Value : \u0110i\u1ec1n h\u1eb1ng s\u1ed1 l\u1ea5p \u0111\u1ea7y d\u1eef li\u1ec7u khuy\u1ebft( n\u1ebfu l\u1ef1a ch\u1ecdn Strategy constant ) Sau khi \u0111\u00e3 c\u00e0i \u0111\u1eb7t xong, click Run \u0111\u1ec3 ch\u1ea1y. B\u01b0\u1edbc 4: Encode d\u1eef li\u1ec7u d\u1ea1ng string Ch\u1ecdn Stage One Hot Encoder Transformer trong m\u1ee5c Transformer c\u1ee7a Scikitsama.ml \u0111\u01b0a v\u00e0o Dataflow Editor. T\u1ea1o k\u1ebft n\u1ed1i t\u1eeb c\u00e1c Stage \u0111\u00e3 t\u1ea1o tr\u01b0\u1edbc \u0111\u00f3 v\u1edbi Stage One Hot Encoder Transformer , l\u1ef1a ch\u1ecdn c\u1ed9t d\u1eef li\u1ec7u encode. Sau khi c\u00e0i \u0111\u1eb7t thu\u1ed9c t\u00ednh , cick l\u1ea1i v\u00e0o Stage v\u00e0 click Run T\u00f9y v\u00e0o t\u1eebng b\u00e0i to\u00e1n, ngo\u00e0i One Hot Encoder Transformer ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng c\u00e1c Stage Transformer kh\u00e1c trong m\u1ee5c Transformer c\u1ee7a Scikitsama.ml nh\u01b0 Ordinal Encoder Transformer \u0111\u1ec3 encode d\u1eef li\u1ec7u. B\u01b0\u1edbc 5: Normalization d\u1eef li\u1ec7u: Trong c\u00e1c b\u00e0i to\u00e1n c\u1ee7a ch\u00fang ta, c\u00f3 m\u1ed9t s\u1ed1 d\u1eef li\u1ec7u kh\u00e1c nhau nhi\u1ec1u v\u1ec1 t\u1ec9 l\u1ec7. V\u00ec v\u1eady \u0111\u1ec3 gi\u1ea3m g\u00e1nh n\u1eb7ng cho m\u00f4 h\u00ecnh h\u1ecdc m\u00e1y , ta c\u1ea7n chu\u1ea9n h\u00f3a t\u1ec9 l\u1ec7 m\u1ed9t s\u1ed1 d\u1eef li\u1ec7u. \u1ede b\u00e0i n\u00e0y , ta chu\u1ea9n h\u00f3a d\u1eef li\u1ec7u v\u1ec1 tu\u1ed5i t\u00e1c h\u00e0nh kh\u00e1ch. Stage Normalize Transformer d\u00f9ng \u0111\u1ec3 b\u00ecnh th\u01b0\u1eddng h\u00f3a d\u1eef li\u1ec7u. Ch\u1ecdn Normalize Transformer trong m\u1ee5c Transformer c\u1ee7a Scikitsama.ml , t\u1ea1o k\u1ebft n\u1ed1i v\u1edbi stage cu\u1ed1i c\u1ee7a flow \u0111\u00e3 train (One Hot Encoder Transformer. L\u1ef1a ch\u1ecdn c\u1ed9t d\u1eef li\u1ec7u Age Sau khi c\u00e0i \u0111\u1eb7t thu\u1ed9c t\u00ednh , click l\u1ea1i v\u00e0o Stage v\u00e0 click Run B\u01b0\u1edbc 6: L\u1ef1a ch\u1ecdn thu\u1eadt to\u00e1n Classification: DSSAMA Platform cung c\u1ea5p c\u00e1c Stage Classification \u1edf h\u00ecnh 11, ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 l\u1ef1a ch\u1ecdn m\u1ed9t trong c\u00e1c Stage \u0111\u00f3 \u0111\u1ec3 ho\u00e0n th\u00e0nh m\u1ed9t m\u00f4 h\u00ecnh h\u1ecdc m\u00e1y v\u1edbi c\u00e1c ph\u1ea7n ti\u1ec1n x\u1eed l\u00fd d\u1eef li\u1ec7u \u0111\u00e3 th\u1ef1c hi\u1ec7n \u1edf c\u00e1c ph\u1ea7n tr\u00ean. M\u1ed7i Stage \u0111\u01b0\u1ee3c c\u00e1c thu\u1ed9c t\u00ednh \u0111\u01b0\u1ee3c c\u00e0i \u0111\u1eb7t v\u1edbi parameter m\u1eb7c \u0111\u1ecbnh \u0111\u1ec3 x\u1eed l\u00fd c\u00e1c b\u00e0i to\u00e1n \u0111i\u1ec3n h\u00ecnh, ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 thay \u0111\u1ed5i theo m\u1ee5c \u0111\u00edch t\u1eebng b\u00e0i to\u00e1n ng\u01b0\u1eddi d\u00f9ng x\u1eed l\u00fd. Ch\u00fang ta x\u00e2y d\u1ef1ng \u0111\u01b0\u1ee3c Flow nh\u01b0 h\u00ecnh 11 d\u01b0\u1edbi \u0111\u00e2y. K\u1ebft qu\u1ea3 hi\u1ec3n th\u1ecb c\u1ee7a Flow v\u1edbi l\u1ef1a ch\u1ecdn Classification l\u00e0 Random Forest Classifier M\u1ed9t s\u1ed1 Flow h\u1ecdc m\u00e1y \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng trong DSSAMA H\u00ecnh 16. M\u1ed9t s\u1ed1 Flow Classification for Titanic X\u00e2y d\u1ef1ng Flow cho b\u00e0i to\u00e1n s\u1eed d\u1ee5ng H\u1ed3i quy - Regression X\u00e2y d\u1ef1ng Flow cho b\u00e0i to\u00e1n ph\u00e2n c\u1ee5m ALS Recommendation 1. M\u00f4 thu\u1eadt to\u00e1n ALS: Thu\u1eadt to\u00e1n Alternating least squares (ALS) d\u1ef1a tr\u00ean vi\u1ec7c ph\u00e2n t\u00edch m\u1ed9t ma tr\u1eadn R th\u00e0nh hai ma tr\u1eadn U v\u00e0 V sao cho . K\u00edch th\u01b0\u1edbc h\u00e0ng c\u1ee7a ma tr\u1eadn kh\u00f4ng x\u00e1c \u0111\u1ecbnh \u0111\u01b0\u1ee3c cung c\u1ea5p d\u01b0\u1edbi d\u1ea1ng tham s\u1ed1 cho thu\u1eadt to\u00e1n v\u00e0 \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 c\u00e1c nh\u00e2n t\u1ed1 \u1ea9n. B\u1edfi v\u00ec Matrix Factorization c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong context c\u1ee7a recommendation, Ma tr\u1eadn U v\u00e0 V c\u00f3 th\u1ec3 g\u1ecdi t\u01b0\u01a1ng \u1ee9ng l\u00e0 User Matrix v\u00e0 Item Matrix. C\u1ed9t th\u1ee9 i c\u1ee7a user matrix \u0111\u01b0\u1ee3c k\u00fd hi\u1ec7u b\u1edfi v\u00e0 c\u1ed9t th\u1ee9 I c\u1ee7a item matrix l\u00e0 . Ma tr\u1eadn R c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 Ratings Matrix v\u1edbi . \u0110\u1ec3 t\u00ecm ra user v\u00e0 item matrix, ta c\u1ea7n t\u1ed1i \u01b0u h\u00e0m m\u1ea5t m\u00e1t sau: V\u1edbi \u03bb l\u00e0 h\u1ec7 s\u1ed1 regularization , l\u00e0 s\u1ed1 l\u01b0\u1ee3ng c\u00e1c items \u0111\u01b0\u1ee3c user I \u0111\u00e1nh gi\u00e1 v\u00e0 l\u00e0 s\u1ed1 l\u1ea7n item j \u0111\u01b0\u1ee3c \u0111\u00e1nh gi\u00e1. Regularization \u0111\u01b0\u1ee3c d\u00fang \u0111\u1ec3 tr\u00e1nh overfiting \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 weighted-\u03bb-regularization. Vi\u1ec7c t\u1ed1i \u01b0u \u0111\u1ed3ng th\u1eddi U, V l\u00e0 t\u01b0\u01a1ng \u0111\u1ed1i ph\u1ee9c t\u1ea1p, thay v\u00e0o \u0111\u00f3, ph\u01b0\u01a1ng ph\u00e1p \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng l\u00e0 l\u1ea7n l\u01b0\u1ee3t t\u1ed1i \u01b0u m\u1ed9t ma tr\u1eadn trong khi c\u1ed1 \u0111\u1ecbnh ma tr\u1eadn kia, t\u1edbi khi h\u1ed9i t\u1ee5. Ma tr\u1eadn R \u0111\u01b0\u1ee3c bi\u1ec3u di\u1ec5n l\u00e0 (i,j,r) trong \u0111\u00f3: i l\u00e0 k\u00fd hi\u1ec7u ch\u1ec9 s\u1ed1 h\u00e0ng, j l\u00e0 k\u00fd hi\u1ec7u ch\u1ec9 s\u1ed1 c\u1ed9t v\u00e0 r l\u00e0 gi\u00e1 tr\u1ecb ma tr\u1eadn \u1edf v\u1ecb tr\u00ed (i, j) 2. M\u00f4 t\u1ea3 b\u00e0i to\u00e1n: S\u1eed d\u1ee5ng m\u1ed9t file.csv \u0111\u00e1nh gi\u00e1 c\u1ee7a ng\u01b0\u1eddi d\u00f9ng v\u1edbi t\u1eebng b\u1ed9 phim trong b\u1ed9 d\u1eef li\u1ec7u MovieLens \u0111\u1ec3 \u0111\u01b0a v\u00e0o m\u00f4 h\u00ecnh ALS Output: T\u1eeb m\u00f4 h\u00ecnh \u0111\u00f3 c\u00f3 th\u1ec3 d\u1ef1 \u0111o\u00e1n \u0111\u01b0\u1ee3c m\u1ee9c \u0111\u1ed9 \u0111\u00e1nh gi\u00e1 c\u1ee7a ng\u01b0\u1eddi d\u00f9ng m\u1edbi v\u1edbi m\u1ed9t s\u1ed1 b\u1ed9 phim c\u0169ng nh\u01b0 nh\u1eefng ng\u01b0\u1eddi d\u00f9ng ti\u1ec1m n\u0103ng c\u00f3 th\u1ec3 xem b\u1ed9 phim \u0111\u00f3. Dataset: l\u00e0 m\u1ed9t file csv v\u1edbi 10000 records g\u1ed3m 3 c\u1ed9t: * Iduser : id c\u1ee7a ng\u01b0\u1eddi tham gia \u0111\u00e1nh gi\u00e1 * Idmovie : id c\u1ee7a b\u1ed9 phi \u0111\u01b0\u1ee3c \u0111\u00e1nh gi\u00e1 * Rating : l\u00e0 m\u1ee9c \u0111\u00e1nh gi\u00e1 c\u1ee7a ng\u01b0\u1eddi d\u00f9ng v\u1edbi b\u1ed9 phim t\u01b0\u01a1ng \u1ee9ng 3. C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n: B\u01b0\u1edbc 1: T\u1ea1o dataset l\u00e0 file.csv bao g\u1ed3m 3 c\u1ed9t iduser, idmovie v\u00e0 rating trong Workspace(Kh\u00f4ng ch\u1ecdn ID Column v\u00e0 Label Column): B\u01b0\u1edbc 2: T\u1ea1o m\u1ed9t Flow trong Project: B\u01b0\u1edbc 3: T\u1ea1o Flow tr\u00ean giao di\u1ec7n bao g\u1ed3m 1 stage Tabular v\u00e0 1 ALS stage: V\u1edbi stage Tabular: ch\u1ecdn c\u00e1c param Dataset l\u00e0 film(nh\u01b0 dataset \u0111\u00e3 t\u1ea1o \u1edf tr\u00ean) v\u00e0 param Select Column l\u00e0 ch\u1ecdn t\u1ea5t c\u1ea3 c\u00e1c c\u1ed9t. V\u1edbi stage ALS ta c\u1ea7n quan t\u00e2m \u0111\u1ebfn m\u1ed9t s\u1ed1 tham s\u1ed1 sau: Type Of Recommendation: g\u1ed3m 2 l\u1ef1a ch\u1ecdn l\u00e0 d\u1ef1 \u0111o\u00e1n m\u1ee9c \u0111\u1ed9 rate c\u1ee7a ng\u01b0\u1eddi d\u00f9ng v\u1edbi m\u1ed9t s\u1ed1 b\u1ed9 phim(RECOMMENDATION_FOR_USERS) v\u00e0 d\u1ef1 \u0111o\u00e1n ng\u01b0\u1eddi d\u00f9ng ti\u1ec1m n\u0103ng c\u00f3 th\u1ec3 xem m\u1ed9t b\u1ed9 phim(RECOMMENDATION_FOR_ITEMS). Number Of Recommendation: s\u1ed1 l\u01b0\u1ee3ng c\u1ea7n recommendation. User Col: ch\u1ecdn c\u1ed9t l\u00e0 userId(v\u1edbi b\u1ed9 dataset tr\u00ean). Item Col: Ch\u1ecdn c\u1ed9t l\u00e0 movieId(v\u1edbi b\u1ed9 dataset tr\u00ean). Rating Col: Ch\u1ecdn c\u1ed9t rating(v\u1edbi b\u1ed9 dataset tr\u00ean). Rank: s\u1ed1 l\u01b0\u1ee3ng c\u00e1c y\u1ebfu t\u1ed1 ti\u1ec1m \u1ea9n trong m\u00f4 h\u00ecnh (m\u1eb7c \u0111\u1ecbnh l\u00e0 10). Max Iter: s\u1ed1 l\u1ea7n l\u1eb7p t\u1ed1i \u0111a \u0111\u1ec3 ch\u1ea1y (m\u1eb7c \u0111\u1ecbnh l\u00e0 10). Reg Param: param regularization trong ALS. Cold Start Strategy: \u1edf b\u00e0i n\u00e0y ta ch\u1ecdn l\u00e0 \u2018drop\u2019. B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 xem k\u1ebft qu\u1ea3: Out put : \u0110\u1ea7u ra l\u00e0 top 10 b\u1ed9 phim \u0111\u01b0\u1ee3c d\u1ef1 \u0111o\u00e1n l\u00e0 ng\u01b0\u1eddi xem \u0111\u00e1nh gi\u00e1( Rating) cao nh\u1ea5t. Text Sentiment classification Image classification","title":"Tutorial"},{"location":"VN/vn_tutorial/#huong-dan-su-dung-dssama-cho-bai-toan-phan-tich-du-lieu","text":"\u1ede ch\u01b0\u01a1ng n\u00e0y , ch\u00fang t\u00f4i s\u1ebd h\u01b0\u1edbng d\u1eabn ng\u01b0\u1eddi d\u00f9ng s\u1eed d\u1ee5ng \u1ee9ng d\u1ee5ng DSSAMA - N\u1ec1n t\u1ea3ng \u0111\u1ec3 qu\u1ea3n l\u00fd v\u00e0 tri\u1ec3n khai c\u00e1c d\u1ef1 \u00e1n Ph\u00e2n t\u00edch d\u1eef li\u1ec7u l\u1edbn \u0111\u1ec3 ph\u00e2n t\u00edch c\u00e1c b\u00e0i to\u00e1n th\u1ef1c t\u1ebf.","title":"H\u01b0\u1edbng d\u1eabn s\u1eed d\u1ee5ng DSSAMA cho b\u00e0i to\u00e1n ph\u00e2n t\u00edch d\u1eef li\u1ec7u"},{"location":"VN/vn_tutorial/#welcome-to-dssama","text":"","title":"Welcome to DSSAMA"},{"location":"VN/vn_tutorial/#1-predict-survival-titanic-passengers","text":"B\u00e0i to\u00e1n Titanic \u0111i\u1ec3n h\u00ecnh trong ph\u00e2n t\u00edch d\u1ef1 \u0111o\u00e1n d\u1eef li\u1ec7u B\u00e0i to\u00e1n : V\u00e0o ng\u00e0y 15 th\u00e1ng 4 n\u0103m 1912, th\u1ea3m h\u1ecda Titanic l\u00e0 m\u1ed9t th\u1ea3m h\u1ecda n\u1ed5i ti\u1ebfng nh\u1ea5t trong l\u1ecbch s\u1eed, T\u00e0u RMS Titanic b\u1ecb ch\u00ecm sau khi va ch\u1ea1m v\u1edbi t\u1ea3ng b\u0103ng \u0111\u00e3 c\u01b0\u1edbp \u0111i 1502 sinh m\u1ea1ng tr\u00ean t\u1ed5ng s\u1ed1 2224 h\u00e0nh kh\u00e1ch v\u00e0 th\u1ee7y th\u1ee7 \u0111o\u00e0n, tr\u00f4i v\u1edbi s\u1ed1 li\u1ec7u thu th\u00e2p \u0111\u01b0\u1ee3c qua th\u1ea3m h\u1ecda bao g\u1ed3m s\u1ed1 l\u01b0\u1ee3ng h\u00e0nh kh\u00e1ch. B\u00e0i to\u00e1n l\u00e0 cho m\u1ed9t l\u01b0\u1ee3ng d\u1eef li\u1ec7u training cho tr\u01b0\u1edbc c\u1ee7a 892 h\u00e0nh kh\u00e1ch bao g\u1ed3m c\u00e1c th\u00f4ng tin nh\u01b0 t\u00ean, gi\u1edbi t\u00ednh, tu\u1ed5i, m\u00e3 s\u1ed1 v\u00e9, cabin, gi\u00e1 v\u00e9, quan h\u1ec7 nh\u00e2n th\u00e2n, s\u1ed1 l\u01b0\u01a1ng tr\u1ebb em, h\u1ecd h\u00e0ng, cha m\u1eb9 \u0111i c\u00f9ng, c\u00f2n s\u1ed1ng hay \u0111\u00e3 t\u1eed n\u1ea1n. Output : D\u1eef li\u1ec7u \u0111\u1ea7u ra l\u00e0 \u0111\u01b0a ra d\u1ef1 \u0111o\u00e1n v\u1ec1 kh\u1ea3 n\u0103ng t\u1eed n\u1ea1n c\u1ee7a c\u00e1c h\u00e0nh kh\u00e1ch c\u00f2n l\u1ea1i d\u1ef1a tr\u00ean nh\u1eefng y\u1ebfu t\u1ed1 bi\u1ebft tr\u01b0\u1edbc nh\u01b0 t\u00ean, tu\u1ed5i, gi\u1edbi t\u00ednh, s\u1ed1 ng\u01b0\u1eddi \u0111i c\u00f9ng, v\u1ecb tr\u00ed ph\u00f2ng v\u2026v. \u00dd ngh\u0129a : B\u00e0i to\u00e1n cho ph\u00e9p ch\u00fang ta c\u00f3 th\u1ec3 d\u1ef1a v\u00e0o \u0111\u00f3 \u0111\u1ec3 d\u1ef1 \u0111o\u00e1n kh\u1ea3 n\u0103ng s\u1ed1ng s\u00f3t c\u1ee7a m\u1ed9t ng\u01b0\u1eddi d\u1ef1a tr\u00ean m\u1ed9t th\u1ea3m h\u1ecda t\u1eeb \u0111\u00f3 c\u00f3 th\u1ec3 r\u00fat ra nh\u1eefng kinh nghi\u1ec7m trong c\u00e1c chuy\u1ebfn h\u00e0nh tr\u00ecnh trong t\u01b0\u01a1ng lai, C\u00f3 th\u1ec3 l\u00e0 thi\u1ebft k\u1ebf l\u1ea1i t\u00e0u m\u1ed9t c\u00e1ch an to\u00e0n h\u01a1n, d\u1ecbch v\u1ee5 ch\u0103m s\u00f3c, c\u1ea3nh b\u00e1o v..v Ph\u00e2n t\u00edch : C\u00f3 th\u1ec3 d\u1ec5 nh\u1eadn th\u1ea5y \u0111\u00e2y l\u00e0 m\u1ed9t b\u00e0i Two-Class Classification v\u1edbi k\u1ebft qu\u1ea3 \u0111\u1ea7u ra l\u00e0 NOT_SUVIVAL ho\u1eb7c SUVIVAL. V\u1edbi m\u1ed9t b\u00e0i to\u00e1n Two-Class Classification nh\u01b0 th\u1ebf n\u00e0y c\u00f3 th\u1ec3 gi\u1ea3i b\u1eb1ng nhi\u1ec1u c\u00e1ch v\u00e0 nhi\u1ec1u thu\u1eadt to\u00e1n kh\u00e1c nhau nh\u01b0 Bayes, Decision Tree, Decision Forest \u2026 T\u1eeb m\u1ed9t m\u1eabu d\u1eef li\u1ec7u RMS Titanic, ch\u00fang ta c\u00f3 th\u1ec3 th\u1ea5y c\u00e1c thu\u1ed9c t\u00ednh th\u1ec3 hi\u1ec3n cho m\u1ed7i h\u00e0nh kh\u00e1ch tr\u00ean t\u00e0u: Survial : K\u1ebft qu\u1ea3 s\u1ed1ng s\u00f3t (0 = Kh\u00f4ng; 1 = C\u00f3) Pclass : L\u1edbp kinh t\u1ebf x\u00e3 h\u1ed9i (1 = T\u1ea7ng l\u1edbp th\u01b0\u1ee3ng l\u01b0u; 2 = T\u1ea7ng l\u1edbp trung l\u01b0u; 3 = C\u00e1c t\u1ea7ng l\u1edbp th\u1ea5p) Name : T\u00ean c\u1ee7a h\u00e0nh kh\u00e1ch Sex : Gi\u1edbi t\u00ednh c\u1ee7a h\u00e0nh kh\u00e1ch Age : Tu\u1ed5i c\u1ee7a h\u00e0nh kh\u00e1ch (30% d\u1eef li\u1ec7u tu\u1ed5i c\u1ee7a h\u00e0nh kh\u00e1ch b\u1ecb khuy\u1ebft) SibSp : S\u1ed1 anh ch\u1ecb em ru\u1ed9t v\u00e0 v\u1ee3 / ch\u1ed3ng c\u1ee7a h\u00e0nh kh\u00e1ch tr\u00ean t\u00e0u Parch : S\u1ed1 ph\u1ee5 huynh v\u00e0 tr\u1ebb em c\u1ee7a h\u00e0nh kh\u00e1ch tr\u00ean t\u00e0u Ticket : S\u1ed1 hi\u1ec7u v\u00e9 c\u1ee7a h\u00e0nh kh\u00e1ch Fare : Gi\u00e1 v\u00e9 h\u00e0nh kh\u00e1ch tr\u1ea3 Cabin : s\u1ed1 cabin c\u1ee7a h\u00e0nh kh\u00e1ch (M\u1ed9t s\u1ed1 m\u1ee5c b\u1ecb khuy\u1ebft d\u1eef li\u1ec7u) Embarked : C\u1ea3ng \u0111\u00f3n kh\u00e1ch c\u1ee7a h\u00e0nh kh\u00e1ch (C = Cherbourg; Q = Queenstown; S = Southampton)","title":"1. Predict survival Titanic passengers"},{"location":"VN/vn_tutorial/#get-started","text":"","title":"Get started"},{"location":"VN/vn_tutorial/#buoc-1-tao-moi-flow-classification-for-titanic-e-lam-viec-voi-bai-toan-titanic-su-dung-cac-mo-hinh-hoc-may-phan-lop","text":"H\u00ecnh 5. Flow Cassification for Titanic v\u1eeba t\u1ea1o Click v\u00e0o Flow Classification for Titanic , giao di\u1ec7n l\u00e0m vi\u1ec7c tr\u1ef1c ti\u1ebfp - DSSAMA Flow hi\u1ec3n th\u1ecb nh\u01b0 trong h\u00ecnh 5. H\u00ecnh 6. Giao di\u1ec7n l\u00e0m vi\u1ec7c tr\u1ef1c ti\u1ebfp Flow Cassification for Titanic","title":"B\u01b0\u1edbc 1: T\u1ea1o m\u1edbi Flow Classification for Titanic \u0111\u1ec3 l\u00e0m vi\u1ec7c v\u1edbi b\u00e0i to\u00e1n Titanic s\u1eed d\u1ee5ng c\u00e1c M\u00f4 h\u00ecnh h\u1ecdc m\u00e1y ph\u00e2n l\u1edbp."},{"location":"VN/vn_tutorial/#buoc-2-import-du-lieu","text":"V\u1edbi b\u00e0i to\u00e1n Titanic, data source ban \u0111\u1ea7u kh\u1edfi t\u1ea1o l\u00e0 d\u1ea1ng Tabular, n\u00ean khi import d\u1eef li\u1ec7u , ta s\u1eed d\u1ee5ng Stage Tabular Input. Click l\u1ef1a ch\u1ecdn Stage Tabular Input \u1edf Stage Repository, \u0111\u01b0a sang Dataflow Editor, khi \u0111\u00f3 hi\u1ec3n th\u1ecb c\u1ed9t Stage Properties b\u00ean ph\u1ea3i m\u00e0n h\u00ecnh, ta t\u00f9y ch\u1ec9nh d\u1eef li\u1ec7u s\u1eed d\u1ee5ng cho ph\u00f9 h\u1ee3p. Quan s\u00e1t h\u00ecnh \u1ea3nh Dataset : l\u1ef1a ch\u1ecdn t\u1eadp d\u1eef li\u1ec7u Titanic Selected Comun : l\u1ef1a l\u1ef1a ch\u1ecdn c\u00e1c c\u1ed9t s\u1ebd s\u1eed d\u1ee5ng trong qu\u00e1 tr\u00ecnh x\u1eed l\u00fd d\u1eef li\u1ec7u. \u1ede v\u00ed d\u1ee5 n\u00e0y, c\u00e1c c\u1ed9t thu\u1ed9c t\u00ednh \u0111\u01b0\u1ee3c l\u1ef1a ch\u1ecdn \u0111\u1ec3 \u0111\u01b0a v\u00e0o ph\u00e2n t\u00edch kh\u00f4ng c\u00f3 thu\u1ed9c t\u00ednh Name , Ticket v\u00e0 Cabin : PClass , Sex , Age , SibSp , Parch , Fare , Embarked . Ng\u01b0\u1eddi d\u00f9ng c\u0169ng c\u00f3 th\u1ec3 l\u1ef1a ch\u1ecdn t\u1ea5t c\u1ea3 c\u00e1c c\u1ed9t d\u1eef li\u1ec7u \u0111\u1ec3 ph\u00e2n t\u00edch. Click l\u1ea1i v\u00e0o Stage v\u00e0 click Run \u0111\u1ec3 ki\u1ec3m tra d\u1eef li\u1ec7u import \u0111\u00e3 ch\u00ednh x\u00e1c ch\u01b0a. Sau khi ch\u1ea1y, ta \u0111\u01b0\u1ee3c b\u1ea3ng d\u1eef li\u1ec7u v\u00e0o \u0111\u01b0\u1ee3c bi\u1ec3u di\u1ec5n d\u01b0\u1edbi d\u1ea1ng \u0111\u1ed3 th\u1ecb v\u00e0 hi\u1ec3n th\u1ecb b\u1ea3ng d\u1eef li\u1ec7u v\u00e0o nh\u01b0 sau:","title":"B\u01b0\u1edbc 2: Import d\u1eef li\u1ec7u"},{"location":"VN/vn_tutorial/#buoc-3-xu-ly-du-lieu-khuyet","text":"Trong b\u00e0i to\u00e1n con t\u00e0u RMS Titanic, c\u1ed9t d\u1eef li\u1ec7u Age v\u00e0 Embarked khuy\u1ebft m\u1ed9t s\u1ed1 \u0111\u01a1n v\u1ecb d\u1eef li\u1ec7u n\u00ean c\u1ea7n x\u1eed l\u00fd c\u00e1c d\u1eef li\u1ec7u khuy\u1ebft \u0111\u00f3. \u0110\u1ec3 x\u1eed l\u00fd c\u1ed9t d\u1eef li\u1ec7u Age v\u00e0 Embarked , ch\u1ecdn Stage Simple Imputer Transformer trong m\u1ee5c Transformer c\u1ee7a Scikitsama.ml \u0111\u01b0a v\u00e0o Dataflow Editor.T\u1ea1o k\u1ebft n\u1ed1i output c\u1ee7a Stage Tabular Input l\u00e0 input c\u1ee7a Stage Simple Imputer Transformer C\u00e0i \u0111\u1eb7t thu\u1ed9c t\u00ednh \u0111\u1ec3 x\u1eed l\u00fd Handle missing data nh\u01b0 h\u00ecnh 8 d\u01b0\u1edbi \u0111\u00e2y: Selected column : L\u1ef1a ch\u1ecdn c\u1ed9t c\u1ea7n x\u1eed l\u00fd Handle missing date. L\u01b0u \u00fd ki\u1ec3u d\u1eef li\u1ec7u c\u1ee7a c\u1ed9t c\u1ea7n x\u1eed l\u00fd Handle missing data. Missing Values : T\u00f9y ch\u1ecdn np.nan ho\u1eb7c None . T\u00f9y v\u00e0o dataset \u0111\u01b0a v\u00e0o c\u00f3 ph\u1ea7n d\u1eef li\u1ec7u b\u1ecb khuy\u1ebft \u0111\u01b0\u1ee3c m\u00e3 d\u01b0\u1edbi d\u1ea1ng n\u00e0o th\u00ec ta ch\u1ecdn d\u1ea1ng \u0111\u00f3. Strategy : l\u1ef1a ch\u1ecdn ph\u01b0\u01a1ng ph\u00e1p Handle missing data trong c\u00e1c ph\u01b0\u01a1ng ph\u00e1p: mean : L\u1ea5p \u0111\u1ea7y d\u1eef li\u1ec7u khuy\u1ebft b\u1eb1ng gi\u00e1 tr\u1ecb trung b\u00ecnh. median : L\u1ea5p \u0111\u1ea7y d\u1eef li\u1ec7u khuy\u1ebft b\u1eb1ng gi\u00e1 tr\u1ecb trung v\u1ecb. most_frequent : L\u1ea5p \u0111\u1ea7y d\u1eef li\u1ec7u khuy\u1ebft b\u1eb1ng d\u1eef li\u1ec7u c\u00f3 t\u1ea7n s\u1ed1 cao nh\u1ea5t. constant : L\u1ea5p \u0111\u1ea7y d\u1eef li\u1ec7u khuy\u1ebft b\u1eb1ng h\u1eb1ng s\u1ed1, h\u1eb1ng s\u1ed1 \u0111i\u1ec1n v\u00e0o \u00f4 textbox Fill Value Fill Value : \u0110i\u1ec1n h\u1eb1ng s\u1ed1 l\u1ea5p \u0111\u1ea7y d\u1eef li\u1ec7u khuy\u1ebft( n\u1ebfu l\u1ef1a ch\u1ecdn Strategy constant ) Sau khi \u0111\u00e3 c\u00e0i \u0111\u1eb7t xong, click Run \u0111\u1ec3 ch\u1ea1y.","title":"B\u01b0\u1edbc 3: X\u1eed l\u00fd d\u1eef li\u1ec7u khuy\u1ebft"},{"location":"VN/vn_tutorial/#buoc-4-encode-du-lieu-dang-string","text":"Ch\u1ecdn Stage One Hot Encoder Transformer trong m\u1ee5c Transformer c\u1ee7a Scikitsama.ml \u0111\u01b0a v\u00e0o Dataflow Editor. T\u1ea1o k\u1ebft n\u1ed1i t\u1eeb c\u00e1c Stage \u0111\u00e3 t\u1ea1o tr\u01b0\u1edbc \u0111\u00f3 v\u1edbi Stage One Hot Encoder Transformer , l\u1ef1a ch\u1ecdn c\u1ed9t d\u1eef li\u1ec7u encode. Sau khi c\u00e0i \u0111\u1eb7t thu\u1ed9c t\u00ednh , cick l\u1ea1i v\u00e0o Stage v\u00e0 click Run T\u00f9y v\u00e0o t\u1eebng b\u00e0i to\u00e1n, ngo\u00e0i One Hot Encoder Transformer ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng c\u00e1c Stage Transformer kh\u00e1c trong m\u1ee5c Transformer c\u1ee7a Scikitsama.ml nh\u01b0 Ordinal Encoder Transformer \u0111\u1ec3 encode d\u1eef li\u1ec7u.","title":"B\u01b0\u1edbc 4: Encode d\u1eef li\u1ec7u d\u1ea1ng string"},{"location":"VN/vn_tutorial/#buoc-5-normalization-du-lieu","text":"Trong c\u00e1c b\u00e0i to\u00e1n c\u1ee7a ch\u00fang ta, c\u00f3 m\u1ed9t s\u1ed1 d\u1eef li\u1ec7u kh\u00e1c nhau nhi\u1ec1u v\u1ec1 t\u1ec9 l\u1ec7. V\u00ec v\u1eady \u0111\u1ec3 gi\u1ea3m g\u00e1nh n\u1eb7ng cho m\u00f4 h\u00ecnh h\u1ecdc m\u00e1y , ta c\u1ea7n chu\u1ea9n h\u00f3a t\u1ec9 l\u1ec7 m\u1ed9t s\u1ed1 d\u1eef li\u1ec7u. \u1ede b\u00e0i n\u00e0y , ta chu\u1ea9n h\u00f3a d\u1eef li\u1ec7u v\u1ec1 tu\u1ed5i t\u00e1c h\u00e0nh kh\u00e1ch. Stage Normalize Transformer d\u00f9ng \u0111\u1ec3 b\u00ecnh th\u01b0\u1eddng h\u00f3a d\u1eef li\u1ec7u. Ch\u1ecdn Normalize Transformer trong m\u1ee5c Transformer c\u1ee7a Scikitsama.ml , t\u1ea1o k\u1ebft n\u1ed1i v\u1edbi stage cu\u1ed1i c\u1ee7a flow \u0111\u00e3 train (One Hot Encoder Transformer. L\u1ef1a ch\u1ecdn c\u1ed9t d\u1eef li\u1ec7u Age Sau khi c\u00e0i \u0111\u1eb7t thu\u1ed9c t\u00ednh , click l\u1ea1i v\u00e0o Stage v\u00e0 click Run","title":"B\u01b0\u1edbc 5: Normalization d\u1eef li\u1ec7u:"},{"location":"VN/vn_tutorial/#buoc-6-lua-chon-thuat-toan-classification","text":"DSSAMA Platform cung c\u1ea5p c\u00e1c Stage Classification \u1edf h\u00ecnh 11, ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 l\u1ef1a ch\u1ecdn m\u1ed9t trong c\u00e1c Stage \u0111\u00f3 \u0111\u1ec3 ho\u00e0n th\u00e0nh m\u1ed9t m\u00f4 h\u00ecnh h\u1ecdc m\u00e1y v\u1edbi c\u00e1c ph\u1ea7n ti\u1ec1n x\u1eed l\u00fd d\u1eef li\u1ec7u \u0111\u00e3 th\u1ef1c hi\u1ec7n \u1edf c\u00e1c ph\u1ea7n tr\u00ean. M\u1ed7i Stage \u0111\u01b0\u1ee3c c\u00e1c thu\u1ed9c t\u00ednh \u0111\u01b0\u1ee3c c\u00e0i \u0111\u1eb7t v\u1edbi parameter m\u1eb7c \u0111\u1ecbnh \u0111\u1ec3 x\u1eed l\u00fd c\u00e1c b\u00e0i to\u00e1n \u0111i\u1ec3n h\u00ecnh, ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 thay \u0111\u1ed5i theo m\u1ee5c \u0111\u00edch t\u1eebng b\u00e0i to\u00e1n ng\u01b0\u1eddi d\u00f9ng x\u1eed l\u00fd. Ch\u00fang ta x\u00e2y d\u1ef1ng \u0111\u01b0\u1ee3c Flow nh\u01b0 h\u00ecnh 11 d\u01b0\u1edbi \u0111\u00e2y. K\u1ebft qu\u1ea3 hi\u1ec3n th\u1ecb c\u1ee7a Flow v\u1edbi l\u1ef1a ch\u1ecdn Classification l\u00e0 Random Forest Classifier M\u1ed9t s\u1ed1 Flow h\u1ecdc m\u00e1y \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng trong DSSAMA H\u00ecnh 16. M\u1ed9t s\u1ed1 Flow Classification for Titanic","title":"B\u01b0\u1edbc 6: L\u1ef1a ch\u1ecdn thu\u1eadt to\u00e1n Classification:"},{"location":"VN/vn_tutorial/#xay-dung-flow-cho-bai-toan-su-dung-hoi-quy-regression","text":"","title":"X\u00e2y d\u1ef1ng Flow cho b\u00e0i to\u00e1n s\u1eed d\u1ee5ng H\u1ed3i quy - Regression"},{"location":"VN/vn_tutorial/#xay-dung-flow-cho-bai-toan-phan-cum","text":"","title":"X\u00e2y d\u1ef1ng Flow cho b\u00e0i to\u00e1n ph\u00e2n c\u1ee5m"},{"location":"VN/vn_tutorial/#als-recommendation","text":"","title":"ALS Recommendation"},{"location":"VN/vn_tutorial/#1-mo-thuat-toan-als","text":"Thu\u1eadt to\u00e1n Alternating least squares (ALS) d\u1ef1a tr\u00ean vi\u1ec7c ph\u00e2n t\u00edch m\u1ed9t ma tr\u1eadn R th\u00e0nh hai ma tr\u1eadn U v\u00e0 V sao cho . K\u00edch th\u01b0\u1edbc h\u00e0ng c\u1ee7a ma tr\u1eadn kh\u00f4ng x\u00e1c \u0111\u1ecbnh \u0111\u01b0\u1ee3c cung c\u1ea5p d\u01b0\u1edbi d\u1ea1ng tham s\u1ed1 cho thu\u1eadt to\u00e1n v\u00e0 \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 c\u00e1c nh\u00e2n t\u1ed1 \u1ea9n. B\u1edfi v\u00ec Matrix Factorization c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong context c\u1ee7a recommendation, Ma tr\u1eadn U v\u00e0 V c\u00f3 th\u1ec3 g\u1ecdi t\u01b0\u01a1ng \u1ee9ng l\u00e0 User Matrix v\u00e0 Item Matrix. C\u1ed9t th\u1ee9 i c\u1ee7a user matrix \u0111\u01b0\u1ee3c k\u00fd hi\u1ec7u b\u1edfi v\u00e0 c\u1ed9t th\u1ee9 I c\u1ee7a item matrix l\u00e0 . Ma tr\u1eadn R c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 Ratings Matrix v\u1edbi . \u0110\u1ec3 t\u00ecm ra user v\u00e0 item matrix, ta c\u1ea7n t\u1ed1i \u01b0u h\u00e0m m\u1ea5t m\u00e1t sau: V\u1edbi \u03bb l\u00e0 h\u1ec7 s\u1ed1 regularization , l\u00e0 s\u1ed1 l\u01b0\u1ee3ng c\u00e1c items \u0111\u01b0\u1ee3c user I \u0111\u00e1nh gi\u00e1 v\u00e0 l\u00e0 s\u1ed1 l\u1ea7n item j \u0111\u01b0\u1ee3c \u0111\u00e1nh gi\u00e1. Regularization \u0111\u01b0\u1ee3c d\u00fang \u0111\u1ec3 tr\u00e1nh overfiting \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 weighted-\u03bb-regularization. Vi\u1ec7c t\u1ed1i \u01b0u \u0111\u1ed3ng th\u1eddi U, V l\u00e0 t\u01b0\u01a1ng \u0111\u1ed1i ph\u1ee9c t\u1ea1p, thay v\u00e0o \u0111\u00f3, ph\u01b0\u01a1ng ph\u00e1p \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng l\u00e0 l\u1ea7n l\u01b0\u1ee3t t\u1ed1i \u01b0u m\u1ed9t ma tr\u1eadn trong khi c\u1ed1 \u0111\u1ecbnh ma tr\u1eadn kia, t\u1edbi khi h\u1ed9i t\u1ee5. Ma tr\u1eadn R \u0111\u01b0\u1ee3c bi\u1ec3u di\u1ec5n l\u00e0 (i,j,r) trong \u0111\u00f3: i l\u00e0 k\u00fd hi\u1ec7u ch\u1ec9 s\u1ed1 h\u00e0ng, j l\u00e0 k\u00fd hi\u1ec7u ch\u1ec9 s\u1ed1 c\u1ed9t v\u00e0 r l\u00e0 gi\u00e1 tr\u1ecb ma tr\u1eadn \u1edf v\u1ecb tr\u00ed (i, j)","title":"1.  M\u00f4 thu\u1eadt to\u00e1n ALS:"},{"location":"VN/vn_tutorial/#2-mo-ta-bai-toan","text":"S\u1eed d\u1ee5ng m\u1ed9t file.csv \u0111\u00e1nh gi\u00e1 c\u1ee7a ng\u01b0\u1eddi d\u00f9ng v\u1edbi t\u1eebng b\u1ed9 phim trong b\u1ed9 d\u1eef li\u1ec7u MovieLens \u0111\u1ec3 \u0111\u01b0a v\u00e0o m\u00f4 h\u00ecnh ALS Output: T\u1eeb m\u00f4 h\u00ecnh \u0111\u00f3 c\u00f3 th\u1ec3 d\u1ef1 \u0111o\u00e1n \u0111\u01b0\u1ee3c m\u1ee9c \u0111\u1ed9 \u0111\u00e1nh gi\u00e1 c\u1ee7a ng\u01b0\u1eddi d\u00f9ng m\u1edbi v\u1edbi m\u1ed9t s\u1ed1 b\u1ed9 phim c\u0169ng nh\u01b0 nh\u1eefng ng\u01b0\u1eddi d\u00f9ng ti\u1ec1m n\u0103ng c\u00f3 th\u1ec3 xem b\u1ed9 phim \u0111\u00f3. Dataset: l\u00e0 m\u1ed9t file csv v\u1edbi 10000 records g\u1ed3m 3 c\u1ed9t: * Iduser : id c\u1ee7a ng\u01b0\u1eddi tham gia \u0111\u00e1nh gi\u00e1 * Idmovie : id c\u1ee7a b\u1ed9 phi \u0111\u01b0\u1ee3c \u0111\u00e1nh gi\u00e1 * Rating : l\u00e0 m\u1ee9c \u0111\u00e1nh gi\u00e1 c\u1ee7a ng\u01b0\u1eddi d\u00f9ng v\u1edbi b\u1ed9 phim t\u01b0\u01a1ng \u1ee9ng","title":"2.  M\u00f4 t\u1ea3 b\u00e0i to\u00e1n:"},{"location":"VN/vn_tutorial/#3-cac-buoc-thuc-hien","text":"","title":"3.  C\u00e1c b\u01b0\u1edbc th\u1ef1c hi\u1ec7n:"},{"location":"VN/vn_tutorial/#buoc-1-tao-dataset-la-filecsv-bao-gom-3-cot-iduser-idmovie-va-rating-trong-workspacekhong-chon-id-column-va-label-column","text":"","title":"B\u01b0\u1edbc 1: T\u1ea1o dataset l\u00e0 file.csv bao g\u1ed3m 3 c\u1ed9t iduser, idmovie v\u00e0 rating trong Workspace(Kh\u00f4ng ch\u1ecdn ID Column v\u00e0 Label Column):"},{"location":"VN/vn_tutorial/#buoc-2-tao-mot-flow-trong-project","text":"","title":"B\u01b0\u1edbc 2: T\u1ea1o m\u1ed9t Flow trong Project:"},{"location":"VN/vn_tutorial/#buoc-3-tao-flow-tren-giao-dien-bao-gom-1-stage-tabular-va-1-als-stage","text":"V\u1edbi stage Tabular: ch\u1ecdn c\u00e1c param Dataset l\u00e0 film(nh\u01b0 dataset \u0111\u00e3 t\u1ea1o \u1edf tr\u00ean) v\u00e0 param Select Column l\u00e0 ch\u1ecdn t\u1ea5t c\u1ea3 c\u00e1c c\u1ed9t. V\u1edbi stage ALS ta c\u1ea7n quan t\u00e2m \u0111\u1ebfn m\u1ed9t s\u1ed1 tham s\u1ed1 sau: Type Of Recommendation: g\u1ed3m 2 l\u1ef1a ch\u1ecdn l\u00e0 d\u1ef1 \u0111o\u00e1n m\u1ee9c \u0111\u1ed9 rate c\u1ee7a ng\u01b0\u1eddi d\u00f9ng v\u1edbi m\u1ed9t s\u1ed1 b\u1ed9 phim(RECOMMENDATION_FOR_USERS) v\u00e0 d\u1ef1 \u0111o\u00e1n ng\u01b0\u1eddi d\u00f9ng ti\u1ec1m n\u0103ng c\u00f3 th\u1ec3 xem m\u1ed9t b\u1ed9 phim(RECOMMENDATION_FOR_ITEMS). Number Of Recommendation: s\u1ed1 l\u01b0\u1ee3ng c\u1ea7n recommendation. User Col: ch\u1ecdn c\u1ed9t l\u00e0 userId(v\u1edbi b\u1ed9 dataset tr\u00ean). Item Col: Ch\u1ecdn c\u1ed9t l\u00e0 movieId(v\u1edbi b\u1ed9 dataset tr\u00ean). Rating Col: Ch\u1ecdn c\u1ed9t rating(v\u1edbi b\u1ed9 dataset tr\u00ean). Rank: s\u1ed1 l\u01b0\u1ee3ng c\u00e1c y\u1ebfu t\u1ed1 ti\u1ec1m \u1ea9n trong m\u00f4 h\u00ecnh (m\u1eb7c \u0111\u1ecbnh l\u00e0 10). Max Iter: s\u1ed1 l\u1ea7n l\u1eb7p t\u1ed1i \u0111a \u0111\u1ec3 ch\u1ea1y (m\u1eb7c \u0111\u1ecbnh l\u00e0 10). Reg Param: param regularization trong ALS. Cold Start Strategy: \u1edf b\u00e0i n\u00e0y ta ch\u1ecdn l\u00e0 \u2018drop\u2019.","title":"B\u01b0\u1edbc 3: T\u1ea1o Flow tr\u00ean giao di\u1ec7n bao g\u1ed3m 1 stage Tabular v\u00e0 1 ALS stage:"},{"location":"VN/vn_tutorial/#buoc-4-an-run-e-xem-ket-qua","text":"Out put : \u0110\u1ea7u ra l\u00e0 top 10 b\u1ed9 phim \u0111\u01b0\u1ee3c d\u1ef1 \u0111o\u00e1n l\u00e0 ng\u01b0\u1eddi xem \u0111\u00e1nh gi\u00e1( Rating) cao nh\u1ea5t.","title":"B\u01b0\u1edbc 4: \u1ea4n Run \u0111\u1ec3 xem k\u1ebft qu\u1ea3:"},{"location":"VN/vn_tutorial/#text-sentiment-classification","text":"","title":"Text Sentiment classification"},{"location":"VN/vn_tutorial/#image-classification","text":"","title":"Image classification"},{"location":"VN/vn_workspace/","text":"","title":"Workspace"}]}